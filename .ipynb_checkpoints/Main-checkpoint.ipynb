{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No file DS_Store\n"
     ]
    }
   ],
   "source": [
    "dataPath = os.getcwd() + '/court case data/testdata/'\n",
    "caseCount = len(os.listdir(dataPath))\n",
    "data = []\n",
    "try:\n",
    "    os.remove(dataPath + \".DS_Store\")\n",
    "except:\n",
    "    print(\"No file DS_Store\")\n",
    "for filename in os.listdir(dataPath):\n",
    "    f = open(os.path.join(dataPath, filename), encoding='utf-8')\n",
    "    data.append([filename.replace('.txt', ''), f.read()])\n",
    "\n",
    "verdict_df = pd.DataFrame(data, columns=[\"id\", \"case text\"])\n",
    "cases_df = pd.read_csv('./court case data/testdata.csv')\n",
    "merged_df = cases_df.join(verdict_df.set_index('id'), on='id', how='left')\n",
    "\n",
    "merged_df[\"verdict_date\"] = pd.to_datetime(merged_df[\"verdict_date\"])\n",
    "merged_df[\"publication_date\"] = pd.to_datetime(merged_df[\"publication_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>verdict_date</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>verdict_type</th>\n",
       "      <th>jurisdiction_type</th>\n",
       "      <th>case text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ECLI-NL-RBNNE-2021-5018</td>\n",
       "      <td>2021-01-10</td>\n",
       "      <td>2021-11-23</td>\n",
       "      <td>uitspraak</td>\n",
       "      <td>['Strafrecht']</td>\n",
       "      <td>\\n\\nRECHTBANK NOORD-NEDERLAND\\nAfdeling strafr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ECLI-NL-RBZUT-2003-AH9598</td>\n",
       "      <td>2003-03-06</td>\n",
       "      <td>2003-09-07</td>\n",
       "      <td>uitspraak</td>\n",
       "      <td>['Strafrecht']</td>\n",
       "      <td>\\n\\nRECHTBANK ZUTPHEN\\nMeervoudige economische...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ECLI-NL-RBZWB-2020-2646</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>uitspraak</td>\n",
       "      <td>['Strafrecht']</td>\n",
       "      <td>\\n\\nRECHTBANK ZEELAND-WEST-BRABANT\\n\\nStrafrec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ECLI-NL-GHAMS-2019-1601</td>\n",
       "      <td>2019-08-05</td>\n",
       "      <td>2019-07-26</td>\n",
       "      <td>uitspraak</td>\n",
       "      <td>['Strafrecht']</td>\n",
       "      <td>\\n\\nafdeling strafrecht\\nparketnummer: 23-0017...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ECLI-NL-GHAMS-2019-1602</td>\n",
       "      <td>2019-08-05</td>\n",
       "      <td>2019-07-26</td>\n",
       "      <td>uitspraak</td>\n",
       "      <td>['Strafrecht']</td>\n",
       "      <td>\\n\\nafdeling strafrecht\\nparketnummer: 23-0017...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18119</th>\n",
       "      <td>ECLI-NL-RBAMS-2013-1294</td>\n",
       "      <td>2013-01-29</td>\n",
       "      <td>2013-08-10</td>\n",
       "      <td>uitspraak</td>\n",
       "      <td>['Strafrecht']</td>\n",
       "      <td>\\n\\nRECHTBANK AMSTERDAM\\n\\n\\nVONNIS\\n\\n \\n\\n13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18120</th>\n",
       "      <td>ECLI-NL-PHR-2020-1106</td>\n",
       "      <td>2020-11-24</td>\n",
       "      <td>2020-11-24</td>\n",
       "      <td>conclusie</td>\n",
       "      <td>['Strafrecht']</td>\n",
       "      <td>\\n\\nPROCUREUR-GENERAAL\\n\\n\\nBIJ DE\\n\\n\\nHOGE R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18121</th>\n",
       "      <td>ECLI-NL-GHAMS-2017-2618</td>\n",
       "      <td>2017-06-29</td>\n",
       "      <td>2017-05-07</td>\n",
       "      <td>uitspraak</td>\n",
       "      <td>['Strafrecht']</td>\n",
       "      <td>\\n\\n\\nparketnummer: 23-001217-13\\ndatum uitspr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18122</th>\n",
       "      <td>ECLI-NL-RBAMS-2013-BZ0392</td>\n",
       "      <td>2013-01-29</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>uitspraak</td>\n",
       "      <td>['Strafrecht']</td>\n",
       "      <td>\\nRECHTBANK AMSTERDAM \\nVONNIS  \\n\\n13/529144-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18123</th>\n",
       "      <td>ECLI-NL-GHAMS-2007-BB2447</td>\n",
       "      <td>2007-07-13</td>\n",
       "      <td>2007-08-29</td>\n",
       "      <td>uitspraak</td>\n",
       "      <td>['Strafrecht']</td>\n",
       "      <td>\\n\\narrestnummer: \\nparketnummer:\\t23-001835-0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18124 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id verdict_date publication_date verdict_type  \\\n",
       "0        ECLI-NL-RBNNE-2021-5018   2021-01-10       2021-11-23    uitspraak   \n",
       "1      ECLI-NL-RBZUT-2003-AH9598   2003-03-06       2003-09-07    uitspraak   \n",
       "2        ECLI-NL-RBZWB-2020-2646   2020-06-23       2020-06-23    uitspraak   \n",
       "3        ECLI-NL-GHAMS-2019-1601   2019-08-05       2019-07-26    uitspraak   \n",
       "4        ECLI-NL-GHAMS-2019-1602   2019-08-05       2019-07-26    uitspraak   \n",
       "...                          ...          ...              ...          ...   \n",
       "18119    ECLI-NL-RBAMS-2013-1294   2013-01-29       2013-08-10    uitspraak   \n",
       "18120      ECLI-NL-PHR-2020-1106   2020-11-24       2020-11-24    conclusie   \n",
       "18121    ECLI-NL-GHAMS-2017-2618   2017-06-29       2017-05-07    uitspraak   \n",
       "18122  ECLI-NL-RBAMS-2013-BZ0392   2013-01-29       2013-01-02    uitspraak   \n",
       "18123  ECLI-NL-GHAMS-2007-BB2447   2007-07-13       2007-08-29    uitspraak   \n",
       "\n",
       "      jurisdiction_type                                          case text  \n",
       "0        ['Strafrecht']  \\n\\nRECHTBANK NOORD-NEDERLAND\\nAfdeling strafr...  \n",
       "1        ['Strafrecht']  \\n\\nRECHTBANK ZUTPHEN\\nMeervoudige economische...  \n",
       "2        ['Strafrecht']  \\n\\nRECHTBANK ZEELAND-WEST-BRABANT\\n\\nStrafrec...  \n",
       "3        ['Strafrecht']  \\n\\nafdeling strafrecht\\nparketnummer: 23-0017...  \n",
       "4        ['Strafrecht']  \\n\\nafdeling strafrecht\\nparketnummer: 23-0017...  \n",
       "...                 ...                                                ...  \n",
       "18119    ['Strafrecht']  \\n\\nRECHTBANK AMSTERDAM\\n\\n\\nVONNIS\\n\\n \\n\\n13...  \n",
       "18120    ['Strafrecht']  \\n\\nPROCUREUR-GENERAAL\\n\\n\\nBIJ DE\\n\\n\\nHOGE R...  \n",
       "18121    ['Strafrecht']  \\n\\n\\nparketnummer: 23-001217-13\\ndatum uitspr...  \n",
       "18122    ['Strafrecht']  \\nRECHTBANK AMSTERDAM \\nVONNIS  \\n\\n13/529144-...  \n",
       "18123    ['Strafrecht']  \\n\\narrestnummer: \\nparketnummer:\\t23-001835-0...  \n",
       "\n",
       "[18124 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import re\n",
    "alphabets= \"([A-Za-z])\"\n",
    "prefixes = \"(Mr|St|Mrs|Ms|Dr|mr|mevr|mvr)[.]\"\n",
    "suffixes = \"(Inc|Ltd|Jr|Sr|Co)\"\n",
    "starters = \"(Mr|Mrs|Ms|Dr|He\\s|She\\s|It\\s|They\\s|Their\\s|Our\\s|We\\s|But\\s|However\\s|That\\s|This\\s|Wherever)\"\n",
    "acronyms = \"([A-Z][.][A-Z][.](?:[A-Z][.])?)\"\n",
    "websites = \"[.](com|net|org|io|gov|nl)\"\n",
    "articles = \"[artikel ][0-9][.][0-9]\"\n",
    "\n",
    "def split_into_sentences2(text):\n",
    "    text = \" \" + text + \"  \"\n",
    "    text = text.replace(\"\\n\",\" \")\n",
    "    text = re.sub(prefixes,\"\\\\1<prd>\",text)\n",
    "    text = re.sub(websites,\"<prd>\\\\1\",text)\n",
    "    text = re.sub(articles,\"[artikelnummer]\",text)\n",
    "    if \"Ph.D\" in text: text = text.replace(\"Ph.D.\",\"Ph<prd>D<prd>\")\n",
    "    text = re.sub(\"\\s\" + alphabets + \"[.] \",\" \\\\1<prd> \",text)\n",
    "    text = re.sub(acronyms+\" \"+starters,\"\\\\1<stop> \\\\2\",text)\n",
    "    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\\\\3<prd>\",text)\n",
    "    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\",text)\n",
    "    text = re.sub(\" \"+suffixes+\"[.] \"+starters,\" \\\\1<stop> \\\\2\",text)\n",
    "    text = re.sub(\" \"+suffixes+\"[.]\",\" \\\\1<prd>\",text)\n",
    "    text = re.sub(\" \" + alphabets + \"[.]\",\" \\\\1<prd>\",text)\n",
    "    if \"”\" in text: text = text.replace(\".”\",\"”.\")\n",
    "    if \"\\\"\" in text: text = text.replace(\".\\\"\",\"\\\".\")\n",
    "    if \"!\" in text: text = text.replace(\"!\\\"\",\"\\\"!\")\n",
    "    if \"?\" in text: text = text.replace(\"?\\\"\",\"\\\"?\")\n",
    "    text = text.replace(\".\",\".<stop>\")\n",
    "    text = text.replace(\"?\",\"?<stop>\")\n",
    "    text = text.replace(\"!\",\"!<stop>\")\n",
    "    text = text.replace(\"<prd>\",\".\")\n",
    "    sentences = text.split(\"<stop>\")\n",
    "    sentences = sentences[:-1]\n",
    "    sentences = [s.strip() for s in sentences]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_sentences(text):\n",
    "    sentences = re.split(r'(?<=[^A-Z].[.?]) +(?=[A-Z])|\\n', text)\n",
    "    sentences = [x for x in sentences if len(x) > 1]\n",
    "    return sentences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two ways of splitting the documents:\n",
    "    For Word2Vec, we need sentences to be an array of words.\n",
    "    For the rest, just the sentence is enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tenlastelegging_words = ['tenlastelegging', 'telastelegging', 'tenlasteleggingen', 'telastlegging']\n",
    "\n",
    "def trim_by_tenlastelegging(doc):\n",
    "    trimmed_doc = doc\n",
    "    stop = False\n",
    "    for keyword in tenlastelegging_words:\n",
    "        if not stop and keyword in doc:\n",
    "            keyword_index = doc.find(keyword)\n",
    "            trimmed_doc = doc[keyword_index:]\n",
    "            stop = True\n",
    "    return trimmed_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18124\n",
      "4714882\n"
     ]
    }
   ],
   "source": [
    "sentence_list_by_word = []\n",
    "sentence_list = []\n",
    "\n",
    "for i in range(len(merged_df)):\n",
    "    doc = merged_df.iloc[i]['case text']\n",
    "    trimmed_doc = trim_by_tenlastelegging(doc)\n",
    "    sentences = split_into_sentences(trimmed_doc)\n",
    "    sentence_list.append(sentences)\n",
    "    for j in sentences:\n",
    "        word_list = [x for x in j.lower().rstrip().replace('.', '').split(' ') if len(x)>0]\n",
    "        sentence_list_by_word.append(word_list)\n",
    "        \n",
    "print(len(sentence_list))\n",
    "print(len(sentence_list_by_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in sentence_list[:1]:\n",
    "    for j in i:\n",
    "        print(j, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rechtbank \n",
      "\n",
      "noord-nederland \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in sentence_list_by_word[:1]:\n",
    "    for j in i:\n",
    "        print(j, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18124\n"
     ]
    }
   ],
   "source": [
    "print(len(sentence_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4714882\n"
     ]
    }
   ],
   "source": [
    "print(len(sentence_list_by_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import common_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dutch_word2vec_model = Word2Vec(sentences=sentence_list_by_word, vector_size=100, window=5, min_count=1, workers=4)\n",
    "dutch_word2vec_model.save(\"word2vec_dutch_court_cases.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dutch_word2vec_model = Word2Vec.load(\"word2vec_dutch_court_cases.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mdma', 'ketamine', 'speed', 'amfetamine', 'heroïne', 'ghb', 'xtc-pillen', 'marihuana', 'lsd', 'diazepam', 'methadon', 'mdma)', 'xtc-tabletten', 'amfetaminen', 'cocaïne', 'fenacetine', 'oxazepam', 'morfine', 'pillen', '(mdma)', 'heroïne)', 'weed', 'kamagra', 'ecstasy', 'metamfetamine', 'wiet', 'methamfetamine', 'xtc)', 'xtc/mdma', 'cafeïne', 'amfetamine)', 'amfetamines', 'pillen)', 'steroïden', 'cannabis', 'gbl', 'hashish', 'anabole', '(cocaïne', 'lidocaïne', 'a-pvp', 'paracetamol', 'crystal', 'harddrugs', 'coke', '(amfetamine)', 'hasj', 'amfetamine’', 'pure', 'tabletten', '(speed)', '4-mta', 'pseudo-efedrine', 'meth', 'levamisol', 'cocaïne)', 'amfetamine;', 'mdma-poeder', '(xtc)', 'heroïne;', 'temazepam', 'hash', 'cocaine', 'pep', 'viagra', 'opium', '2c-b', 'inositol', 'cocaïne;', 'mdma/xtc', 'sildenafil', 'mdma;', 'tabletten)', 'manitol', '(mdma', 'lorazepam', 'crack', 'pil', 'procaïne', 'opiaten', 'mcpp', 'mannitol', 'amfetaminepasta', '34-methyleendioxymethamfetamine', 'mdma-kristallen', 'pasta', '(met)amfetamine', 'versnijdingsmiddel', '‘kok’', 'pmma', 'drugs', 'mdma-pillen', 'base', 'cocaïne28', 'xtc-poeder', 'benzodiazepinen', 'hennep)', 'mefedron', 'capsules', 'tabak']\n"
     ]
    }
   ],
   "source": [
    "sims = dutch_word2vec_model.wv.most_similar('xtc', topn=100)\n",
    "print([i[0] for i in sims])\n",
    "# print(sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create list of drugs, smuggle, quantity keywords with Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_word2vec_relevant_words(words, matches):\n",
    "    word2vec_list = []\n",
    "    for word in words:\n",
    "        results = dutch_word2vec_model.wv.most_similar(word, topn=100)\n",
    "        for i in results:\n",
    "            word2vec_list.append(i[0])\n",
    "            \n",
    "    word2vec_list = list(set([i for i in word2vec_list if word2vec_list.count(i)>matches]))\n",
    "    return word2vec_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drugs list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77\n",
      "['methamfetamine', 'safrol', 'lsd', 'amfetaminepasta', 'drugs', '34-methyleendioxymethamfetamine', 'heroïne;', 'apaa', 'fenacetine', 'pep', 'mdma-kristallen', 'harddrugs', 'ghb', 'd-metamfetamine', 'kristallen', 'cocaïne)', 'amfetaminesulfaat', 'marihuana', 'mdma', 'heroïne)', 'cocaïne28', 'methadon', 'amfetaminebase', 'weed', 'cocaïne;', 'hennep', 'pseudo-efedrine', 'n-formylamfetamine', 'speed', 'ketamine', 'cafeïne', 'amfetamineolie', 'methanol', 'cocaïne', 'eindproduct', 'ecstasy', 'paracetamol', 'tabletten', 'manitol', 'amfetamine', 'cannabis', 'xtc', 'pil', '2c-b', 'crystal', '(met)amfetamine', 'lidocaïne', 'mdma)', '(mdma)', 'mdma/xtc', 'gbl', 'diazepam', 'amfetamine’', 'hash', 'xtc-tabletten', 'hashish', 'cocaïne?', 'mdma-pillen', 'azijnzuuranhydride', 'mdma-poeder', 'metamfetamine', 'crack', 'cocaine', 'mdma;', 'amfetaminen', 'pillen', 'amfetamine)', 'mefedron', 'heroïne', 'coke', 'hasj', 'xtc-pillen', 'morfine', 'apaan', 'opium', 'hasjiesj', 'mapa']\n"
     ]
    }
   ],
   "source": [
    "list_of_drugs = ['xtc', 'mdma', 'cocaine', 'wiet', 'speed', 'bmk', 'pmk']\n",
    "word2vec_drug_list = create_word2vec_relevant_words(list_of_drugs, 2)\n",
    "\n",
    "print(len(word2vec_drug_list))\n",
    "print(word2vec_drug_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n"
     ]
    }
   ],
   "source": [
    "drugs_to_exclude = ['pasta', 'kristallen', 'poedervorm']\n",
    "word2vec_drug_list = [drug for drug in word2vec_drug_list if drug not in drugs_to_exclude]\n",
    "print(len(word2vec_drug_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smuggle keyword list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n",
      "['produceren', 'leverantie', 'bronlanden', 'fabricage', 'exporteren', 'vervaardiging', 'uithalen', 'smokkel', 'verwerking', 'productie', 'transport', 'kweek', 'importeren', 'doorlevering', 'versnijden', 'invoeren', 'transsport', 'cocaïnehandel', 'verhandeling', 'transporteren', 'gesmokkelde', 'hennepteelt', 'doorverkoop', 'levering', 'productie/bewerking', '(invoer', 'aanvoer', 'afzet', 'verkoop', 'bewerking', 'hennephandel', 'in-/uitvoer', 'handel', 'export', 'binnensmokkelen', 'invoer', 'versnijding', 'uitvoer', 'leverancier', 'bronland', 'import', 'doorvoer', 'produktie']\n"
     ]
    }
   ],
   "source": [
    "list_of_smuggle_words = ['smokkel', 'invoer', 'uitvoer', 'import', 'export', 'transport']\n",
    "word2vec_smuggle_list = create_word2vec_relevant_words(list_of_smuggle_words, 3)\n",
    "\n",
    "word2vec_smuggle_list = list(set(word2vec_smuggle_list + list_of_smuggle_words ))\n",
    "print(len(word2vec_smuggle_list))\n",
    "print(word2vec_smuggle_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drugs_to_exclude = ['pasta', 'kristallen', 'poedervorm']\n",
    "# word2vec_drug_list = [drug for drug in word2vec_drug_list if drug not in drugs_to_exclude]\n",
    "# print(len(word2vec_drug_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantity keyword list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "['stuks', 'bollen', 'pillen', 'kg)', 'gram', 'gram;', 'kilo)', 'milliliter', 'pakjes', 'kilogram)', 'pakketten', 'mg)', 'bolletjes', 'xtc-pillen', 'blokken', 'ton', 'gripzakjes', 'mdma-pillen', 'zakjes', 'wikkels', 'joints', 'slikkersbollen', 'gram)', 'tabletten', 'ponypacks', 'kilo']\n"
     ]
    }
   ],
   "source": [
    "list_of_quantity_words = ['tabletten', 'kilo', 'gram', 'pakketten']\n",
    "word2vec_quantity_list = create_word2vec_relevant_words(list_of_quantity_words, 2)\n",
    "\n",
    "word2vec_quantity_list = list(set(word2vec_quantity_list + list_of_quantity_words))\n",
    "print(len(word2vec_quantity_list))\n",
    "print(word2vec_quantity_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Country list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89\n",
      "['frankrijk', 'dubai', 'bosnië', 'chili', 'italië', '[land]', 'oekraïne', 'ghana', 'europa', 'argentinië', 'servië', 'istanbul', 'noorwegen', 'curaçao', 'denemarken', 'rica', 'belgië', 'oostenrijk', 'jamaica', 'berlijn', 'panama', 'republiek', 'spanje', 'tanger', 'costa', 'australië', 'natal', 'bulgarije', 'amerika', 'barcelona', 'dominicaanse', 'caracas', 'hongarije', 'madrid', 'antwerpen', 'marokko', 'lima', 'suriname', 'venezuela', 'malaga', 'hamburg', 'buitenland', 'belgië)', 'ecuador', 'brazilië', 'ierland', 'zwitserland', 'iran', 'zuid-amerika', 'gevlogen', 'portugal', 'paramaribo', 'guatemala', 'peru', 'turkije', 'pakistan', 'griekenland', 'slowakije', 'luxemburg', 'canada', 'bogota', 'congo', 'londen', 'groot-brittannië', 'kinshasa', 'sydney', 'polen', 'china', 'tsjechië', 'finland', 'parijs', 'brussel', 'mexico', 'singapore', 'zweden', 'afrika', 'kenia', 'syrië', 'engeland', 'duitsland)', 'nederland', 'kroatië', 'thailand', 'roemenië', 'trinidad', 'lissabon', 'sevilla', 'warschau', 'guayaquil']\n"
     ]
    }
   ],
   "source": [
    "list_of_countries = ['duitsland', 'colombia', 'alicante']\n",
    "word2vec_country_list = create_word2vec_relevant_words(list_of_countries, 1)\n",
    "\n",
    "print(len(word2vec_country_list))\n",
    "print(word2vec_country_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create SpaCy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "345# !python -m spacy download nl_core_news_md\n",
    "nlp = spacy.load('nl_core_news_md')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file = open(\"drugs list.txt\", \"r\", encoding='utf-8')\n",
    "my_file = my_file.readlines()\n",
    "drugs_list = []\n",
    "for i in my_file:\n",
    "    drugs_list.append(i.replace('\\n', ''))\n",
    "drugs_list = list(set(drugs_list + word2vec_drug_list))\n",
    "    \n",
    "my_file = open(\"countries list.txt\", \"r\", encoding='utf-8')\n",
    "my_file = my_file.readlines()\n",
    "countries_list = []\n",
    "for i in my_file:\n",
    "    countries_list.append(i.replace('\\n', ''))\n",
    "countries_list = list(set(countries_list + word2vec_country_list))\n",
    "\n",
    "my_file = open(\"countries_to_exclude.txt\", \"r\", encoding='utf-8')\n",
    "my_file = my_file.readlines()\n",
    "countries_to_exclude = []\n",
    "for i in my_file:\n",
    "    countries_to_exclude.append(i.replace('\\n', ''))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_spacy_model():\n",
    "    # Create dict of drug pattern and quantity pattern\n",
    "    pattern_list = []\n",
    "    \n",
    "    for i in countries_to_exclude:\n",
    "        pattern_list.append({\"label\": \"EXCL\", \"pattern\": [{\"lower\": i.lower()}]})\n",
    "    \n",
    "    for i in drugs_list:\n",
    "        pattern_list.append({\"label\": \"DRUG\", \"pattern\": [{\"lower\": i.lower()}]})\n",
    "    \n",
    "#     quantity_rule = {\"label\": \"QUANTITY\", \"pattern\": [{\"IS_DIGIT\": True}, {\"LOWER\": \"gram\"}]}\n",
    "#     pattern_list.append(quantity_rule)\n",
    "    for i in word2vec_quantity_list:\n",
    "        pattern_list.append({\"label\": \"QUANTITY\", \"pattern\": [{\"IS_DIGIT\": True}, {\"LOWER\": i}]})\n",
    "        pattern_list.append({\"label\": \"QUANTITY\", \"pattern\": [{\"ENT_TYPE\": \"CARDINAL\"}, {\"LOWER\": i}]})\n",
    "    \n",
    "    for i in countries_list:\n",
    "        pattern_list.append({\"label\": \"GPE\", \"pattern\": [{\"lower\": i.replace(' ', '').lower()}]})\n",
    "    \n",
    "    # Add drug and quantity rules to the model\n",
    "    config = {\n",
    "   \"phrase_matcher_attr\": None,\n",
    "   \"validate\": True,\n",
    "   \"overwrite_ents\": True,\n",
    "   \"ent_id_sep\": \"||\",\n",
    "    }\n",
    "    ruler = nlp.add_pipe(\"entity_ruler\", config=config)\n",
    "\n",
    "    #List of Entities and Patterns\n",
    "#     patterns = drugs_ent_list\n",
    "    ruler.add_patterns(pattern_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "configure_spacy_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select cases and chunks to keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(len(sentence_list) == len(merged_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every case, split the sentences. If a sentence in a case contains a drug, a smuggle word, and a location: keep chunk and save to trafficking_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_translation_dict = {}\n",
    "countries_that_give_error = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim(user_agent = \"geoapiExercises\")\n",
    "\n",
    "def google_approves(loc):\n",
    "    if loc in country_translation_dict:\n",
    "        return True\n",
    "    if loc in countries_that_give_error:\n",
    "        return False\n",
    "    else:\n",
    "        try:\n",
    "            location = geolocator.geocode(loc, language='en')\n",
    "            country_name = location.raw['display_name'].split(',')[-1]\n",
    "            country_translation_dict[loc] = country_name\n",
    "            return True\n",
    "        except:\n",
    "            print(f\"{loc} is not a location.\")\n",
    "            countries_that_give_error.append(loc)\n",
    "            return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18124\n"
     ]
    }
   ],
   "source": [
    "print(len(sentence_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Veluwerand is not a location.\n",
      "gemeente Valkenswaard is not a location.\n",
      "Medeveroordeelde is not a location.\n",
      "schuur/schuren is not a location.\n",
      "fenetylline is not a location.\n",
      "Liempde gemeente Boxtel is not a location.\n",
      "Deugdelijke is not a location.\n",
      "gemeente Nieuwkoop is not a location.\n",
      "hennephandel is not a location.\n",
      "gronddelict is not a location.\n",
      "tenaamgestelde is not a location.\n",
      "overheidscontroles is not a location.\n",
      "Fosforzuur is not a location.\n",
      "Duitland is not a location.\n",
      "gemeente Maassluis is not a location.\n",
      "gemeente Zandvoort is not a location.\n",
      "Rappange is not a location.\n",
      "gemeente Oude-IJsselstreek is not a location.\n",
      "gemeente Eindhoven is not a location.\n",
      "gemeente Mill is not a location.\n",
      "luchtafzuigingen is not a location.\n",
      "soortgevallen is not a location.\n",
      "Gokoun is not a location.\n",
      "Handhavingsprotocol is not a location.\n",
      "huisartsenjournaal is not a location.\n",
      "gemeente Alkmaar is not a location.\n",
      "rechtbank Roermond is not a location.\n",
      "Verenigd Koninkrijk.2Dat is not a location.\n",
      "stoffen/chemicaliën is not a location.\n",
      "tabletteermachine is not a location.\n",
      "narcotica is not a location.\n",
      "art.126ff is not a location.\n",
      "MDMA/MDA is not a location.\n",
      "vacumeermachines is not a location.\n",
      "naar/vanuit is not a location.\n",
      "Leuckartsynthese.18 is not a location.\n",
      "GHB-gebruik is not a location.\n",
      "drugs-labs is not a location.\n",
      "Processtap is not a location.\n",
      "gemeente Geldrop-Mierlo is not a location.\n",
      "Australisch Wetboek van is not a location.\n",
      "Lysergide is not a location.\n",
      "Leuckart-procedure106 is not a location.\n",
      "Kokosnotenarrest is not a location.\n",
      "omstandigheden”24 is not a location.\n",
      "natriumformiaat is not a location.\n",
      "ammoniumformiaat is not a location.\n",
      "kilohandelaren is not a location.\n",
      "gemeente Vlissingen is not a location.\n",
      "gedeald is not a location.\n",
      "LFO-rapport is not a location.\n",
      "koperdiefstallen is not a location.\n",
      "gemeente Middelburug is not a location.\n",
      "afvaldumpingen is not a location.\n",
      "pleegperiode is not a location.\n",
      "Douanewetgeving is not a location.\n",
      "N-ethylMDA is not a location.\n",
      "Inositol is not a location.\n",
      "middelen-grondstoffen is not a location.\n",
      "PiperylMethylKeton is not a location.\n",
      "mutatieverslag is not a location.\n",
      "Florida the defendants is not a location.\n",
      "XTC-gebruik is not a location.\n",
      "N-formyl is not a location.\n",
      "s-Hertogenbosch halveren is not a location.\n",
      "aangehouden.3 is not a location.\n",
      "Platinumoxide is not a location.\n",
      "Magnesiumstearaat is not a location.\n",
      "Luckartmethode is not a location.\n",
      "s-Herto¬gen¬bosch is not a location.\n",
      "Zeeland2 is not a location.\n",
      "Amsterdam3 is not a location.\n",
      "sofdrugscircuit is not a location.\n",
      "Leukartmethode is not a location.\n",
      "geproduceerd.12 is not a location.\n",
      "dl-metamfetamine is not a location.\n",
      "sulfaatzout is not a location.\n",
      "Arnhem Elst gemeente Overbetuwe is not a location.\n",
      "Ressen gemeente Lingewaard is not a location.\n",
      "10-06-2017 is not a location.\n",
      "telefoontaps is not a location.\n",
      "kolomdistilleerpijp is not a location.\n",
      "vakantie-)huisje is not a location.\n",
      "Alcapharm is not a location.\n",
      "gamma-butyrolacton is not a location.\n",
      "aanschaf/overdracht is not a location.\n",
      "Colombiaan is not a location.\n",
      "gearresteerd128 is not a location.\n",
      "A-G Wortel is not a location.\n",
      "noscapine is not a location.\n",
      "niet-civiele is not a location.\n",
      "hasjtransport is not a location.\n",
      "onderzoeksbevel is not a location.\n",
      "Zevenaar Rijen is not a location.\n",
      "=) is not a location.\n",
      "verdachte].84 is not a location.\n",
      "Panamees is not a location.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "relevant_chunk_list = []\n",
    "ecli_list = []\n",
    "\n",
    "for index, case in enumerate(sentence_list):\n",
    "    chunk_list = []\n",
    "    trafficking_related = False\n",
    "    for chunk in case:\n",
    "        word_list = [x for x in chunk.lower().rstrip().replace('.', '').split(' ') if len(x)>0]\n",
    "        if any(drug in word_list for drug in word2vec_drug_list) and any(smuggle_word in word_list for smuggle_word in word2vec_smuggle_list):\n",
    "            ents = nlp(chunk).ents\n",
    "            if any(ent.label_ == \"GPE\" for ent in ents):\n",
    "                stop = False\n",
    "                for ent in ents:\n",
    "                    if not stop and ent.label_ == \"GPE\" and google_approves(ent.text):\n",
    "                        trafficking_related = True\n",
    "                        chunk_list.append(chunk)\n",
    "                        stop = True\n",
    "    if trafficking_related:\n",
    "        relevant_chunk_list.append(chunk_list)\n",
    "        ecli_list.append(merged_df.iloc[index]['id'].replace('-', ':'))\n",
    "\n",
    "trafficking_df = pd.DataFrame({'id': pd.Series(ecli_list), 'chunks': pd.Series(relevant_chunk_list)})  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2223 cases kept from original 18124 cases.\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(trafficking_df)} cases kept from original {len(merged_df)} cases.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_chunk_list = []\n",
    "ecli_list = []\n",
    "\n",
    "for index, case in enumerate(sentence_list):\n",
    "    chunk_list = []\n",
    "    trafficking_related = False\n",
    "    for chunk in case:\n",
    "        word_list = [x for x in chunk.lower().rstrip().replace('.', '').split(' ') if len(x)>0]\n",
    "        if any(drug in word_list for drug in word2vec_drug_list) and any(smuggle_word in word_list for smuggle_word in word2vec_smuggle_list):\n",
    "            ents = nlp(chunk).ents\n",
    "            if any(ent.label_ == \"GPE\" or ent.label_ == \"LOC\" for ent in ents):\n",
    "                trafficking_related = True\n",
    "                chunk_list.append(chunk)\n",
    "    if trafficking_related:\n",
    "        relevant_chunk_list.append(chunk_list)\n",
    "        ecli_list.append(merged_df.iloc[index]['id'].replace('-', ':'))\n",
    "\n",
    "trafficking_df = pd.DataFrame({'id': pd.Series(ecli_list), 'chunks': pd.Series(relevant_chunk_list)})  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2355 cases kept from original 18124 cases.\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(trafficking_df)} cases kept from original {len(merged_df)} cases.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create rule-based NER & POS tagging model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def extract_chunk_info(txt):\n",
    "    source_country = None\n",
    "    total_info = []\n",
    "    for token in nlp(txt):\n",
    "        info = {}\n",
    "        drug_info = {}\n",
    "        countries = []\n",
    "        \n",
    "        if token.ent_type_ == \"DRUG\":\n",
    "            info = {\"drug\": token.text}\n",
    "            \n",
    "            ## Get source and destination\n",
    "            for ancestor in token.ancestors:\n",
    "                for nephew in ancestor.children:\n",
    "                    if nephew.ent_type_ == \"GPE\" or nephew.ent_type_ == \"LOC\":\n",
    "                        countries.append(nephew)\n",
    "                        for child in nephew.children:\n",
    "                            if child.dep_ == \"conj\" and child.ent_type_ == \"GPE\" or child.ent_type_ == \"LOC\":\n",
    "                                countries.append(child.text)\n",
    "                            elif child.pos_ == \"ADP\" and child.dep_ == \"case\":\n",
    "                                adj = child.text\n",
    "            if len(countries) > 0 :\n",
    "                try:\n",
    "                    info[adj] = countries\n",
    "                except:\n",
    "                    info['land'] = countries\n",
    "                        \n",
    "            ## Get volume\n",
    "            for ancestors in token.ancestors:\n",
    "                for nephew in ancestors.children:\n",
    "                    if nephew.ent_type_ == \"QUANTITY\" or nephew.ent_type_ == \"CARDINAL\":\n",
    "                        for second_nephew in nephew.children:\n",
    "                            if second_nephew.is_digit != nephew.is_digit:\n",
    "                                if second_nephew.is_digit:\n",
    "                                    info['volume'] = second_nephew.text\n",
    "                                    info['volume_type'] = nephew.text\n",
    "                                else:\n",
    "                                    info['volume'] = nephew.text\n",
    "                                    info['volume_type'] = second_nephew.text\n",
    "            if 'volume' not in info:\n",
    "                for child in token.children:\n",
    "                    if (child.dep_ == \"det\" and child.like_num) or (child.dep_ == \"nummod\"):\n",
    "                        info['volume'] = child.text\n",
    "                                \n",
    "        if len(info) > 1:\n",
    "#             print(info)\n",
    "            total_info.append(info)\n",
    "    return total_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get linguistic distance between token a and token b. After iter 10 it is deemed a too far distance.\n",
    "def get_linguistic_distance(a, b):\n",
    "    tokens_to_consider = [b]\n",
    "    found = False\n",
    "    iters = 0\n",
    "    while not found:\n",
    "        for token in tokens_to_consider:\n",
    "            tokens_to_add = []\n",
    "            for ancestor in token.ancestors:\n",
    "                if ancestor not in tokens_to_add and ancestor not in tokens_to_consider:\n",
    "                    tokens_to_add.append(ancestor)\n",
    "            for child in token.children:\n",
    "                if child not in tokens_to_add and child not in tokens_to_consider:\n",
    "                    tokens_to_add.append(child)\n",
    "            tokens_to_consider = tokens_to_consider + tokens_to_add\n",
    "        for x in tokens_to_consider:\n",
    "            if a.orth == x.orth:\n",
    "                found = True\n",
    "        iters += 1\n",
    "        if iters == 10:\n",
    "            found = True\n",
    "    return iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adposition_from_loc(token):\n",
    "    for child in token.children:\n",
    "        if child.pos_ == \"ADP\" and child.dep_ == \"case\":\n",
    "            return child.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_chunk_info(txt):\n",
    "    result = {}\n",
    "    print('START CHUNK')\n",
    "    for token in nlp(txt):\n",
    "        if token.ent_type_ == \"DRUG\":\n",
    "            print(f\" \\n Extracting info for {token.text}.\")\n",
    "            drug_info = extract_info_from_drug(token, txt)\n",
    "            result[token.text] = drug_info\n",
    "    return result\n",
    "            \n",
    "adj_list = []          \n",
    "def extract_info_from_drug(drug, txt):\n",
    "    volumes = []\n",
    "    locations = {}\n",
    "    irrelevant_locations = []\n",
    "    for token in nlp(txt):\n",
    "        \n",
    "        # Extract countries\n",
    "        if token.ent_type_ == \"GPE\":\n",
    "            dist = get_linguistic_distance(drug, token)\n",
    "#             if dist < 15:\n",
    "            adj = get_adposition_from_loc(token)\n",
    "            print(f\"    {adj}: {token.text}, dist: {dist}, conj: {token.conjuncts}\")\n",
    "            locs = [token.text]\n",
    "            for loc in token.conjuncts:\n",
    "                locs.append(loc.text)\n",
    "            if adj not in locations:\n",
    "                locations[adj] = locs\n",
    "                if adj not in adj_list:\n",
    "                    adj_list.append(adj)\n",
    "            else:\n",
    "                for loc in locs:\n",
    "                    if loc not in locations[adj]:\n",
    "                        locations[adj].append(loc)\n",
    "#             else:\n",
    "#                 irrelevant_locations.append(token.text)\n",
    "#                 print(f\"{token.text} is irrelevant.\")\n",
    "        \n",
    "        # Extract volume\n",
    "        if token.ent_type_ == \"QUANTITY\":\n",
    "            volume = {}\n",
    "            dist = get_linguistic_distance(drug, token)\n",
    "            second_token = \"\"\n",
    "#             if dist < 10:\n",
    "            quantity = {}\n",
    "            for ancestor in token.ancestors:\n",
    "                if ancestor.ent_type_ == \"QUANTITY\":\n",
    "                    second_token = ancestor\n",
    "            for child in token.children:\n",
    "                if child.ent_type_ == \"QUANTITY\":\n",
    "                    second_token = child\n",
    "\n",
    "            ## Decide volume and volume_type\n",
    "            if not isinstance(second_token, str):\n",
    "                if nlp(token.text)[0].ent_type_ == \"CARDINAL\":\n",
    "                    volume['volume'] = token.text\n",
    "                    volume['volume_type'] = second_token.text\n",
    "                    volume['dist'] = dist\n",
    "                elif nlp(second_token.text)[0].ent_type_ == \"CARDINAL\":\n",
    "                    volume['volume'] = second_token.text\n",
    "                    volume['volume_type'] = token.text\n",
    "                    volume['dist'] = dist\n",
    "\n",
    "                #Only append when not already in volumes\n",
    "                if volume not in volumes:\n",
    "                    volumes.append(volume)\n",
    "    #             else:\n",
    "    #                 print(f\"{token.text} is irrelevant.\")\n",
    "                \n",
    "        \n",
    "        \n",
    "            \n",
    "    print(volumes)\n",
    "\n",
    "    result = {}\n",
    "    if bool(locations):\n",
    "        result['locations'] = locations\n",
    "#     if len(volumes) > 0:\n",
    "    result[\"volume\"] = volumes\n",
    "    if len(irrelevant_locations) > 0:\n",
    "        result[\"irrelevant_locations\"] = irrelevant_locations\n",
    "    \n",
    "    return result\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_chunk_info_without_log(txt):\n",
    "    result = {}\n",
    "    for token in nlp(txt):\n",
    "        if token.ent_type_ == \"DRUG\":\n",
    "            drug_info = extract_info_from_drug_without_log(token, txt)\n",
    "            result[token.text] = drug_info\n",
    "    return result\n",
    "            \n",
    "adj_list = []          \n",
    "def extract_info_from_drug_without_log(drug, txt):\n",
    "    volumes = []\n",
    "    locations = {}\n",
    "    irrelevant_locations = []\n",
    "    for token in nlp(txt):\n",
    "        \n",
    "        # Extract countries\n",
    "        if token.ent_type_ == \"GPE\":\n",
    "            dist = get_linguistic_distance(drug, token)\n",
    "#             if dist < 15:\n",
    "            adj = get_adposition_from_loc(token)\n",
    "            locs = [token.text]\n",
    "            for loc in token.conjuncts:\n",
    "                locs.append(loc.text)\n",
    "            if adj not in locations:\n",
    "                locations[adj] = locs\n",
    "                if adj not in adj_list:\n",
    "                    adj_list.append(adj)\n",
    "            else:\n",
    "                for loc in locs:\n",
    "                    if loc not in locations[adj]:\n",
    "                        locations[adj].append(loc)\n",
    "#             else:\n",
    "#                 irrelevant_locations.append(token.text)\n",
    "#                 print(f\"{token.text} is irrelevant.\")\n",
    "        \n",
    "        # Extract volume\n",
    "        if token.ent_type_ == \"QUANTITY\":\n",
    "            volume = {}\n",
    "            dist = get_linguistic_distance(drug, token)\n",
    "            second_token = \"\"\n",
    "#             if dist < 10:\n",
    "            quantity = {}\n",
    "            for ancestor in token.ancestors:\n",
    "                if ancestor.ent_type_ == \"QUANTITY\":\n",
    "                    second_token = ancestor\n",
    "            for child in token.children:\n",
    "                if child.ent_type_ == \"QUANTITY\":\n",
    "                    second_token = child\n",
    "\n",
    "            ## Decide volume and volume_type\n",
    "            if not isinstance(second_token, str):\n",
    "                if nlp(token.text)[0].ent_type_ == \"CARDINAL\":\n",
    "                    volume['volume'] = token.text\n",
    "                    volume['volume_type'] = second_token.text\n",
    "                    volume['dist'] = dist\n",
    "                elif nlp(second_token.text)[0].ent_type_ == \"CARDINAL\":\n",
    "                    volume['volume'] = second_token.text\n",
    "                    volume['volume_type'] = token.text\n",
    "                    volume['dist'] = dist\n",
    "\n",
    "                #Only append when not already in volumes\n",
    "                if volume not in volumes:\n",
    "                    volumes.append(volume)\n",
    "    #             else:\n",
    "    #                 print(f\"{token.text} is irrelevant.\")\n",
    "                \n",
    "        \n",
    "        \n",
    "            \n",
    "\n",
    "    result = {}\n",
    "    if bool(locations):\n",
    "        result['locations'] = locations\n",
    "#     if len(volumes) > 0:\n",
    "    result[\"volume\"] = volumes\n",
    "    if len(irrelevant_locations) > 0:\n",
    "        result[\"irrelevant_locations\"] = irrelevant_locations\n",
    "    \n",
    "    return result\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuse_chunks(chunks): \n",
    "    # Loop through chunks\n",
    "    drug_dict = {}\n",
    "    for chunk in chunks:\n",
    "        chunk_info = extract_chunk_info_without_log(chunk)\n",
    "\n",
    "        # Loop through drugs\n",
    "        if chunk_info is not None:\n",
    "            for drug in chunk_info:\n",
    "                lowerdrug = drug.lower()\n",
    "                if lowerdrug not in drug_dict:\n",
    "                    drug_dict[lowerdrug] = {'locations': [], 'volumes': []}\n",
    "                if len(chunk_info[drug]['volume']) > 0:\n",
    "                    drug_dict[lowerdrug]['volumes'].append(chunk_info[drug]['volume'])\n",
    "                if 'locations' in chunk_info[drug]:\n",
    "                    drug_dict[lowerdrug]['locations'].append(chunk_info[drug]['locations'])\n",
    "    return drug_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuse_locations(fused_chunks):\n",
    "    for drug in fused_chunks:\n",
    "        adjectives = {}\n",
    "        for location_entry in fused_chunks[drug]['locations']:\n",
    "            for adjective in location_entry:\n",
    "                if adjective not in adjectives:\n",
    "                    adjectives[adjective] = []\n",
    "                for country in location_entry[adjective]:\n",
    "                    if country not in adjectives[adjective]:\n",
    "                        adjectives[adjective].append(country)\n",
    "        fused_chunks[drug]['locations'] = adjectives\n",
    "    return fused_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuse_volumes(fused_locations):\n",
    "    for drug in fused_locations:\n",
    "        final_volume = {}\n",
    "        dist = 100\n",
    "        for volumes in fused_locations[drug]['volumes']:\n",
    "            if len(volumes) > 0:\n",
    "                for volume in volumes:\n",
    "                    if 'dist' in volume:\n",
    "                        if volume['dist'] < dist:\n",
    "                            dist = volume['dist']\n",
    "                            final_volume = volume\n",
    "        fused_locations[drug]['volumes'] = final_volume\n",
    "        return fused_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# country_translation_dict = {}\n",
    "# countries_that_give_error = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_locations(data):\n",
    "    geolocator = Nominatim(user_agent = \"geoapiExercises\")\n",
    "    if data is not None:\n",
    "        for drug in data:\n",
    "            if 'locations' in data[drug]:\n",
    "                data[drug]['original_locations'] = data[drug]['locations'].copy()\n",
    "                for adjective in data[drug]['locations']:\n",
    "                    country_list = []\n",
    "                    locations = data[drug]['locations'][adjective]\n",
    "                    for loc in locations:\n",
    "                        if loc not in country_translation_dict and loc not in countries_that_give_error:    \n",
    "                            try:\n",
    "                                location = geolocator.geocode(loc, language='en')\n",
    "                                country_name = location.raw['display_name'].split(',')[-1]\n",
    "                                country_translation_dict[loc] = country_name\n",
    "                                if country_name not in country_list:\n",
    "                                    country_list.append(country_name)\n",
    "                            except Exception as e:\n",
    "                                print(f\"{loc} is not a location.\")\n",
    "                                countries_that_give_error.append(loc)\n",
    "                        else:\n",
    "                            if loc in country_translation_dict:\n",
    "                                if country_translation_dict[loc] not in country_list:\n",
    "                                    country_list.append(country_translation_dict[loc])\n",
    "                    data[drug]['locations'][adjective] = country_list\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_location_directions(data):\n",
    "    from_adjectives = ['uit', 'vanuit', 'van']\n",
    "    to_adjectives = ['naar']\n",
    "    via_adjectives = ['via']\n",
    "    if data is not None:\n",
    "        for drug in data:\n",
    "            fromlocs = []\n",
    "            tolocs = []\n",
    "            vialocs = []\n",
    "            locations = data[drug]['locations']\n",
    "            for adj in locations:\n",
    "                if adj in from_adjectives:\n",
    "                    for loc in locations[adj]:\n",
    "                        if loc not in fromlocs:\n",
    "                            fromlocs.append(loc)\n",
    "                elif adj in to_adjectives:\n",
    "                    for loc in locations[adj]:\n",
    "                        if loc not in tolocs:\n",
    "                            tolocs.append(loc)\n",
    "                elif adj in via_adjectives:\n",
    "                    for loc in locations[adj]:\n",
    "                        if loc not in vialocs:\n",
    "                            vialocs.append(loc)\n",
    "\n",
    "            data[drug]['locations'] = {'from': fromlocs, 'to': tolocs, 'via': vialocs}\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [97]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#     print(id)\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m     fused_chunks \u001b[38;5;241m=\u001b[39m \u001b[43mfuse_chunks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mchunks\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     fused_locations \u001b[38;5;241m=\u001b[39m fuse_locations(fused_chunks)\n\u001b[0;32m     13\u001b[0m     fused_volumes \u001b[38;5;241m=\u001b[39m fuse_volumes(fused_locations)\n",
      "Input \u001b[1;32mIn [60]\u001b[0m, in \u001b[0;36mfuse_chunks\u001b[1;34m(chunks)\u001b[0m\n\u001b[0;32m      3\u001b[0m drug_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunks:\n\u001b[1;32m----> 5\u001b[0m     chunk_info \u001b[38;5;241m=\u001b[39m \u001b[43mextract_chunk_info_without_log\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# Loop through drugs\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chunk_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "Input \u001b[1;32mIn [59]\u001b[0m, in \u001b[0;36mextract_chunk_info_without_log\u001b[1;34m(txt)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_chunk_info_without_log\u001b[39m(txt):\n\u001b[0;32m      2\u001b[0m     result \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m \u001b[43mnlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtxt\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m token\u001b[38;5;241m.\u001b[39ment_type_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDRUG\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m      5\u001b[0m             drug_info \u001b[38;5;241m=\u001b[39m extract_info_from_drug_without_log(token, txt)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\spacy\\language.py:1017\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m   1015\u001b[0m     error_handler \u001b[38;5;241m=\u001b[39m proc\u001b[38;5;241m.\u001b[39mget_error_handler()\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1017\u001b[0m     doc \u001b[38;5;241m=\u001b[39m proc(doc, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcomponent_cfg\u001b[38;5;241m.\u001b[39mget(name, {}))  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m   1018\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1019\u001b[0m     \u001b[38;5;66;03m# This typically happens if a component is not initialized\u001b[39;00m\n\u001b[0;32m   1020\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE109\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\spacy\\pipeline\\trainable_pipe.pyx:52\u001b[0m, in \u001b[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\spacy\\pipeline\\transition_parser.pyx:250\u001b[0m, in \u001b[0;36mspacy.pipeline.transition_parser.Parser.predict\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\spacy\\pipeline\\transition_parser.pyx:265\u001b[0m, in \u001b[0;36mspacy.pipeline.transition_parser.Parser.greedy_parse\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\thinc\\model.py:315\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m OutT:\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;124;03m\"\"\"Call the model's `forward` function with `is_train=False`, and return\u001b[39;00m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;124;03m    only the output, instead of the `(output, callback)` tuple.\u001b[39;00m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\spacy\\ml\\tb_framework.py:33\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(model, X, is_train):\n\u001b[1;32m---> 33\u001b[0m     step_model \u001b[38;5;241m=\u001b[39m \u001b[43mParserStepModel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43munseen_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43munseen_classes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_upper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhas_upper\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m step_model, step_model\u001b[38;5;241m.\u001b[39mfinish_steps\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\spacy\\ml\\parser_model.pyx:216\u001b[0m, in \u001b[0;36mspacy.ml.parser_model.ParserStepModel.__init__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\thinc\\model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\thinc\\layers\\chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\thinc\\model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\thinc\\layers\\linear.py:35\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     33\u001b[0m W \u001b[38;5;241m=\u001b[39m cast(Floats2d, model\u001b[38;5;241m.\u001b[39mget_param(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m     34\u001b[0m b \u001b[38;5;241m=\u001b[39m cast(Floats1d, model\u001b[38;5;241m.\u001b[39mget_param(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m---> 35\u001b[0m Y \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgemm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrans2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m Y \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m b\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackprop\u001b[39m(dY: OutT) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m InT:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "final_df = pd.DataFrame(columns=['ecli', 'drug', 'relevant_countries'])    \n",
    "\n",
    "    \n",
    "    \n",
    "from geopy.geocoders import Nominatim\n",
    "                        \n",
    "for index, row in trafficking_df.iterrows():\n",
    "    id = row['id']\n",
    "#     print(id)\n",
    "    \n",
    "    fused_chunks = fuse_chunks(row['chunks'])\n",
    "    fused_locations = fuse_locations(fused_chunks)\n",
    "    fused_volumes = fuse_volumes(fused_locations)\n",
    "    translated_locations = translate_locations(fused_volumes)\n",
    "#     location_directions = get_location_directions(translated_locations)\n",
    "    \n",
    "#     print(location_directions)\n",
    "    if translated_locations is not None:\n",
    "        for drug in translated_locations:\n",
    "            relevant_countries = []\n",
    "            curr = translated_locations[drug]\n",
    "            for adjective in curr['locations']:\n",
    "                locs = curr['locations'][adjective]\n",
    "                for loc in locs:\n",
    "                    if loc not in relevant_countries:\n",
    "                        relevant_countries.append(loc)\n",
    "                    \n",
    "            \n",
    "            \n",
    "            row = {'ecli': id, 'drug': drug, 'relevant_countries': relevant_countries}\n",
    "            final_df = final_df.append(row, ignore_index=True)\n",
    "        \n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Morocco': 73, 'Argentina': 28, 'Jamaica': 1, 'France': 145, 'Belgium': 605, 'Germany': 450, 'UnitedStates': 153, 'UnitedKingdom': 379, 'Italy': 109, 'Sweden': 112, 'Turkey': 63, 'Kyrgyzstan': 11, 'Norway': 51, 'Spain': 161, 'China': 37, 'DominicanRepublic': 63, 'Suriname': 55, 'SouthAmerica': 83, 'Ecuador': 30, 'BosniaandHerzegovina': 6, 'Brazil': 50, 'Peru': 21, 'Europe': 32, 'Iran': 5, 'Colombia': 82, 'Haiti': 6, 'Poland': 84, 'Pakistan': 29, 'Asia': 5, 'Israel': 5, 'Denmark': 36, 'Finland': 19, 'Thailand': 12, 'Australia': 50, 'TrinidadandTobago': 9, 'Croatia': 2, 'Austria': 20, 'Canada': 8, 'Mexico': 16, 'India': 11, 'Philippines': 10, 'Czechia': 9, 'Hungary': 14, 'Barbados': 1, 'Romania': 17, 'Portugal': 15, 'Bolivia': 3, 'Anchorage': 6, 'Benin': 1, 'Luxembourg': 6, 'Namibia': 4, 'Ireland': 22, 'Slovakia': 5, 'Switzerland': 42, 'IsleofMan': 2, 'SaudiArabia': 4, 'DemocraticRepublicoftheCongo': 11, 'Japan': 11, 'Chile': 16, 'Ethiopia': 9, 'Kenya': 12, 'Ghana': 5, 'Iceland': 4, 'Malawi': 19, 'SouthAfrica': 9, 'UnitedArabEmirates': 1, 'Panama': 18, 'TheGambia': 1, 'Cuba': 2, 'Russia': 4, 'Slovenia': 1, 'Venezuela': 19, 'Laos': 1, 'BurkinaFaso': 2, 'Africa': 3, 'Mongolia': 1, 'TheBahamas': 4, 'Angola': 1, 'Afghanistan': 1, 'Libya': 1, 'Liechtenstein': 1, 'Ukraine': 7, 'Tunisia': 1, 'Greece': 1, \"Côted'Ivoire\": 1, 'Paraguay': 1, 'Malta': 2, 'Bulgaria': 4, 'Egypt': 1, 'Senegal': 1, 'Rwanda': 1, 'Indonesia': 1, 'Albania': 3, 'NewZealand': 2, 'Lithuania': 1, 'Nigeria': 1, 'Liberia': 1, 'Honduras': 2, 'Guyana': 1}\n"
     ]
    }
   ],
   "source": [
    "vectorcounts = {}\n",
    "\n",
    "for index, row in final_df.iterrows():\n",
    "    locs = row['relevant_countries']\n",
    "    for loc in locs:\n",
    "        if loc != \"Netherlands\":\n",
    "            if loc not in vectorcounts:\n",
    "                vectorcounts[loc] = 0\n",
    "            vectorcounts[loc] = vectorcounts[loc] + 1\n",
    "            \n",
    "print(vectorcounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "geo": "geo",
         "hovertemplate": "<b>%{hovertext}</b><br><br>iso_alpha=%{location}<br>count=%{z}<extra></extra>",
         "hovertext": [
          "Afghanistan",
          "Albania",
          "Algeria",
          "Angola",
          "Argentina",
          "Australia",
          "Austria",
          "Bahrain",
          "Bangladesh",
          "Belgium",
          "Benin",
          "Bolivia",
          "Bosnia and Herzegovina",
          "Botswana",
          "Brazil",
          "Bulgaria",
          "Burkina Faso",
          "Burundi",
          "Cambodia",
          "Cameroon",
          "Canada",
          "Central African Republic",
          "Chad",
          "Chile",
          "China",
          "Colombia",
          "Comoros",
          "Congo, Dem. Rep.",
          "Congo, Rep.",
          "Costa Rica",
          "Cote d'Ivoire",
          "Croatia",
          "Cuba",
          "Czech Republic",
          "Denmark",
          "Djibouti",
          "Dominican Republic",
          "Ecuador",
          "Egypt",
          "El Salvador",
          "Equatorial Guinea",
          "Eritrea",
          "Ethiopia",
          "Finland",
          "France",
          "Gabon",
          "Gambia",
          "Germany",
          "Ghana",
          "Greece",
          "Guatemala",
          "Guinea",
          "Guinea-Bissau",
          "Haiti",
          "Honduras",
          "Hong Kong, China",
          "Hungary",
          "Iceland",
          "India",
          "Indonesia",
          "Iran",
          "Iraq",
          "Ireland",
          "Israel",
          "Italy",
          "Jamaica",
          "Japan",
          "Jordan",
          "Kenya",
          "Korea, Dem. Rep.",
          "Korea, Rep.",
          "Kuwait",
          "Lebanon",
          "Lesotho",
          "Liberia",
          "Libya",
          "Madagascar",
          "Malawi",
          "Malaysia",
          "Mali",
          "Mauritania",
          "Mauritius",
          "Mexico",
          "Mongolia",
          "Montenegro",
          "Morocco",
          "Mozambique",
          "Myanmar",
          "Namibia",
          "Nepal",
          "Netherlands",
          "New Zealand",
          "Nicaragua",
          "Niger",
          "Nigeria",
          "Norway",
          "Oman",
          "Pakistan",
          "Panama",
          "Paraguay",
          "Peru",
          "Philippines",
          "Poland",
          "Portugal",
          "Puerto Rico",
          "Reunion",
          "Romania",
          "Rwanda",
          "Sao Tome and Principe",
          "Saudi Arabia",
          "Senegal",
          "Serbia",
          "Sierra Leone",
          "Singapore",
          "Slovak Republic",
          "Slovenia",
          "Somalia",
          "South Africa",
          "Spain",
          "Sri Lanka",
          "Sudan",
          "Swaziland",
          "Sweden",
          "Switzerland",
          "Syria",
          "Taiwan",
          "Tanzania",
          "Thailand",
          "Togo",
          "Trinidad and Tobago",
          "Tunisia",
          "Turkey",
          "Uganda",
          "United Kingdom",
          "United States",
          "Uruguay",
          "Venezuela",
          "Vietnam",
          "West Bank and Gaza",
          "Yemen, Rep.",
          "Zambia",
          "Zimbabwe"
         ],
         "locations": [
          "AFG",
          "ALB",
          "DZA",
          "AGO",
          "ARG",
          "AUS",
          "AUT",
          "BHR",
          "BGD",
          "BEL",
          "BEN",
          "BOL",
          "BIH",
          "BWA",
          "BRA",
          "BGR",
          "BFA",
          "BDI",
          "KHM",
          "CMR",
          "CAN",
          "CAF",
          "TCD",
          "CHL",
          "CHN",
          "COL",
          "COM",
          "COD",
          "COG",
          "CRI",
          "CIV",
          "HRV",
          "CUB",
          "CZE",
          "DNK",
          "DJI",
          "DOM",
          "ECU",
          "EGY",
          "SLV",
          "GNQ",
          "ERI",
          "ETH",
          "FIN",
          "FRA",
          "GAB",
          "GMB",
          "DEU",
          "GHA",
          "GRC",
          "GTM",
          "GIN",
          "GNB",
          "HTI",
          "HND",
          "HKG",
          "HUN",
          "ISL",
          "IND",
          "IDN",
          "IRN",
          "IRQ",
          "IRL",
          "ISR",
          "ITA",
          "JAM",
          "JPN",
          "JOR",
          "KEN",
          "KOR",
          "KOR",
          "KWT",
          "LBN",
          "LSO",
          "LBR",
          "LBY",
          "MDG",
          "MWI",
          "MYS",
          "MLI",
          "MRT",
          "MUS",
          "MEX",
          "MNG",
          "MNE",
          "MAR",
          "MOZ",
          "MMR",
          "NAM",
          "NPL",
          "NLD",
          "NZL",
          "NIC",
          "NER",
          "NGA",
          "NOR",
          "OMN",
          "PAK",
          "PAN",
          "PRY",
          "PER",
          "PHL",
          "POL",
          "PRT",
          "PRI",
          "REU",
          "ROU",
          "RWA",
          "STP",
          "SAU",
          "SEN",
          "SRB",
          "SLE",
          "SGP",
          "SVK",
          "SVN",
          "SOM",
          "ZAF",
          "ESP",
          "LKA",
          "SDN",
          "SWZ",
          "SWE",
          "CHE",
          "SYR",
          "TWN",
          "TZA",
          "THA",
          "TGO",
          "TTO",
          "TUN",
          "TUR",
          "UGA",
          "GBR",
          "USA",
          "URY",
          "VEN",
          "VNM",
          "PSE",
          "YEM",
          "ZMB",
          "ZWE"
         ],
         "name": "",
         "type": "choropleth",
         "z": [
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          21601,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          17024,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          13096,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          18314,
          139421,
          null,
          null,
          null,
          null,
          null,
          null,
          null
         ]
        }
       ],
       "layout": {
        "coloraxis": {
         "colorbar": {
          "title": {
           "text": "count"
          }
         },
         "colorscale": [
          [
           0,
           "#0d0887"
          ],
          [
           0.1111111111111111,
           "#46039f"
          ],
          [
           0.2222222222222222,
           "#7201a8"
          ],
          [
           0.3333333333333333,
           "#9c179e"
          ],
          [
           0.4444444444444444,
           "#bd3786"
          ],
          [
           0.5555555555555556,
           "#d8576b"
          ],
          [
           0.6666666666666666,
           "#ed7953"
          ],
          [
           0.7777777777777778,
           "#fb9f3a"
          ],
          [
           0.8888888888888888,
           "#fdca26"
          ],
          [
           1,
           "#f0f921"
          ]
         ]
        },
        "geo": {
         "center": {},
         "domain": {
          "x": [
           0,
           1
          ],
          "y": [
           0,
           1
          ]
         }
        },
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"d2d28e23-995e-4122-9678-fc9292214f6d\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"d2d28e23-995e-4122-9678-fc9292214f6d\")) {                    Plotly.newPlot(                        \"d2d28e23-995e-4122-9678-fc9292214f6d\",                        [{\"coloraxis\":\"coloraxis\",\"geo\":\"geo\",\"hovertemplate\":\"<b>%{hovertext}</b><br><br>iso_alpha=%{location}<br>count=%{z}<extra></extra>\",\"hovertext\":[\"Afghanistan\",\"Albania\",\"Algeria\",\"Angola\",\"Argentina\",\"Australia\",\"Austria\",\"Bahrain\",\"Bangladesh\",\"Belgium\",\"Benin\",\"Bolivia\",\"Bosnia and Herzegovina\",\"Botswana\",\"Brazil\",\"Bulgaria\",\"Burkina Faso\",\"Burundi\",\"Cambodia\",\"Cameroon\",\"Canada\",\"Central African Republic\",\"Chad\",\"Chile\",\"China\",\"Colombia\",\"Comoros\",\"Congo, Dem. Rep.\",\"Congo, Rep.\",\"Costa Rica\",\"Cote d'Ivoire\",\"Croatia\",\"Cuba\",\"Czech Republic\",\"Denmark\",\"Djibouti\",\"Dominican Republic\",\"Ecuador\",\"Egypt\",\"El Salvador\",\"Equatorial Guinea\",\"Eritrea\",\"Ethiopia\",\"Finland\",\"France\",\"Gabon\",\"Gambia\",\"Germany\",\"Ghana\",\"Greece\",\"Guatemala\",\"Guinea\",\"Guinea-Bissau\",\"Haiti\",\"Honduras\",\"Hong Kong, China\",\"Hungary\",\"Iceland\",\"India\",\"Indonesia\",\"Iran\",\"Iraq\",\"Ireland\",\"Israel\",\"Italy\",\"Jamaica\",\"Japan\",\"Jordan\",\"Kenya\",\"Korea, Dem. Rep.\",\"Korea, Rep.\",\"Kuwait\",\"Lebanon\",\"Lesotho\",\"Liberia\",\"Libya\",\"Madagascar\",\"Malawi\",\"Malaysia\",\"Mali\",\"Mauritania\",\"Mauritius\",\"Mexico\",\"Mongolia\",\"Montenegro\",\"Morocco\",\"Mozambique\",\"Myanmar\",\"Namibia\",\"Nepal\",\"Netherlands\",\"New Zealand\",\"Nicaragua\",\"Niger\",\"Nigeria\",\"Norway\",\"Oman\",\"Pakistan\",\"Panama\",\"Paraguay\",\"Peru\",\"Philippines\",\"Poland\",\"Portugal\",\"Puerto Rico\",\"Reunion\",\"Romania\",\"Rwanda\",\"Sao Tome and Principe\",\"Saudi Arabia\",\"Senegal\",\"Serbia\",\"Sierra Leone\",\"Singapore\",\"Slovak Republic\",\"Slovenia\",\"Somalia\",\"South Africa\",\"Spain\",\"Sri Lanka\",\"Sudan\",\"Swaziland\",\"Sweden\",\"Switzerland\",\"Syria\",\"Taiwan\",\"Tanzania\",\"Thailand\",\"Togo\",\"Trinidad and Tobago\",\"Tunisia\",\"Turkey\",\"Uganda\",\"United Kingdom\",\"United States\",\"Uruguay\",\"Venezuela\",\"Vietnam\",\"West Bank and Gaza\",\"Yemen, Rep.\",\"Zambia\",\"Zimbabwe\"],\"locations\":[\"AFG\",\"ALB\",\"DZA\",\"AGO\",\"ARG\",\"AUS\",\"AUT\",\"BHR\",\"BGD\",\"BEL\",\"BEN\",\"BOL\",\"BIH\",\"BWA\",\"BRA\",\"BGR\",\"BFA\",\"BDI\",\"KHM\",\"CMR\",\"CAN\",\"CAF\",\"TCD\",\"CHL\",\"CHN\",\"COL\",\"COM\",\"COD\",\"COG\",\"CRI\",\"CIV\",\"HRV\",\"CUB\",\"CZE\",\"DNK\",\"DJI\",\"DOM\",\"ECU\",\"EGY\",\"SLV\",\"GNQ\",\"ERI\",\"ETH\",\"FIN\",\"FRA\",\"GAB\",\"GMB\",\"DEU\",\"GHA\",\"GRC\",\"GTM\",\"GIN\",\"GNB\",\"HTI\",\"HND\",\"HKG\",\"HUN\",\"ISL\",\"IND\",\"IDN\",\"IRN\",\"IRQ\",\"IRL\",\"ISR\",\"ITA\",\"JAM\",\"JPN\",\"JOR\",\"KEN\",\"KOR\",\"KOR\",\"KWT\",\"LBN\",\"LSO\",\"LBR\",\"LBY\",\"MDG\",\"MWI\",\"MYS\",\"MLI\",\"MRT\",\"MUS\",\"MEX\",\"MNG\",\"MNE\",\"MAR\",\"MOZ\",\"MMR\",\"NAM\",\"NPL\",\"NLD\",\"NZL\",\"NIC\",\"NER\",\"NGA\",\"NOR\",\"OMN\",\"PAK\",\"PAN\",\"PRY\",\"PER\",\"PHL\",\"POL\",\"PRT\",\"PRI\",\"REU\",\"ROU\",\"RWA\",\"STP\",\"SAU\",\"SEN\",\"SRB\",\"SLE\",\"SGP\",\"SVK\",\"SVN\",\"SOM\",\"ZAF\",\"ESP\",\"LKA\",\"SDN\",\"SWZ\",\"SWE\",\"CHE\",\"SYR\",\"TWN\",\"TZA\",\"THA\",\"TGO\",\"TTO\",\"TUN\",\"TUR\",\"UGA\",\"GBR\",\"USA\",\"URY\",\"VEN\",\"VNM\",\"PSE\",\"YEM\",\"ZMB\",\"ZWE\"],\"name\":\"\",\"z\":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,21601.0,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,17024.0,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,13096.0,null,null,null,null,null,null,null,null,null,null,null,null,null,null,18314.0,139421.0,null,null,null,null,null,null,null],\"type\":\"choropleth\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"geo\":{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"center\":{}},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"count\"}},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('d2d28e23-995e-4122-9678-fc9292214f6d');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(12)\n",
    "gapminder = px.data.gapminder().query(\"year==2007\")\n",
    "#gapminder['counts'] = np.nan\n",
    "\n",
    "d = {'United States': [139421],\n",
    "    'Canada': [21601], \n",
    "    'United Kingdom': [18314],\n",
    "    'Germany': [17024],\n",
    "    'Spain': [13096]}\n",
    "\n",
    "yourdata = pd.DataFrame(d).T.reset_index()\n",
    "yourdata.columns=['country', 'count']\n",
    "\n",
    "df=pd.merge(gapminder, yourdata, how='left', on='country')\n",
    "\n",
    "fig = px.choropleth(df, locations=\"iso_alpha\",\n",
    "                    color=\"count\", \n",
    "                    hover_name=\"country\", # column to add to hover information\n",
    "                    color_continuous_scale=px.colors.sequential.Plasma)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doorzoekingen is not a location.\n",
      "zoutzuur is not a location.\n",
      "zwavelzuur is not a location.\n",
      "mierenzuur is not a location.\n",
      "diepvriezers is not a location.\n",
      "vacuümmachine is not a location.\n",
      "Neede/Borculo is not a location.\n",
      "voorhanden is not a location.\n",
      "uitblijft is not a location.\n",
      "locaties is not a location.\n",
      "medeverdachten is not a location.\n",
      "gefaciliteerd is not a location.\n",
      "gemaakt is not a location.\n",
      "vervoerd is not a location.\n",
      "1 is not a location.\n",
      "4 is not a location.\n",
      "  is not a location.\n",
      "[ is not a location.\n",
      "voorbereidingshandelingen is not a location.\n",
      "opslaglocaties is not a location.\n",
      "Verenigde is not a location.\n",
      "voorbereidings-handelingen is not a location.\n",
      "Nederlnd is not a location.\n",
      "\t is not a location.\n",
      "undercoveragenten is not a location.\n",
      "] is not a location.\n",
      "2 is not a location.\n",
      "Uitleveringsbesluit is not a location.\n",
      "Groot-Britannië is not a location.\n",
      "uitvoer is not a location.\n",
      "5 is not a location.\n",
      "Beerzeveld is not a location.\n",
      "telefoonnummers is not a location.\n",
      "Nederlandtezamen is not a location.\n",
      "medeplegen is not a location.\n",
      "pogingen is not a location.\n",
      "doorvoer is not a location.\n",
      "gevlogen is not a location.\n",
      "tezamen is not a location.\n",
      "witwassen is not a location.\n",
      "MDMA is not a location.\n",
      "amfetamine is not a location.\n",
      "afkortingen is not a location.\n",
      "verslepen is not a location.\n",
      "naderhand is not a location.\n",
      "invoer is not a location.\n",
      "Isopropylalcohol is not a location.\n",
      "    is not a location.\n",
      "calciumchloride is not a location.\n",
      "petroleumether is not a location.\n",
      "kaliumpermanganaat is not a location.\n",
      "natriumhydroxide is not a location.\n",
      "XTC-laboratorium is not a location.\n",
      "Methyleendioxy is not a location.\n",
      "vestigingsplaats is not a location.\n",
      "deelname is not a location.\n",
      "Geneefse is not a location.\n",
      "zeehavens is not a location.\n",
      "bolkoeler is not a location.\n",
      "’ is not a location.\n",
      "verplichtingen is not a location.\n",
      "handgenummerde is not a location.\n",
      "drugsopbrengsten is not a location.\n",
      "subsidiair is not a location.\n",
      "MDMA.171 is not a location.\n",
      "aangetroffen.176 is not a location.\n",
      "nutsvoorzieningen is not a location.\n",
      "retourtransport is not a location.\n",
      "Marokko/Spanje is not a location.\n",
      "hoeveelheden is not a location.\n",
      "geleden.35 is not a location.\n",
      "fishskin is not a location.\n",
      "ordeloosheid(28 is not a location.\n",
      "pleegplaats is not a location.\n",
      "2.330.000- is not a location.\n",
      "capaciteitsproblemen is not a location.\n",
      "Itot is not a location.\n",
      "Berndsen-Jansen is not a location.\n",
      "Alcobacca is not a location.\n",
      "georganiseerd/geregeld is not a location.\n",
      "ontmoetingen is not a location.\n",
      "voorbereiden is not a location.\n",
      "bevorderen is not a location.\n",
      "amfetamine.31 is not a location.\n",
      "bevindingen is not a location.\n",
      "plegen is not a location.\n",
      "9 is not a location.\n",
      "misdrijf is not a location.\n",
      "Geringe is not a location.\n",
      "hoeveelheid is not a location.\n",
      "afkomstig is not a location.\n",
      "hashtransporten is not a location.\n",
      "amtefamine is not a location.\n",
      "afspraken is not a location.\n",
      "mililiter is not a location.\n",
      "Ananassen is not a location.\n",
      "Deklading is not a location.\n",
      "hasjiesj is not a location.\n",
      "gelopen is not a location.\n",
      "Marfret is not a location.\n",
      "Peruaan is not a location.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ecli</th>\n",
       "      <th>drug</th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>via</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ECLI:NL:RBZUT:2003:AH9598</td>\n",
       "      <td>drugs</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ECLI:NL:PHR:2007:BA1113</td>\n",
       "      <td>drugs</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ECLI:NL:GHAMS:2018:2662</td>\n",
       "      <td>cocaïne</td>\n",
       "      <td>[Argentina]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ECLI:NL:RBAMS:2017:9087</td>\n",
       "      <td>cocaïne</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ECLI:NL:RBAMS:2017:9085</td>\n",
       "      <td>cocaïne</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3847</th>\n",
       "      <td>ECLI:NL:HR:1998:ZD1191</td>\n",
       "      <td>hennep</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3848</th>\n",
       "      <td>ECLI:NL:HR:1998:ZD1191</td>\n",
       "      <td>marihuana</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3849</th>\n",
       "      <td>ECLI:NL:RBNHO:2013:10924</td>\n",
       "      <td>cocaïne</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3850</th>\n",
       "      <td>ECLI:NL:GHSHE:2021:3205</td>\n",
       "      <td>cocaïne</td>\n",
       "      <td>[Netherlands, DominicanRepublic]</td>\n",
       "      <td>[DominicanRepublic]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3851</th>\n",
       "      <td>ECLI:NL:RBLIM:2018:3094</td>\n",
       "      <td>cocaïne</td>\n",
       "      <td>[DominicanRepublic, Netherlands]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3852 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           ecli       drug                              from  \\\n",
       "0     ECLI:NL:RBZUT:2003:AH9598      drugs                                []   \n",
       "1       ECLI:NL:PHR:2007:BA1113      drugs                                []   \n",
       "2       ECLI:NL:GHAMS:2018:2662    cocaïne                       [Argentina]   \n",
       "3       ECLI:NL:RBAMS:2017:9087    cocaïne                                []   \n",
       "4       ECLI:NL:RBAMS:2017:9085    cocaïne                                []   \n",
       "...                         ...        ...                               ...   \n",
       "3847     ECLI:NL:HR:1998:ZD1191     hennep                                []   \n",
       "3848     ECLI:NL:HR:1998:ZD1191  marihuana                                []   \n",
       "3849   ECLI:NL:RBNHO:2013:10924    cocaïne                                []   \n",
       "3850    ECLI:NL:GHSHE:2021:3205    cocaïne  [Netherlands, DominicanRepublic]   \n",
       "3851    ECLI:NL:RBLIM:2018:3094    cocaïne  [DominicanRepublic, Netherlands]   \n",
       "\n",
       "                       to via  \n",
       "0                      []  []  \n",
       "1                      []  []  \n",
       "2                      []  []  \n",
       "3                      []  []  \n",
       "4                      []  []  \n",
       "...                   ...  ..  \n",
       "3847                   []  []  \n",
       "3848                   []  []  \n",
       "3849                   []  []  \n",
       "3850  [DominicanRepublic]  []  \n",
       "3851                   []  []  \n",
       "\n",
       "[3852 rows x 5 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = pd.DataFrame(columns=['ecli', 'drug', 'from', 'to', 'via'])    \n",
    "\n",
    "    \n",
    "    \n",
    "from geopy.geocoders import Nominatim\n",
    "                        \n",
    "for index, row in trafficking_df.iterrows():\n",
    "    id = row['id']\n",
    "#     print(id)\n",
    "    \n",
    "    fused_chunks = fuse_chunks(row['chunks'])\n",
    "    fused_locations = fuse_locations(fused_chunks)\n",
    "    fused_volumes = fuse_volumes(fused_locations)\n",
    "    translated_locations = translate_locations(fused_volumes)\n",
    "    location_directions = get_location_directions(translated_locations)\n",
    "    \n",
    "#     print(location_directions)\n",
    "    if location_directions is not None:\n",
    "        for drug in location_directions:\n",
    "            curr = location_directions[drug]\n",
    "            fromloc = curr['locations']['from']\n",
    "            toloc = curr['locations']['to']\n",
    "            vialoc = curr['locations']['via']\n",
    "            \n",
    "            row = {'ecli': id, 'drug': drug, 'from': fromloc, 'to': toloc, 'via': vialoc}\n",
    "            final_df = final_df.append(row, ignore_index=True)\n",
    "        \n",
    "final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ecli</th>\n",
       "      <th>drug</th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>via</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ecli, drug, from, to, via]\n",
       "Index: []"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df[final_df['ecli'] == 'ECLI:NL:RBOVE:2018:4873']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Benin', 1), ('Bolivia', 1), ('UnitedArabEmirates', 1), ('Czechia', 1), ('Angola', 1), ('Liechtenstein', 1), ('Greece', 1), ('Senegal', 1), ('Nigeria', 1), ('Asia', 2), ('Norway', 2), ('Ghana', 2), ('Iran', 2), ('Ireland', 2), ('Panama', 2), ('Argentina', 3), ('Iceland', 3), ('Albania', 3), ('India', 4), ('Romania', 4), ('Kenya', 4), ('Israel', 4), ('Denmark', 4), ('Mexico', 5), ('Italy', 5), ('Chile', 5), ('Sweden', 6), ('Ukraine', 6), ('Thailand', 7), ('TrinidadandTobago', 8), ('Switzerland', 8), ('DemocraticRepublicoftheCongo', 9), ('Ethiopia', 9), ('UnitedKingdom', 12), ('Peru', 14), ('Venezuela', 14), ('Turkey', 15), ('Spain', 16), ('Ecuador', 16), ('China', 18), ('Suriname', 18), ('Germany', 20), ('France', 21), ('Pakistan', 23), ('UnitedStates', 23), ('Brazil', 26), ('Morocco', 39), ('DominicanRepublic', 53), ('Poland', 54), ('Colombia', 55), ('SouthAmerica', 67), ('Belgium', 121), ('Netherlands', 607)]\n",
      "\n",
      "\n",
      "[('Jamaica', 1), ('Hungary', 1), ('Asia', 1), ('Czechia', 1), ('Thailand', 1), ('Libya', 1), ('Chile', 1), ('Egypt', 1), ('Lithuania', 1), ('Venezuela', 1), ('Japan', 2), ('Luxembourg', 2), ('Russia', 2), ('Argentina', 2), ('Africa', 2), ('Romania', 2), ('India', 2), ('Suriname', 3), ('SouthAfrica', 3), ('DominicanRepublic', 3), ('SouthAmerica', 4), ('Canada', 5), ('Austria', 5), ('Ecuador', 6), ('Ireland', 6), ('Turkey', 7), ('Finland', 8), ('Brazil', 10), ('Portugal', 10), ('Mexico', 10), ('Switzerland', 13), ('Colombia', 14), ('Morocco', 15), ('Panama', 15), ('Poland', 17), ('Denmark', 18), ('UnitedStates', 18), ('Europe', 20), ('France', 26), ('Norway', 28), ('Australia', 33), ('Italy', 34), ('Spain', 42), ('Sweden', 73), ('Belgium', 131), ('Germany', 219), ('UnitedKingdom', 227), ('Netherlands', 415)]\n"
     ]
    }
   ],
   "source": [
    "total_from_country_dict = {}\n",
    "total_to_country_dict = {}\n",
    "\n",
    "for index, row in final_df.iterrows():\n",
    "    for i in row['from']:\n",
    "        if i not in total_from_country_dict:\n",
    "            total_from_country_dict[i] = 0\n",
    "        total_from_country_dict[i] = total_from_country_dict[i] + 1\n",
    "        \n",
    "    for i in row['to']:\n",
    "        if i not in total_to_country_dict:\n",
    "            total_to_country_dict[i] = 0\n",
    "        total_to_country_dict[i] = total_to_country_dict[i] + 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(sorted(total_from_country_dict.items(), key = lambda kv: kv[1]))\n",
    "print('\\n')\n",
    "print(sorted(total_to_country_dict.items(), key = lambda kv: kv[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United States\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "geolocator = Nominatim(user_agent = \"geoapiExercises\")\n",
    "location = geolocator.geocode(\"verenigde staten\")\n",
    "country_name = location.raw['display_name'].split(',')[-1]\n",
    "print(country_name)\n",
    "print(len(country_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get complete adjective list and country list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_adjective_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in trafficking_df.iterrows():\n",
    "    fused_chunks = fuse_chunks(row['chunks'])\n",
    "    for drug in fused_chunks:\n",
    "        locations = fused_chunks[drug]['locations']\n",
    "        for adjective in locations:\n",
    "            for adj in adjective.keys():\n",
    "                complete_adjective_list.append(adj)\n",
    "            \n",
    "                \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8049"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(complete_adjective_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ten',\n",
       " 'tussen',\n",
       " 'Op',\n",
       " 'inzake',\n",
       " 'buiten',\n",
       " 'aan',\n",
       " 'onder',\n",
       " 'nabij',\n",
       " 'langs',\n",
       " 'over',\n",
       " 'vanaf',\n",
       " 'van',\n",
       " 'naar',\n",
       " 'volgens',\n",
       " None,\n",
       " 'rondom',\n",
       " 'jegens',\n",
       " 'per',\n",
       " 'binnen',\n",
       " 'te',\n",
       " 'middels',\n",
       " 'met',\n",
       " 'omtrent',\n",
       " 'achter',\n",
       " 'door',\n",
       " 'ter',\n",
       " 'uit',\n",
       " 'vanuit',\n",
       " 'via',\n",
       " 'tegen',\n",
       " 'op',\n",
       " 'bij',\n",
       " 'in',\n",
       " 'In',\n",
       " 'om',\n",
       " 'voor']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(complete_adjective_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ECLI:NL:RBZUT:2003:AH9598</td>\n",
       "      <td>[hij op tijdstippen in de periode 6 februari 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ECLI:NL:RBZWB:2020:2646</td>\n",
       "      <td>[- een (compleet) in werking zijnde laboratori...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ECLI:NL:PHR:2007:BA1113</td>\n",
       "      <td>[In de maand december 1998 ontstond onder ande...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ECLI:NL:GHAMS:2018:2662</td>\n",
       "      <td>[Dit feit heeft betrekking op een geslaagde in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ECLI:NL:RBAMS:2017:9087</td>\n",
       "      <td>[Verdachte heeft in de ochtend van 5 april 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2585</th>\n",
       "      <td>ECLI:NL:GHSHE:2020:1730</td>\n",
       "      <td>[Gezien het vorenstaande is het hof van oordee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2586</th>\n",
       "      <td>ECLI:NL:HR:1998:ZD1191</td>\n",
       "      <td>[\"4. hij in de periode van 1 januari 1993 tot ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2587</th>\n",
       "      <td>ECLI:NL:RBNHO:2013:10924</td>\n",
       "      <td>[Met de officier van justitie en de raadsvrouw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2588</th>\n",
       "      <td>ECLI:NL:GHSHE:2021:3205</td>\n",
       "      <td>[hij verdachte in of omstreeks de periode van ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2589</th>\n",
       "      <td>ECLI:NL:RBLIM:2018:3094</td>\n",
       "      <td>[De rechtbank concludeert voorts dat deze coca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2590 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             id  \\\n",
       "0     ECLI:NL:RBZUT:2003:AH9598   \n",
       "1       ECLI:NL:RBZWB:2020:2646   \n",
       "2       ECLI:NL:PHR:2007:BA1113   \n",
       "3       ECLI:NL:GHAMS:2018:2662   \n",
       "4       ECLI:NL:RBAMS:2017:9087   \n",
       "...                         ...   \n",
       "2585    ECLI:NL:GHSHE:2020:1730   \n",
       "2586     ECLI:NL:HR:1998:ZD1191   \n",
       "2587   ECLI:NL:RBNHO:2013:10924   \n",
       "2588    ECLI:NL:GHSHE:2021:3205   \n",
       "2589    ECLI:NL:RBLIM:2018:3094   \n",
       "\n",
       "                                                 chunks  \n",
       "0     [hij op tijdstippen in de periode 6 februari 2...  \n",
       "1     [- een (compleet) in werking zijnde laboratori...  \n",
       "2     [In de maand december 1998 ontstond onder ande...  \n",
       "3     [Dit feit heeft betrekking op een geslaagde in...  \n",
       "4     [Verdachte heeft in de ochtend van 5 april 201...  \n",
       "...                                                 ...  \n",
       "2585  [Gezien het vorenstaande is het hof van oordee...  \n",
       "2586  [\"4. hij in de periode van 1 januari 1993 tot ...  \n",
       "2587  [Met de officier van justitie en de raadsvrouw...  \n",
       "2588  [hij verdachte in of omstreeks de periode van ...  \n",
       "2589  [De rechtbank concludeert voorts dat deze coca...  \n",
       "\n",
       "[2590 rows x 2 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trafficking_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "case = list(trafficking_df[trafficking_df['id'] == 'ECLI:NL:GHAMS:2018:2662']['chunks'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Dit feit heeft betrekking op een geslaagde invoer van \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    900 gram\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">QUANTITY</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    cocaïne\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DRUG</span>\n",
       "</mark>\n",
       " vanuit \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Argentinië\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " door een persoon genaamd [naam \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    6\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       "].</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START CHUNK\n",
      " \n",
      " Extracting info for cocaïne.\n",
      "    vanuit: Argentinië, dist: 2, conj: ()\n",
      "[{'volume': '900', 'volume_type': 'gram'}]\n"
     ]
    }
   ],
   "source": [
    "for chunk in case:\n",
    "    displacy.render(nlp(chunk), style = 'ent')\n",
    "    extract_chunk_info(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entities(txt):\n",
    "    doc = nlp(txt)\n",
    "    for ent in doc.ents:\n",
    "        print(ent, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all loc entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_entities(entity):\n",
    "    entity_list = []\n",
    "    for i in range(len(trafficking_df)):\n",
    "        chunks = list(trafficking_df.iloc[i]['chunks'])\n",
    "        for chunk in chunks:\n",
    "            doc = nlp(chunk)\n",
    "            for ent in doc.ents:\n",
    "                if ent.label_ == entity:\n",
    "#                     print(trafficking_df.iloc[i]['id'])\n",
    "                    if ent.text not in entity_list:\n",
    "                        entity_list.append(ent.text)\n",
    "    return entity_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_list = list_entities(\"LOC\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gaswasser', 'Noordzee', 'Ettenseweg', 'Klein Horendonk', 'Maasdelta', 'Rotterdamse haven', 'medeveroordeelde', 'Prins Clausstraat', 'Westerschelde', 'Daartegenover', 'Wvmc', 'NFI-onderzoek', 'woning.2', 'inrichting/opbouw', 'Verderop', 'ZD04', 'Westelijke Havendijk', 'IJmond', 'Leuckartmethode', 'Eindhovenseweg', 'Zuid', 'koeriersauto', 'Tonsdijk', 'mengsels/substanties', 'Zuid-Limburgse', 'Industrieweg', 'Oost', 'micro-cellulose', 'Opiumwetbesluit', 'Wieringerwaardstraat', 'Luikerweg', 'verwijzingsbevel', 'Pijp', 'Lier', 'auditu-verklaringen', 'Keton', 'Rijn', 'Josemans-arrest', 'Bouchereau-arrest', 'schuur.5', 'Vogelweide', 'Ermelo4', 'Stationsweg', 'beek', 'Roteb', 'Gezinsherenigingsrichtlijn', 'Korvelseweg', 'Berkel', 'Arnhem', 'reactieketels L2', 'Gravesend', 'Sint Hubertuslaan', 'Tweede Groenedijk', 'Ermerweg', 'Diemen-Zuid', 'Noord-Beemster', 'Douanelaboratorium', 'Efedrine', 'enkelslag tabletteermachine', 'Einlassung', 'hennepkweek', 'AE-1-2017', 'Spaanse Polder', 'Nagel-onderzoek', 'Nero”-onderzoek', 'Vliertstraat', 'Narcotic', 'Alanenweg', 'Tallon-criterium', 'hennephandel', 'amfetamines.4', 'Sas', 'Nederlandse Antillen', 'Medemblik', 'Wildenberg', 'Maasvlakte', 'Duivendrecht', 'afschermproces-verbaal', 'onderhandelingsgesprekken', 'Indiaan', 'Ulft', 'Cobalt-onderzoek', 'Zuidschermer', 'Sri Lankese', 'Schiphol gemeente Haarlemmermeer', 'Venlose', 'ontmoetingen/besprekingen', 'Katerberg']\n"
     ]
    }
   ],
   "source": [
    "print(loc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gpe_list = list_entities(\"GPE\")\n",
    "print(gpe_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Argentinië\n",
      "Rotterdam\n",
      "Nederland\n",
      "Jamaica\n",
      "Hoogeveen\n",
      "gemeente Hoogeveen\n",
      "Utrecht\n",
      "Frankrijk\n",
      "België\n",
      "Duitsland\n",
      "Bonn\n",
      "Landgraaf\n",
      "buitenland\n",
      "Curaçao\n",
      "Leende\n",
      "drugs\n",
      "Wernhout\n",
      "Roden\n",
      "Leek\n",
      "Drachten\n",
      "Tolbert\n",
      "Tilburg\n",
      "Roermond\n",
      "Sprundel\n",
      "Nederhorst\n",
      "Putten\n",
      "Zeewolde\n",
      "Leuven\n",
      "Neede/Borculo\n",
      "Borculo\n",
      "Baarn\n",
      "MDMA‑kristallen\n",
      "Langdonk\n",
      "Roosendaal\n",
      "Neede/\n",
      "namen\n",
      "Mallorca\n",
      "Uden\n",
      "Turnhout\n",
      "Oisterwijk\n",
      "Neede\n",
      "Oost-Nederland\n",
      "Dominicaanse\n",
      "Medeveroordeelde\n",
      "Zuid-Amerika\n",
      "Ecuador\n",
      "Italië\n",
      "Schuinesloot\n",
      "Zeeland\n",
      "Esch\n",
      "Rilland\n",
      "Oosterhout\n",
      "Montfoort\n",
      "Ahaus\n",
      "Moergestel\n",
      "Arnhem\n",
      "Brazilië\n",
      "Oss\n",
      "Antwerpen\n",
      "gemeente Kaag\n",
      "Braassem\n",
      "Harderwijk\n",
      "Mono\n",
      "Peru\n",
      "Amsterdam\n",
      "Zweden\n",
      "Lienden\n",
      "Ommen\n",
      "Eindhoven\n",
      "gemeente Heerlen\n",
      "Suriname\n",
      "gemeente Venlo\n",
      "Europa\n",
      "gemeente Haarlem\n",
      "Liessel\n",
      "Alkmaar\n",
      "Breda\n",
      "shal\n",
      "Colombia\n",
      "fenetylline\n",
      "Nuenen gemeente Nuenen\n",
      "Seville 1\n",
      "Polen\n",
      "Knegsel\n",
      "Noord-Nederland\n",
      "Leeuwarden\n",
      "Pakistan\n",
      "Azië\n",
      "Vriezenveen\n",
      "Liempde gemeente Boxtel\n",
      "Belgie\n",
      "Hechtel-Eksel\n",
      "Akersloot\n",
      "Amstelveen\n",
      "Gastel\n",
      "Malaga\n",
      "Marokko\n",
      "Spanje\n",
      "Tanger\n",
      "gemeente Nieuwkoop\n",
      "Houten\n",
      "Engeland\n",
      "Denemarken\n",
      "Finland\n",
      "Bergen\n",
      "Turkije\n",
      "Maastricht\n",
      "s-Hertogenbosch\n",
      "Thailand\n",
      "Best\n",
      "Goes\n",
      "Nijmegen\n",
      "Verenigd Koninkrijk\n",
      "Waalre\n",
      "Helmond\n",
      "Ermelo\n",
      "China\n",
      "N-formyl\n",
      "Schoonebeek\n",
      "gronddelict\n",
      "overheidscontroles\n",
      "Emmen\n",
      "Odiliapeel\n",
      "rechtbank Limburg\n",
      "Trinidad\n",
      "Heemskerk\n",
      "Enschede\n",
      "Assen\n",
      "Haarlem\n",
      "Arnhem-Leeuwarden\n",
      "Liberty\n",
      "Randstad\n",
      "Hazeldonk\n",
      "Oostenrijk\n",
      "Ipswich\n",
      "Papekop\n",
      "rechtbank Zeeland-West-Brabant\n",
      "Verenigde Staten\n",
      "Canada\n",
      "Mexico\n",
      "Amerika\n",
      "Flevoland\n",
      "Schiphol\n",
      "Nederlnd\n",
      "Groot-Brittannië\n",
      "gemeente Zutphen\n",
      "Hoensbroek\n",
      "Bunde\n",
      "Oirsbeek\n",
      "Duitland\n",
      "Etten-Leur\n",
      "gemeente Maastricht\n",
      "Zaventem\n",
      "gemeente Maassluis\n",
      "NL\n",
      "Heerlen\n",
      "Hellevoetsluis\n",
      "Spijkenisse\n",
      "Duero\n",
      "Baarle-Nassau\n",
      "Eemnes\n",
      "Parijs\n",
      "Frans-Guyana\n",
      "Dresden\n",
      "Voort\n",
      "gemeente Zandvoort\n",
      "Hongarije\n",
      "Valkenswaard\n",
      "Noorwegen\n",
      "Leeds\n",
      "Wales\n",
      "Rumours\n",
      "Abcoude\n",
      "Amersfoort\n",
      "Weert\n",
      "Diemen\n",
      "Limburg\n",
      "Echt\n",
      "gemeente Eindhoven\n",
      "Seville 2\n",
      "Telegram\n",
      "Ooltgensplaat\n",
      "Deventer\n",
      "Mooiland\n",
      "gemeente Mill\n",
      "Apeldoorn\n",
      "Biezenmortel\n",
      "Dongen\n",
      "Ulicoten\n",
      "Roosendaalse Vliet\n",
      "Luxemburg\n",
      "Nieuwegein\n",
      "luchtafzuigingen\n",
      "Veldhoven\n",
      "Well\n",
      "Sittard\n",
      "gemeente Sittard-Geleen\n",
      "Kerkrade\n",
      "Yerseke\n",
      "Bornerbroek\n",
      "IJmuiden\n",
      "Gemeenschap\n",
      "Wolvega\n",
      "Sint Maarten\n",
      "Liverpool\n",
      "Groot-Britannië\n",
      "Daalwijk\n",
      "India\n",
      "Grashoek\n",
      "Hoorn\n",
      "West-Kruiskade\n",
      "Ierland\n",
      "Košice\n",
      "Zwolle\n",
      "Verenigd koninkrijk\n",
      "Ceza\n",
      "Barendrecht\n",
      "Westmaas\n",
      "Beusichem\n",
      "Lucaswolde\n",
      "Rijen\n",
      "gemeente Gilze\n",
      "Zaanstreek-Waterland\n",
      "Purmerend\n",
      "Amsterdam-Amstelland\n",
      "Hoofddorp\n",
      "Bussum\n",
      "gemeente Midden-Drenthe\n",
      "misdrij\n",
      "Lommel\n",
      "Dordrecht\n",
      "Handhavingsprotocol\n",
      "the Middle District\n",
      "Florida and elsewhere\n",
      "Jacksonville Florida\n",
      "Count\n",
      "Jacksonville\n",
      "gemeente Alkmaar\n",
      "Nederweert-Eind\n",
      "Voerendaal\n",
      "Australië\n",
      "Groningen\n",
      "Brantôme\n",
      "Winterswijk\n",
      "Fijnaart\n",
      "Dilsen-Stokkem\n",
      "Verenigd Koninkrijk.2Dat\n",
      "Mondoza\n",
      "gemeente Borculo\n",
      "Delft\n",
      "Natriumboorhybride\n",
      "tabletteermachine\n",
      "AP-logo\n",
      "narcotica\n",
      "Rijckevorsel\n",
      "new age\n",
      "art.126ff\n",
      "Antofagasta\n",
      "Midden-Amerika\n",
      "vacumeermachines\n",
      "naar/vanuit\n",
      "Dover\n",
      "Hengelo\n",
      "Nederlandtezamen\n",
      "Leuckartsynthese.18\n",
      "Geldrop\n",
      "Bavel\n",
      "Gamma\n",
      "GHB-gebruik\n",
      "drugs-labs\n",
      "Processtap\n",
      "Culemborg\n",
      "Veenendaal\n",
      "veerboot\n",
      "pseudo-efedrine\n",
      "Emst\n",
      "Zuidlaren\n",
      "Vlissingen\n",
      "gebroken.14\n",
      "Hansa\n",
      "omgekocht.4\n",
      "geweest.6\n",
      "drugstransporten.31\n",
      "Katwijk\n",
      "Lysergide\n",
      "Aruba\n",
      "Leuckart-procedure106\n",
      "Ghana\n",
      "Kenia\n",
      "Japan\n",
      "Waalwijk\n",
      "Kerkrade Landgraaf\n",
      "Brunssum\n",
      "Toran\n",
      "Schymik\n",
      "Roemenië\n",
      "Oudenbosch\n",
      "Doetinchem\n",
      "Nederland(1\n",
      "Stockholm\n",
      "Bondsrepubliek Duitsland\n",
      "Lübeck\n",
      "Almere\n",
      "natriumformiaat\n",
      "ammoniumformiaat\n",
      "VS\n",
      "Duivendrecht\n",
      "Heuvelland\n",
      "Keulen\n",
      "Cariben\n",
      "LFO-rapport\n",
      "Eext\n",
      "L-22\n",
      "koperdiefstallen\n",
      "Kroatië\n",
      "Rucphen\n",
      "District Helmond\n",
      "gemeente Haarlemmermeer\n",
      "loods.19\n",
      "Groot Brittannië\n",
      "Verenigde Naties\n",
      "Koninkrijk der Nederlanden\n",
      "Limburg Noord-Brabant\n",
      "Oldenzaal\n",
      "Fosforzuur\n",
      "Lagos\n",
      "PH-KCF\n",
      "Accra\n",
      "Dubai\n",
      "EU\n",
      "Arnhem-Maastricht\n",
      "N-ethylMDA\n",
      "Oldenburg\n",
      "Brabant\n",
      "Budel\n",
      "Straelen\n",
      "Grijpskerke\n",
      "PiperylMethylKeton\n",
      "Groot-Brittanie\n",
      "Elst\n",
      "Zwitserland\n",
      "Larvik\n",
      "Helsingborg\n",
      "mutatieverslag\n",
      "Veen\n",
      "wiet/hasj\n",
      "Gronsveld gemeente Eijsden\n",
      "Rumpt\n",
      "Geldermalsen\n",
      "Leiden\n",
      "Florida the defendants\n",
      "Caucedo\n",
      "Londen\n",
      "Hechtel Eksel\n",
      "Gent\n",
      "pleegperiode\n",
      "Sint-Oedenrode\n",
      "St. Helens\n",
      "Merseyside\n",
      "Tiel\n",
      "Panama\n",
      "Hamburg\n",
      "Parkstad\n",
      "Europese Unie\n",
      "Rb)28\n",
      "Rome\n",
      "Gilze\n",
      "Columbia\n",
      "Den Haag\n",
      "Den Haag.10\n",
      "s-Hertogenbosch halveren\n",
      "Velden\n",
      "Scandinavië\n",
      "Hard\n",
      "eerstvermelde\n",
      "aangehouden.3\n",
      "Puth\n",
      "Merkelbeek\n",
      "Geleen\n",
      "Zuid-Limburg\n",
      "Urmond\n",
      "euro's\n",
      "Miami\n",
      "Checkpoint\n",
      "gemeente Slochteren\n",
      "Platinumoxide\n",
      "Florida”29\n",
      "Zegge\n",
      "Luckartmethode\n",
      "Zwartebroek\n",
      "Delfshaven\n",
      "Noord Limburg\n",
      "Basse\n",
      "s-Herto¬gen¬bosch\n",
      "Douanewetgeving\n",
      "Zeeland2\n",
      "Amsterdam3\n",
      "sofdrugscircuit\n",
      "Leukartmethode\n",
      "tenaamgestelde\n",
      "geproduceerd.12\n",
      "Haarzuilens\n",
      "Gageldijk\n",
      "Beverwijk\n",
      "Zierikzee\n",
      "Sint Kruis\n",
      "Zuidwolde\n",
      "Veeningen\n",
      "gemeente Sluis\n",
      "dl-metamfetamine\n",
      "Gorpeind\n",
      "Hulshof\n",
      "Rusland\n",
      "Kalmthout\n",
      "Haaften\n",
      "Overasselt\n",
      "sulfaatzout\n",
      "Arnhem Elst gemeente Overbetuwe\n",
      "Barneveld\n",
      "Helsinki\n",
      "Zoetermeer\n",
      "Ressen gemeente Lingewaard\n",
      "Prinsenbeek\n",
      "Nederland.56\n",
      "hennephandel\n",
      "Bunschoten\n",
      "Chaam\n",
      "Waddinxveen\n",
      "Sassenheim\n",
      "rechtbank Oost-Brabant\n",
      "Genève\n",
      "Geneefse\n",
      "Reggio\n",
      "Costa\n",
      "Rica\n",
      "inkoopt1\n",
      "geplaatst4\n",
      "Colombiaan\n",
      "leveren8\n",
      "telefoontaps\n",
      "Europe\n",
      "kolomdistilleerpijp\n",
      "vakantie-)huisje\n",
      "Wildertstraat\n",
      "Alcapharm\n",
      "Enschot\n",
      "Venezuela\n",
      "Sao\n",
      "Paulo\n",
      "gamma-butyrolacton\n",
      "Hoogerheide\n",
      "gemeente Montferland\n",
      "Bergh\n",
      "Lawaai\n",
      "bronland\n",
      "Tobago\n",
      "aanschaf/overdracht\n",
      "drugsopbrengsten\n",
      "Hull\n",
      "Groot-Brittanië\n",
      "gearresteerd128\n",
      "Nistelrode\n",
      "gemeente Bernheze\n",
      "Voorst\n",
      "Lomm\n",
      "A-G Wortel\n",
      "Western\n",
      "Manchester\n",
      "MDMA.171\n",
      "aangetroffen.176\n",
      "Naarden\n",
      "Zeist\n",
      "Berlijn\n",
      "Florida\n",
      "Koewacht\n",
      "Linnewever\n",
      "Nederland.181\n",
      "Afrika\n",
      "Zevenaar\n",
      "Oostende\n",
      "Lummen\n",
      "Dorsten\n",
      "Düren\n",
      "Périgueux\n",
      "Gilze-Rijen\n",
      "Terborg\n",
      "Waspik\n",
      "Nunhem\n",
      "noscapine\n",
      "NLG\n",
      "Wanssum\n",
      "Algeciras\n",
      "Marokko/Spanje\n",
      "Portugal\n",
      "Nimes\n",
      "Noordwijk\n",
      "hasjtransport\n",
      "Perpignan\n",
      "onderzoeksbevel\n",
      "Overijssel\n",
      "Heidelberg\n",
      "Bonaire\n",
      "Aarle-Rixtel\n",
      "Jongeren\n",
      "Emmer-Compascuum\n",
      "Zevenbergen\n",
      "Zevenaar Rijen\n",
      "Baarle Nassau\n",
      "geleden.35\n",
      "Weesp\n",
      "=)\n",
      "GHB.2\n",
      "verdachte].84\n",
      "B01\n",
      "stad Nador\n",
      "Chili\n",
      "fishskin\n",
      "Gorinchem\n",
      "Hulten gemeente Gilze\n",
      "Iran\n",
      "Heerhugowaard\n",
      "gemeente Beemster\n",
      "Afghanistan\n",
      "Amsterdam.3\n",
      "Midden-\n",
      "Norderstedt\n",
      "Harlingen\n",
      "cocaïne.3\n",
      "Augsburg\n",
      "Klundert\n",
      "gemeente Moerdijk\n",
      "voorbereidingshande-lingen\n",
      "mefredon\n",
      "Jumbotassen\n",
      "Zeist Odijk\n",
      "Zaltbommel\n",
      "Tsjechië\n",
      "La Fuiaga\n",
      "5.054\n",
      "Schoonhoven\n",
      "opgelegd;-\n",
      "harddrugs;-\n",
      "strafbaarstellen\n",
      "2.330.000-\n",
      "Liechtenstein\n",
      "synthese.10\n",
      "Laren\n",
      "Temse\n",
      "Herselt\n",
      "Trier\n",
      "hennepkweek\n",
      "Venlo\n",
      "Oekraine\n",
      "Tienray\n",
      "Mijnsheerenland\n",
      "Strijen\n",
      "Neunkirchen-Vluyn\n",
      "Sevilla\n",
      "price\n",
      "Lelystad\n",
      "softdruggebruik\n",
      "Hulst\n",
      "kwam34\n",
      "Bremen\n",
      "Zuid-\n",
      "Oosterzee gemeente\n",
      "Paramaribo\n",
      "Wuppertal\n",
      "Griekenland\n",
      "Den Bosch\n",
      "Itot\n",
      "luchtvrachtcontainer\n",
      "Bergkamp\n",
      "financier.(3\n",
      "Hong Kong\n",
      "Madrid\n",
      "Alcobacca\n",
      "Zundert\n",
      "Diyarbakir\n",
      "Kilimanjaro\n",
      "Basel\n",
      "Zaandam\n",
      "Kentucky\n",
      "Chelmsford\n",
      "gemeente Apeldoorn\n",
      "Fairfield\n",
      "AADK5494NL\n",
      "AADK5464NL\n",
      "AADK5465NL\n",
      "Wervershoof\n",
      "DOC-282\n",
      "Warschau\n",
      "Medeplegen\n",
      "Hippolytushoef\n",
      "El-Aamrani\n",
      "Dazzler\n",
      "Zevenhuizen\n",
      "Oslo\n",
      "Moskou\n",
      "alternatief/cumulatief\n",
      "Haren\n",
      "Stellendam\n",
      "Zuidland Heijplaat\n",
      "Den Hoorn\n",
      "Malta\n",
      "Best.17\n",
      "Verenigd Koninkrijk.18\n",
      "Saasveld\n",
      "Lima\n",
      "Zürich\n",
      "Brussel\n",
      "hennep/hasjiesj\n",
      "Charleroi\n",
      "Airside\n",
      "transportlogistieke\n",
      "Milaan\n",
      "Balkan\n",
      "Arnhem Amsterdam\n",
      "georganiseerd/geregeld\n",
      "COVID-19\n",
      "Amiens\n",
      "Charleville\n",
      "Cholet\n",
      "Lyon\n",
      "Le Havre\n",
      "Rouen\n",
      "Bordeaux\n",
      "Valencia\n",
      "overgemaakt/geleend/overhandigd\n",
      "art. 36e Sr\n",
      "gemeente Terneuzen\n",
      "Terneuzen\n",
      "Senegal\n",
      "methyleendioxymethamfetamine\n",
      "Zwanenburg gemeente Haarlemmermeer\n",
      "Belgïe\n",
      "Benthuizen\n",
      "amfetamine.31\n",
      "Caracas\n",
      "Vinkeveen\n",
      "Zwanenburg\n",
      "Haarlemmermeer\n",
      "..\n",
      "evenbedoeld\n",
      "Voorburg\n",
      "Delfgauw\n",
      "Aalsmeer\n",
      "Frankfurt\n",
      "Main\n",
      "Mein\n",
      "Wateringen\n",
      "Zuidland Van den Berg\n",
      "s-Hertogenbosch Tilburg\n",
      "Equador\n",
      "Kigeme\n",
      "Zaïre\n",
      "euro’s\n",
      "Breuberg\n",
      "Groot-Brittannie\n",
      "Friesland\n",
      "Made\n",
      "Colon\n",
      "Vermeeren\n",
      "Italie\n",
      "Congo\n",
      "Magdeburg\n",
      "Sachsen\n",
      "Bautzen\n",
      "VS.\n",
      "Toldijk gemeente Steenderen\n",
      "kiloblokken\n",
      "Encrochatgesprekken\n",
      "senior-inspecteur\n",
      "Ulft\n",
      "Auckland\n",
      "Rechtbank Oost-Brabant\n",
      "Kessel\n",
      "kookstappen\n",
      "Zuid-Holland-Zuid\n",
      "Cancun\n",
      "Mechelen\n",
      "Nederland.65\n",
      "havenmedewerker\n",
      "Rozenburg\n",
      "Litouwen\n",
      "Nigeria\n",
      "hashtransporten\n",
      "BVH-mutaties\n",
      "Medellin\n",
      "Volendam\n",
      "Aken\n",
      "stofmap\n",
      "drugs-containers\n",
      "5.100-\n",
      "Elten-Emmerich\n",
      "Gramsbergen\n",
      "Medemblik\n",
      "Wassenaar\n",
      "Vermont\n",
      "Ecstacy\n",
      "Aruba Colombia\n",
      "Drunen\n",
      "Kaatsheuvel\n",
      "gedachtestreepje1\n",
      "Meram\n",
      "Felixstowe\n",
      "f.200= per kilogram\n",
      "f.464.000=\n",
      "Raamsdonksveer\n",
      "West-Europa\n",
      "Liberia\n",
      "Reuver\n",
      "Maasmechelen\n",
      "Operaciones\n",
      "Curaçaos\n",
      "Godlinze\n",
      "Santa\n",
      "Marta\n",
      "Guyana\n",
      "Gelazur\n",
      "Clinge\n",
      "Volkel\n",
      "Zuidoost\n",
      ".36\n",
      "Ananassen\n",
      "Deklading\n",
      "Düsseldorf\n",
      "Marbella\n",
      "Wanroij\n",
      "Mannheim\n",
      "Goch\n",
      "Boxmeer\n",
      "Nijeveen\n",
      "Malmö\n",
      "Aalburg\n",
      "Hammonia\n",
      "Almelo\n",
      "Bogota\n",
      "Bolivia\n",
      "De Peruaan\n",
      "Padua\n",
      "Haïti\n",
      "lever-de\n",
      "Zwijndrecht\n",
      "Marokko.[betrokkene\n",
      "gemeente Landgraaf\n"
     ]
    }
   ],
   "source": [
    "for i in gpe_list:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
