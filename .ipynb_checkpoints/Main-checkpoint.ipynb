{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No file DS_Store\n"
     ]
    }
   ],
   "source": [
    "dataPath = os.getcwd() + '/court case data/testdata/'\n",
    "caseCount = len(os.listdir(dataPath))\n",
    "data = []\n",
    "try:\n",
    "    os.remove(dataPath + \".DS_Store\")\n",
    "except:\n",
    "    print(\"No file DS_Store\")\n",
    "for filename in os.listdir(dataPath):\n",
    "    f = open(os.path.join(dataPath, filename), encoding='utf-8')\n",
    "    data.append([filename.replace('.txt', ''), f.read()])\n",
    "\n",
    "verdict_df = pd.DataFrame(data, columns=[\"id\", \"case text\"])\n",
    "cases_df = pd.read_csv('./court case data/testdata.csv')\n",
    "merged_df = cases_df.join(verdict_df.set_index('id'), on='id', how='left')\n",
    "\n",
    "merged_df[\"verdict_date\"] = pd.to_datetime(merged_df[\"verdict_date\"])\n",
    "merged_df[\"publication_date\"] = pd.to_datetime(merged_df[\"publication_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>verdict_date</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>verdict_type</th>\n",
       "      <th>jurisdiction_type</th>\n",
       "      <th>case text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ECLI-NL-RBNNE-2021-5018</td>\n",
       "      <td>2021-01-10</td>\n",
       "      <td>2021-11-23</td>\n",
       "      <td>uitspraak</td>\n",
       "      <td>['Strafrecht']</td>\n",
       "      <td>\\n\\nRECHTBANK NOORD-NEDERLAND\\nAfdeling strafr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ECLI-NL-RBZUT-2003-AH9598</td>\n",
       "      <td>2003-03-06</td>\n",
       "      <td>2003-09-07</td>\n",
       "      <td>uitspraak</td>\n",
       "      <td>['Strafrecht']</td>\n",
       "      <td>\\n\\nRECHTBANK ZUTPHEN\\nMeervoudige economische...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ECLI-NL-RBZWB-2020-2646</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>uitspraak</td>\n",
       "      <td>['Strafrecht']</td>\n",
       "      <td>\\n\\nRECHTBANK ZEELAND-WEST-BRABANT\\n\\nStrafrec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ECLI-NL-GHAMS-2019-1601</td>\n",
       "      <td>2019-08-05</td>\n",
       "      <td>2019-07-26</td>\n",
       "      <td>uitspraak</td>\n",
       "      <td>['Strafrecht']</td>\n",
       "      <td>\\n\\nafdeling strafrecht\\nparketnummer: 23-0017...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ECLI-NL-GHAMS-2019-1602</td>\n",
       "      <td>2019-08-05</td>\n",
       "      <td>2019-07-26</td>\n",
       "      <td>uitspraak</td>\n",
       "      <td>['Strafrecht']</td>\n",
       "      <td>\\n\\nafdeling strafrecht\\nparketnummer: 23-0017...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18119</th>\n",
       "      <td>ECLI-NL-RBAMS-2013-1294</td>\n",
       "      <td>2013-01-29</td>\n",
       "      <td>2013-08-10</td>\n",
       "      <td>uitspraak</td>\n",
       "      <td>['Strafrecht']</td>\n",
       "      <td>\\n\\nRECHTBANK AMSTERDAM\\n\\n\\nVONNIS\\n\\n \\n\\n13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18120</th>\n",
       "      <td>ECLI-NL-PHR-2020-1106</td>\n",
       "      <td>2020-11-24</td>\n",
       "      <td>2020-11-24</td>\n",
       "      <td>conclusie</td>\n",
       "      <td>['Strafrecht']</td>\n",
       "      <td>\\n\\nPROCUREUR-GENERAAL\\n\\n\\nBIJ DE\\n\\n\\nHOGE R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18121</th>\n",
       "      <td>ECLI-NL-GHAMS-2017-2618</td>\n",
       "      <td>2017-06-29</td>\n",
       "      <td>2017-05-07</td>\n",
       "      <td>uitspraak</td>\n",
       "      <td>['Strafrecht']</td>\n",
       "      <td>\\n\\n\\nparketnummer: 23-001217-13\\ndatum uitspr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18122</th>\n",
       "      <td>ECLI-NL-RBAMS-2013-BZ0392</td>\n",
       "      <td>2013-01-29</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>uitspraak</td>\n",
       "      <td>['Strafrecht']</td>\n",
       "      <td>\\nRECHTBANK AMSTERDAM \\nVONNIS  \\n\\n13/529144-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18123</th>\n",
       "      <td>ECLI-NL-GHAMS-2007-BB2447</td>\n",
       "      <td>2007-07-13</td>\n",
       "      <td>2007-08-29</td>\n",
       "      <td>uitspraak</td>\n",
       "      <td>['Strafrecht']</td>\n",
       "      <td>\\n\\narrestnummer: \\nparketnummer:\\t23-001835-0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18124 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id verdict_date publication_date verdict_type  \\\n",
       "0        ECLI-NL-RBNNE-2021-5018   2021-01-10       2021-11-23    uitspraak   \n",
       "1      ECLI-NL-RBZUT-2003-AH9598   2003-03-06       2003-09-07    uitspraak   \n",
       "2        ECLI-NL-RBZWB-2020-2646   2020-06-23       2020-06-23    uitspraak   \n",
       "3        ECLI-NL-GHAMS-2019-1601   2019-08-05       2019-07-26    uitspraak   \n",
       "4        ECLI-NL-GHAMS-2019-1602   2019-08-05       2019-07-26    uitspraak   \n",
       "...                          ...          ...              ...          ...   \n",
       "18119    ECLI-NL-RBAMS-2013-1294   2013-01-29       2013-08-10    uitspraak   \n",
       "18120      ECLI-NL-PHR-2020-1106   2020-11-24       2020-11-24    conclusie   \n",
       "18121    ECLI-NL-GHAMS-2017-2618   2017-06-29       2017-05-07    uitspraak   \n",
       "18122  ECLI-NL-RBAMS-2013-BZ0392   2013-01-29       2013-01-02    uitspraak   \n",
       "18123  ECLI-NL-GHAMS-2007-BB2447   2007-07-13       2007-08-29    uitspraak   \n",
       "\n",
       "      jurisdiction_type                                          case text  \n",
       "0        ['Strafrecht']  \\n\\nRECHTBANK NOORD-NEDERLAND\\nAfdeling strafr...  \n",
       "1        ['Strafrecht']  \\n\\nRECHTBANK ZUTPHEN\\nMeervoudige economische...  \n",
       "2        ['Strafrecht']  \\n\\nRECHTBANK ZEELAND-WEST-BRABANT\\n\\nStrafrec...  \n",
       "3        ['Strafrecht']  \\n\\nafdeling strafrecht\\nparketnummer: 23-0017...  \n",
       "4        ['Strafrecht']  \\n\\nafdeling strafrecht\\nparketnummer: 23-0017...  \n",
       "...                 ...                                                ...  \n",
       "18119    ['Strafrecht']  \\n\\nRECHTBANK AMSTERDAM\\n\\n\\nVONNIS\\n\\n \\n\\n13...  \n",
       "18120    ['Strafrecht']  \\n\\nPROCUREUR-GENERAAL\\n\\n\\nBIJ DE\\n\\n\\nHOGE R...  \n",
       "18121    ['Strafrecht']  \\n\\n\\nparketnummer: 23-001217-13\\ndatum uitspr...  \n",
       "18122    ['Strafrecht']  \\nRECHTBANK AMSTERDAM \\nVONNIS  \\n\\n13/529144-...  \n",
       "18123    ['Strafrecht']  \\n\\narrestnummer: \\nparketnummer:\\t23-001835-0...  \n",
       "\n",
       "[18124 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import re\n",
    "alphabets= \"([A-Za-z])\"\n",
    "prefixes = \"(Mr|St|Mrs|Ms|Dr|mr|mevr|mvr)[.]\"\n",
    "suffixes = \"(Inc|Ltd|Jr|Sr|Co)\"\n",
    "starters = \"(Mr|Mrs|Ms|Dr|He\\s|She\\s|It\\s|They\\s|Their\\s|Our\\s|We\\s|But\\s|However\\s|That\\s|This\\s|Wherever)\"\n",
    "acronyms = \"([A-Z][.][A-Z][.](?:[A-Z][.])?)\"\n",
    "websites = \"[.](com|net|org|io|gov|nl)\"\n",
    "articles = \"[artikel ][0-9][.][0-9]\"\n",
    "\n",
    "def split_into_sentences2(text):\n",
    "    text = \" \" + text + \"  \"\n",
    "    text = text.replace(\"\\n\",\" \")\n",
    "    text = re.sub(prefixes,\"\\\\1<prd>\",text)\n",
    "    text = re.sub(websites,\"<prd>\\\\1\",text)\n",
    "    text = re.sub(articles,\"[artikelnummer]\",text)\n",
    "    if \"Ph.D\" in text: text = text.replace(\"Ph.D.\",\"Ph<prd>D<prd>\")\n",
    "    text = re.sub(\"\\s\" + alphabets + \"[.] \",\" \\\\1<prd> \",text)\n",
    "    text = re.sub(acronyms+\" \"+starters,\"\\\\1<stop> \\\\2\",text)\n",
    "    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\\\\3<prd>\",text)\n",
    "    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\",text)\n",
    "    text = re.sub(\" \"+suffixes+\"[.] \"+starters,\" \\\\1<stop> \\\\2\",text)\n",
    "    text = re.sub(\" \"+suffixes+\"[.]\",\" \\\\1<prd>\",text)\n",
    "    text = re.sub(\" \" + alphabets + \"[.]\",\" \\\\1<prd>\",text)\n",
    "    if \"”\" in text: text = text.replace(\".”\",\"”.\")\n",
    "    if \"\\\"\" in text: text = text.replace(\".\\\"\",\"\\\".\")\n",
    "    if \"!\" in text: text = text.replace(\"!\\\"\",\"\\\"!\")\n",
    "    if \"?\" in text: text = text.replace(\"?\\\"\",\"\\\"?\")\n",
    "    text = text.replace(\".\",\".<stop>\")\n",
    "    text = text.replace(\"?\",\"?<stop>\")\n",
    "    text = text.replace(\"!\",\"!<stop>\")\n",
    "    text = text.replace(\"<prd>\",\".\")\n",
    "    sentences = text.split(\"<stop>\")\n",
    "    sentences = sentences[:-1]\n",
    "    sentences = [s.strip() for s in sentences]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_sentences(text):\n",
    "    sentences = re.split(r'(?<=[^A-Z].[.?]) +(?=[A-Z])|\\n', text)\n",
    "    sentences = [x for x in sentences if len(x) > 1]\n",
    "    return sentences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two ways of splitting the documents:\n",
    "    For Word2Vec, we need sentences to be an array of words.\n",
    "    For the rest, just the sentence is enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18124\n",
      "5107544\n"
     ]
    }
   ],
   "source": [
    "sentence_list_by_word = []\n",
    "sentence_list = []\n",
    "\n",
    "for i in range(len(merged_df)):\n",
    "    doc = merged_df.iloc[i]['case text']\n",
    "    sentences = split_into_sentences(doc)\n",
    "    sentence_list.append(sentences)\n",
    "    for j in sentences:\n",
    "        word_list = [x for x in j.lower().rstrip().replace('.', '').split(' ') if len(x)>0]\n",
    "        sentence_list_by_word.append(word_list)\n",
    "        \n",
    "print(len(sentence_list))\n",
    "print(len(sentence_list_by_word))\n",
    "# print(sentence_list[8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RECHTBANK NOORD-NEDERLAND \n",
      "\n",
      "Afdeling strafrecht  \n",
      "\n",
      "Locatie Leeuwarden \n",
      "\n",
      "parketnummer 18/048259-21 \n",
      "\n",
      "Vonnis van de meervoudige kamer voor de behandeling van strafzaken d.d. 1 oktober 2021 in de zaak van het openbaar ministerie tegen de verdachte  \n",
      "\n",
      "      [verdachte]  \n",
      "\n",
      "geboren op [geboortedatum] 1971 te [geboorteplaats]  \n",
      "\n",
      "thans gedetineerd te [instelling]. \n",
      "\n",
      "Dit vonnis is gewezen naar aanleiding van het onderzoek ter terechtzitting van 17 september 2021. \n",
      "\n",
      "Verdachte is verschenen bijgestaan door mr. \n",
      "\n",
      "A.C. \n",
      "\n",
      "Huisman advocaat te Deventer. \n",
      "\n",
      "Het openbaar ministerie is ter terechtzitting vertegenwoordigd door mr. \n",
      "\n",
      "E.R. \n",
      "\n",
      "Jepkema. \n",
      "\n",
      "Tenlastelegging \n",
      "\n",
      "Aan verdachte is na nadere omschrijving van de tenlastelegging ten laste gelegd dat:  \n",
      "\n",
      "1. \n",
      "\n",
      "hij in of omstreeks de periode van 1 oktober 2020 tot en met 19 februari 2021 meerdere malen althans eenmaal telkens te Minnertsga gemeente Waadhoeke tezamen en in vereniging met een of meer anderen althans alleen opzettelijk heeft bereid en/of bewerkt \n",
      "\n",
      "en/of verwerkt en/of verkocht en/of afgeleverd en/of verstrekt en/of vervoerd en/of vervaardigd in elk geval opzettelijk aanwezig heeft gehad een hoeveelheid/hoeveelheden van een materiaal bevattende amfetamine (speed) zijnde amfetamine (speed) een middel als bedoeld in de bij de Opiumwet behorende lijst 1 dan wel aangewezen krachtens het vijfde lid van artikel 3a van die wet; \n",
      "\n",
      "2.  \n",
      "\n",
      "hij op een of meer tijdstippen in of omstreeks de periode van 1 oktober 2020 tot en met 19 februari 2021 te Minnertsga gemeente Waadhoeke althans in Nederland tezamen en in vereniging met een ander of anderen althans alleen (telkens) al dan niet opzettelijk \n",
      "\n",
      "stoffen te weten: \n",
      "\n",
      "-MDA en/of \n",
      "\n",
      "-MDMA en/of \n",
      "\n",
      "-Amfetamine en/of \n",
      "\n",
      "-Methamfetamine en/of \n",
      "\n",
      "-N-acetyl-amfetamine \n",
      "\n",
      "althans met bovengenoemde stoffen verontreinigd water heeft gebracht in een sloot (gelegen aan of nabij de [straatnaam] ) zijnde een oppervlaktewaterlichaam terwijl: \n",
      "\n",
      "-een daartoe strekkende vergunning niet was verleend door Onze Minister dan wel het bestuur van het betrokken waterschap en \n",
      "\n",
      "-daarvoor geen vrijstelling was verleend bij of krachtens algemene \n",
      "\n",
      "maatregel van bestuur en \n",
      "\n",
      "-artikel 6.3 van de Waterwet niet van toepassing was. \n",
      "\n",
      "Beoordeling van het bewijs \n",
      "\n",
      "Standpunt van de officier van justitie \n",
      "\n",
      "De officier van justitie heeft veroordeling gevorderd voor feit 1 en feit 2 beide in de periode van 18 en 19 februari 2021.  \n",
      "\n",
      "Standpunt van de verdediging \n",
      "\n",
      "De raadsman heeft met betrekking tot feit 1 aangevoerd dat bewezen kan worden dat verdachte op 18/ 19 februari 2021 in het laboratorium op het perceel aan de [straatnaam] te Minnertsga aanwezig was en er handelingen met betrekking tot het proces heeft verricht. \n",
      "\n",
      "De ten laste gelegde periode kan niet bewezen worden omdat nergens uit blijkt dat verdachte op andere dagen dan 18/ 19 februari 2021 aanwezig was. \n",
      "\n",
      "Ten aanzien van feit 2 heeft de raadsman aangevoerd dat verdachte één dag namelijk op 18/19 februari 2021 in het laboratorium handelingen heeft verricht. \n",
      "\n",
      "Uit het dossier kan niet worden opgemaakt dat verdachte opzettelijk een rol heeft gespeeld bij het lozen van afvalwater in de sloot. \n",
      "\n",
      "Verdachte dient van feit 2 te worden vrijgesproken. \n",
      "\n",
      "Oordeel van de rechtbank \n",
      "\n",
      "Op 19 februari 2021 is bij de doorzoeking op het perceel aan de [straatnaam] te Minnertsga een productieplaats van synthetische drugs aangetroffen2.  \n",
      "\n",
      "Uit onderzoek verricht door experts van de Landelijke Faciliteit Ontmantelen (LFO) blijkt onder meer dat in de opstal gelegen aan de linkerzijde van het perceel drie aan elkaar geschakelde ruimtes waren ingericht voor de productie. \n",
      "\n",
      "Twee ruimtes (aangeduid als E en V) waren in gebruik ten behoeve van de opslag van voorraad chemicaliën (nieuw en afval) ten behoeven van de vervaardiging van synthetische drugs en/of precursoren (BMK). Bij het betreden van de derde ruimte (aangeduid als L) werd de geur van amfetamineachtige stoffen geroken. \n",
      "\n",
      "De ruimte L was ingericht en in gebruik ten behoeve van de vervaardiging c.q. bewerking van vermoedelijk BenzylMethylKeton (BMK: grondstof (meth)amfetamine) met behulp van een preprecursor (MAPA BMK glycidezuur) en een sterk zuur en vermoedelijk de vervaarding en bewerking van amfetamine met behulp van de ter plaatse vervaardigde BMK. Aan de achterzijde van ruimte L stonden twee in werking zijnde productieopstellingen bestaande uit een vierkante rvs reactieketel voorzien van een rvs koeler en een roermotor waaruit aan de voorzijde via een kogelafsluiter warme ongeveer 60 °C olieachtige vloeistof geur BMK in een vat liep. \n",
      "\n",
      "In dit vat stond een vloeistofpomp welke middels een slang de warme vloeistof aan het overpompen was in een 200 liter schroefdekselvat. \n",
      "\n",
      "Verder stond er een stoomdestillatieopstelling bestaande uit een rvs reactieketel welke middels een rvsslang gekoppeld was aan een koelsysteem. \n",
      "\n",
      "Onder de reactieketel stond een gasbrander te branden. \n",
      "\n",
      "Daarnaast stonden in de ruimte L diverse verpakkingen (jerrycans en vaten) met chemicaliën opgeslagen.3 \n",
      "\n",
      "Uit de lijst aangetroffen en in beslag genomen goederen4 blijkt dat in de verschillende ruimtes aan de [straatnaam] te Minnertsga onder meer de volgende goederen zijn aangetroffen. \n",
      "\n",
      "Ruimte L \n",
      "\n",
      "AANK6618NL 19 jerrycans inhoudsmaat 20 liter etiket ‘Formic acid’ alle geheel gevuld  \n",
      "\n",
      "met een heldere zure vloeistof geur mierenzuur. \n",
      "\n",
      "Totaal 380 liter mierenzuur volgens het NFI bevattende mierenzuur5. \n",
      "\n",
      "AANK6617NL 9x bruine vezel versterkte zak etiket lithopone 25 kg met 12x dubbele  \n",
      "\n",
      "\t\tplastic zak alle met restanten wit poeder bevattende volgens NFI MAPA6. \n",
      "\n",
      "AANK6614NL Klemdekselvat inhoudsmaat 200 liter geheel gevuld met een stroperige  \n",
      "\n",
      "basische substantie vermoedelijk destillatieresidu volgens het NFI bevattende voornamelijk amfetamine gerelateerde syntheseverontreinigingen7. \n",
      "\n",
      "AANK6613NL Maatbeker inhoudsmaat 3 liter met daarin circa 1800 ml bruine olieachtige  \n",
      "\n",
      "\t\tvloeistof met de geur van amfetamine achtige stoffen volgens het NFI \t\t\tbevattende oa amfetamine8. \n",
      "\n",
      "AANK6612NL Een petfles met etiket ‘plus sinas’ met daarin 500 ml bruine emulsie met de  \n",
      "\n",
      "\t\tgeur van tolueen volgens het NFI bevattende oa amfetamine9.  \n",
      "\n",
      "Uit het NFI-rapport blijkt verder onder meer dat BMK (benzylmethylketon) een grondstof is voor amfetamine. \n",
      "\n",
      "MAPA wordt gebruikt voor het vervaardigen van BMK. Mierenzuur is een hulpstof bij de vervaardiging van amfetamine met de Leuckartmethode10.  \n",
      "\n",
      "Deze conclusie komt overeen met de interpretatie van het LFO namelijk dat de aangetroffen productiemiddelen (o.a. reactieketels scheitrechters) en chemicaliën (o.a.MAPA BMK glycidezuur fosforzuur mierenzuur formamide en caustic soda) typische goederen zijn en chemicaliën zijn welke aangetroffen worden op locaties waar synthetische drugs vervaardigd of bewerkt worden. \n",
      "\n",
      "De productieplaats aanwezig in opstal [L] was ingericht en in gebruik voor het op (zeer) grote schaal vervaardigen c.q. bewerken van BMK van uit een preprecursor en amfetamine met behulp van de ter plaatse vervaardigde BMK met behulp van een rvs reactieketel (loog) met een inhoudsmaat van 1500 liter. \n",
      "\n",
      "Op moment van ontdekking was de productieplaats in werking11.  \n",
      "\n",
      "Verdachte is tijdens de inval op het perceel aan de [straatnaam] te Minnertsga in het lab aangetroffen.12 Hij heeft onder meer kookwerkzaamheden verricht in het laboratorium.13 Verder was ook medeverdachte [medeverdachte] in het lab aan het werk.14 \n",
      "\n",
      "Medeplegen \n",
      "\n",
      "De rechtbank stelt voorop dat de betrokkenheid aan een strafbaar feit als medeplegen kan worden bewezenverklaard indien is komen vast te staan dat bij het begaan daarvan sprake is geweest van een voldoende nauwe en bewuste samenwerking. \n",
      "\n",
      "Uit de bewijsmiddelen leidt de rechtbank met betrekking tot de betrokkenheid van verdachte bij het tenlastegelegde het volgende af. \n",
      "\n",
      "Verdachte werkte mee aan het productieproces van amfetamine in het lab. \n",
      "\n",
      "Hij voerde onder meer werkzaamheden uit als de kok. \n",
      "\n",
      "Samen met verdachte is de medeverdachte [medeverdachte] op 19 februari 2021 in het lab aangetroffen. \n",
      "\n",
      "De medeverdachte verrichtte hier ook werkzaamheden in opdracht van verdachte. \n",
      "\n",
      "Op grond van het voorgaande oordeelt de rechtbank dat sprake is geweest van een voldoende nauwe en bewuste samenwerking tussen verdachte en zijn medeverdachte die in de kern bestaat uit een gezamenlijke uitvoering. \n",
      "\n",
      "Daarmee acht de rechtbank het tenlastegelegde medeplegen bewezen. \n",
      "\n",
      "Periode  \n",
      "\n",
      "Aan verdachte is ten laste gelegd dat hij in de periode van 1 oktober 2020 tot en met 19 februari 2021 zich schuldig heeft gemaakt aan het meewerken in het productielab van amfetamine. \n",
      "\n",
      "De rechtbank stelt vast dat verdachte op 19 februari 2021 door de politie wordt aangetroffen op het perceel aan de [straatnaam] . \n",
      "\n",
      "In het dossier zijn aanwijzingen voorhanden dat er in het aangetroffen productielab reeds een langere periode amfetamine is geproduceerd maar niet kan worden vastgesteld dat verdachte hierbij betrokken is geweest. \n",
      "\n",
      "Wel kan worden vastgesteld dat verdachte in ieder geval een dag voor de inval toen medeverdachte daar aankwam aanwezig was in het productielab. \n",
      "\n",
      "De rechtbank komt net als de officier van justitie en de raadsman tot het oordeel dat enkel de periode van 18 tot en met 19 februari 2021 wettig en overtuigend bewezen kan worden. \n",
      "\n",
      "Van de overige ten laste gelegde periode zal de rechtbank verdachte vrijspreken. \n",
      "\n",
      "Feit 2.  \n",
      "\n",
      "Bij het produceren van synthetische drugs komt afval vrij. \n",
      "\n",
      "Uit onderzoek is gebleken dat er afvalwater vanuit het laboratorium werd geloosd in de naastgelegen sloot en daarmee in het oppervlaktewater. \n",
      "\n",
      "In de ruimte van het laboratorium was zichtbaar dat vanaf een grote IBC (container) een overloop was aangesloten op een PVC buis en vervolgens op een gele slang. \n",
      "\n",
      "Deze gele slang lag langs de wand en kwam door de wand naar buiten. \n",
      "\n",
      "Vervolgens hing de gele slang in een afvoerput. \n",
      "\n",
      "Hierdoor kwam het afvalwater verderop op het perceel in de sloot terecht. \n",
      "\n",
      "De vraag die de rechtbank dient te beantwoorden is of verdachte deze constructie heeft aangelegd dan wel wist dat het afvalwater op deze manier werd geloosd. \n",
      "\n",
      "De rechtbank is van oordeel dat uit de voorhanden zijnde stukken niet kan worden opgemaakt door wie het laboratorium is opgebouwd en daarmee de constructie voor de afvoer van het afvalwater. \n",
      "\n",
      "Verder is de rechtbank van oordeel dat op grond van het beschikbare strafdossier niet wettig en overtuigend kan worden bewezen dat verdachte wist of had kunnen weten dat het afvalwater buiten het laboratorium via een afvoerput die uitkomt in de sloot in oppervlaktewater werd geloosd. \n",
      "\n",
      "De gele slang kwam uit in een afvoerput waarbij niet direct zichtbaar was en ook niet meteen voor de hand liggend was dat deze put loosde op het oppervlaktewater. \n",
      "\n",
      "De rechtbank zal verdachte van feit 2 vrijspreken.  \n",
      "\n",
      "Bewezenverklaring \n",
      "\n",
      "De rechtbank acht feit 1 wettig en overtuigend bewezen met dien verstande dat:   \n",
      "\n",
      "1. \n",
      "\n",
      "hij in de periode van 18 februari 2021 tot en met 19 februari 2021 te Minnertsga tezamen en in vereniging met anderen opzettelijk heeft bereid en bewerkt en verwerkt en vervaardigd en aanwezig heeft gehad hoeveelheden van een materiaal bevattende amfetamine (speed) zijnde amfetamine (speed) een middel als bedoeld in de bij de Opiumwet behorende lijst I.  \n",
      "\n",
      "Verdachte zal van het meer of anders ten laste gelegde worden vrijgesproken aangezien de rechtbank dat niet bewezen acht. \n",
      "\n",
      "Voor zover in de tenlastelegging taal- en/of schrijffouten voorkomen zijn deze in de bewezenverklaring verbeterd. \n",
      "\n",
      "Verdachte is daardoor niet geschaad in de verdediging. \n",
      "\n",
      "Strafbaarheid van het bewezen verklaarde  \n",
      "\n",
      "Het bewezen verklaarde levert op:  \n",
      "\n",
      "1. \n",
      "\n",
      "Medeplegen van opzettelijk handelen in strijd met het in artikel 2 onder C van de Opiumwet gegeven verbod. \n",
      "\n",
      "Dit feit is strafbaar nu geen omstandigheden aannemelijk zijn geworden die de strafbaarheid uitsluiten.  \n",
      "\n",
      "Strafbaarheid van verdachte \n",
      "\n",
      "De rechtbank acht verdachte strafbaar nu niet van enige strafuitsluitingsgrond is gebleken.  \n",
      "\n",
      "Strafmotivering \n",
      "\n",
      "Vordering van de officier van justitie \n",
      "\n",
      "De officier van justitie heeft gevorderd dat verdachte wordt veroordeeld tot een gevangenisstraf voor de duur van 30 maanden met aftrek van de dagen doorgebracht in voorarrest. \n",
      "\n",
      "Standpunt van de verdediging \n",
      "\n",
      "De raadsman heeft verzocht een lagere straf op te leggen dan geëist door de officier van justitie gelet op de bepleite vrijspraak van feit 2. \n",
      "\n",
      "Oordeel van de rechtbank \n",
      "\n",
      "Bij de bepaling van de straf heeft de rechtbank rekening gehouden met de aard en de ernst van het bewezen en strafbaar verklaarde de omstandigheden waaronder dit is begaan de persoon van verdachte zoals deze naar voren is gekomen uit het onderzoek ter terechtzitting het uittreksel uit de justitiële documentatie alsmede de vordering van de officier van justitie en het pleidooi van de verdediging. \n",
      "\n",
      "De rechtbank heeft in het bijzonder het volgende in aanmerking genomen. \n",
      "\n",
      "Verdachte heeft zich samen met anderen schuldig gemaakt aan de productie van amfetamine. \n",
      "\n",
      "Het is algemeen bekend dat de productie van synthetische drugs en verdovende middelen in het algemeen zeer schadelijk is voor de volksgezondheid en bovenal voor de gezondheid van de gebruikers van deze middelen. \n",
      "\n",
      "Bovendien bekostigen gebruikers hun drugsgebruik vaak door diefstal of ander crimineel gedrag waardoor schade en overlast wordt toegebracht aan anderen. \n",
      "\n",
      "Het chemisch afval dat ontstaat bij de productie wordt vrijwel altijd illegaal gedumpt hetgeen zeer schadelijk is voor het milieu. \n",
      "\n",
      "Ook bij het laboratorium waarin verdachte werkte werd afval geloosd in het oppervlaktewater. \n",
      "\n",
      "Zowel de productie van een synthetische drug zoals amfetamine als het daaruit voorkomende chemische afval en het dumpen van dat afval zijn dan ook maatschappelijk ontwrichtend. \n",
      "\n",
      "De verdachte heeft kennelijk enkel gedacht aan zijn eigen financiële gewin en zich totaal niet bekommerd om de risico’s voor omwonenden en de schadelijke gevolgen van zijn handelen voor anderen en het milieu. \n",
      "\n",
      "De rechtbank heeft tevens in aanmerking genomen dat verdachte eerder onherroepelijk is veroordeeld voor soortgelijke strafbare feiten tot forse gevangenisstraffen. \n",
      "\n",
      "De rechtbank neemt mee in haar overweging dat zij anders dan de officier van justitie alleen tot een bewezenverklaring komt van feit 1. \n",
      "\n",
      "Gelet daarop zal de rechtbank een lagere straf opleggen dan de officier van justitie heeft geëist.  \n",
      "\n",
      "Alles afwegende is de rechtbank van oordeel dat gelet op de ernst van het feit een gevangenisstraf voor de duur van 24 maanden passend en geboden is. \n",
      "\n",
      "Toepassing van wetsartikelen \n",
      "\n",
      "De rechtbank heeft gelet op artikel 47 van het Wetboek van Strafrecht en de artikelen 2 10 van de Opiumwet. \n",
      "\n",
      "Deze voorschriften zijn toegepast zoals zij ten tijde van het bewezen verklaarde rechtens golden dan wel ten tijde van deze uitspraak gelden.  \n",
      "\n",
      "Uitspraak  \n",
      "\n",
      "De rechtbank  \n",
      "\n",
      "Verklaart niet bewezen hetgeen verdachte onder 2 is ten laste gelegd en spreekt verdachte daarvan vrij.  \n",
      "\n",
      "Verklaart het onder 1 ten laste gelegde bewezen te kwalificeren en strafbaar zoals voormeld en verdachte daarvoor strafbaar. \n",
      "\n",
      "Verklaart niet bewezen hetgeen aan verdachte meer of anders is ten laste gelegd dan het bewezen verklaarde en spreekt verdachte daarvan vrij.  \n",
      "\n",
      "Veroordeelt verdachte tot: \n",
      "\n",
      "een gevangenisstraf voor de duur van 24 maanden.   \n",
      "\n",
      "Beveelt dat de tijd die de veroordeelde voor de tenuitvoerlegging van deze uitspraak in verzekering en/of voorlopige hechtenis heeft doorgebracht bij de uitvoering van de opgelegde gevangenisstraf geheel in mindering zal worden gebracht.  \n",
      "\n",
      "Dit vonnis is gewezen door mr. \n",
      "\n",
      "A.H.M. \n",
      "\n",
      "Dölle voorzitter mr. \n",
      "\n",
      "R.B. \n",
      "\n",
      "Maring en mr. \n",
      "\n",
      "C.A.J. \n",
      "\n",
      "Tuinstra rechters bijgestaan door W. van Goor griffier en uitgesproken ter openbare terechtzitting van deze rechtbank op 1 oktober 2021. \n",
      "\n",
      "Mr. C.A.J. \n",
      "\n",
      "Tuinstra is buiten staat dit vonnis mede te ondertekenen. \n",
      "\n",
      " Wanneer hierna wordt verwezen naar doorgenummerde dossierpagina’s betreft dit delen van ambtsedige processen-verbaal als bijlagen opgenomen bij het dossier met het nummer 2021042068 doorgenummerd 1 tot en met 907. \n",
      "\n",
      " Pagina 473 e.v. \n",
      "\n",
      " Proces-verbaal bevindingen ondersteuning LFO los bijgevoegd. \n",
      "\n",
      " Pagina 502 ev. \n",
      "\n",
      " Rapport NFI d.d. 3 mei 2021 zaaknummer 2021.03.10.103 opgemaakt door ing. \n",
      "\n",
      "A.G.A. \n",
      "\n",
      "Sprong \n",
      "\n",
      " Zie voetnoot 5. \n",
      "\n",
      " Zie voetnoot 5. \n",
      "\n",
      " Zie voetnoot 5. \n",
      "\n",
      " Zie voetnoot 5. \n",
      "\n",
      "10 \n",
      "\n",
      " Zie voetnoot 5. \n",
      "\n",
      "11 \n",
      "\n",
      " Zie voetnoot 3.  \n",
      "\n",
      "12 \n",
      "\n",
      " Pagina 131 icm pagina 133 en pagina 140 \n",
      "\n",
      "13 \n",
      "\n",
      " Pagina 179 ev. \n",
      "\n",
      "14 \n",
      "\n",
      " Pagina 175 ev. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in sentence_list[:1]:\n",
    "    for j in i:\n",
    "        print(j, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rechtbank \n",
      "\n",
      "noord-nederland \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in sentence_list_by_word[:1]:\n",
    "    for j in i:\n",
    "        print(j, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18124\n"
     ]
    }
   ],
   "source": [
    "print(len(sentence_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5107544\n"
     ]
    }
   ],
   "source": [
    "print(len(sentence_list_by_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import common_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dutch_word2vec_model = Word2Vec(sentences=sentence_list_by_word, vector_size=100, window=5, min_count=1, workers=4)\n",
    "dutch_word2vec_model.save(\"word2vec_dutch_court_cases.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dutch_word2vec_model = Word2Vec.load(\"word2vec_dutch_court_cases.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['export', 'import', 'invoer', 'doorvoer', 'verkoop', 'handel', 'aanvoer', 'versnijding', 'gesmokkelde', 'drugssmokkel', 'productie/verwerking', 'exporteren', 'transporteren', 'bronlanden', 'invoeren', 'verhandeling', 'leverantie', 'importeren', 'uithalen', 'binnenbrengen', 'cocaïnehandel', 'binnensmokkelen', 'doorlevering', 'smokkelen', 'overdracht', 'drugstransporten', 'fabricage', 'wederverkoop', 'bronland', 'levering', 'afleveringen', 'dealen', '(synthetische)', 'transporten', 'doorverkoop', 'aankoop', 'terugwinnen', 'verspreiding', 'straatverkoop', 'productie', 'produktie', 'georganiseerde', 'transsport', 'leveranciers', 'aankopen', 'transport', 'verhandelen', 'vervaardiging', 'vondst', 'verwerking', 'terugwinproces', 'versnijden', 'drugshandel', 'vermenging', 'overdrachten', 'organisatoren', 'grootschalige', 'kweek', 'doorlating', 'cocaïnesmokkel', 'distributie', 'soft', 'uithaal', 'straathandel', 'drugsroute', 'verkopers', 'hennepteelt', 'overdacht', 'hasjtransporten', 'suppressant', 'producenten', 'handelaren', 'synthetische', 'aamo9018nl', 'verkopen/afleveren/verstrekken', '(invoer', 'bewerking', '(grootschalige)', 'verwerkingsproces', 'in-/uitvoer', 'verkooppunten', 'versnijdingenmiddel', 'aciviteiten', 'aanschaf', '(verhandelen', 'koeriers', 'leverancier', 'extractie', 'leveringen', '(internationale)', 'geldtransacties', 'afhalers', 'inkoopt', 'productie/bewerking', 'hennephandel', 'drugskartels', 'troepen', 'opzetten', '(aamm9114nl#03)', 'onderkennen/herkennen']\n"
     ]
    }
   ],
   "source": [
    "sims = dutch_word2vec_model.wv.most_similar('smokkel', topn=100)\n",
    "print([i[0] for i in sims])\n",
    "# print(sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create list of drugs, smuggle, quantity keywords with Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_word2vec_relevant_words(words, matches):\n",
    "    word2vec_list = []\n",
    "    for word in words:\n",
    "        results = dutch_word2vec_model.wv.most_similar(word, topn=100)\n",
    "        for i in results:\n",
    "            word2vec_list.append(i[0])\n",
    "            \n",
    "    word2vec_list = list(set([i for i in word2vec_list if word2vec_list.count(i)>matches]))\n",
    "    return word2vec_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drugs list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n",
      "['mdma-hcl', 'speed', 'hasjiesj', 'aceton', 'ecstasy', 'crack', 'hennep', 'xtc', 'mdma-tabletten', 'morfine', 'xtc-tabletten', 'lidocaïne', 'crystal', 'tolueen', 'weed', 'amfetamine)', 'diazepam', 'amfetamine', 'heroïne;', 'pasta', 'xtc/mdma', 'tabletten', 'mdma', 'harddrugs', 'mefedron', 'cafeïne', 'mdma-pillen', 'lsd', 'amfetaminepasta', 'temazepam', 'meth', 'drugs', '34-methyleendioxymethamfetamine', 'manitol', 'speed/amfetamine', 'opium', 'zwavelzuur', 'metamfetamine', 'kristallen', 'olie', 'methadon', 'pillen)', 'cannabis', 'gbl', 'oxazepam', 'amfetamine/speed', 'heroïne)', 'hasj', 'amfetamineolie', 'methanol', '(mdma)', 'paracetamol', 'pillen', 'xtc-pillen', 'pep', 'cocaïne', 'coke', '2c-b', 'hashish', 'n-formylamfetamine', 'fenacetine', 'amfetaminesulfaat', 'heroïne', 'hash', 'ketamine', 'cocaïne;', 'ghb', 'methamfetamine', 'poedervorm', 'amfetaminen', '(mdma', 'mdma-kristallen', 'cocaïne?', 'azijnzuuranhydride', 'marihuana', 'mapa', 'eindproduct', 'mdma-poeder', 'amfetaminebase']\n"
     ]
    }
   ],
   "source": [
    "list_of_drugs = ['xtc', 'mdma', 'cocaine', 'wiet', 'speed', 'bmk', 'pmk']\n",
    "word2vec_drug_list = create_word2vec_relevant_words(list_of_drugs, 2)\n",
    "\n",
    "print(len(word2vec_drug_list))\n",
    "print(word2vec_drug_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n"
     ]
    }
   ],
   "source": [
    "drugs_to_exclude = ['pasta', 'kristallen', 'poedervorm']\n",
    "word2vec_drug_list = [drug for drug in word2vec_drug_list if drug not in drugs_to_exclude]\n",
    "print(len(word2vec_drug_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smuggle keyword list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "['vervaardiging', 'gesmokkelde', 'levering', 'transporten', 'uithalen', 'produktie', 'organisatoren', 'hennepteelt', 'leverantie', 'invoeren', 'aankoop', 'handel', 'invoer', 'productie', 'importeren', 'transsport', 'bewerking', 'kweek', 'bronland', 'terugwinnen', 'in-/uitvoer', 'leverancier', 'verhandeling', 'smokkel', 'leveranciers', 'cocaïnehandel', 'transporteren', 'doorverkoop', 'exporteren', 'straatverkoop', 'export', 'versnijding', '(grootschalige)', 'uitvoer', 'doorvoer', 'versnijden', 'productie/verwerking', 'fabricage', 'transport', 'bronlanden', '(invoer', 'doorlevering', 'verkoop', 'aanvoer', 'import']\n"
     ]
    }
   ],
   "source": [
    "list_of_smuggle_words = ['smokkel', 'invoer', 'uitvoer', 'import', 'export', 'transport']\n",
    "word2vec_smuggle_list = create_word2vec_relevant_words(list_of_smuggle_words, 3)\n",
    "\n",
    "word2vec_smuggle_list = list(set(word2vec_smuggle_list + list_of_smuggle_words ))\n",
    "print(len(word2vec_smuggle_list))\n",
    "print(word2vec_smuggle_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drugs_to_exclude = ['pasta', 'kristallen', 'poedervorm']\n",
    "# word2vec_drug_list = [drug for drug in word2vec_drug_list if drug not in drugs_to_exclude]\n",
    "# print(len(word2vec_drug_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantity keyword list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "['kg)', 'tabletten', 'mg)', 'mdma-pillen', 'milliliter', 'blokken', 'gram)', 'gram;', 'ton', 'ponypacks', 'bollen', 'balen', 'mg', 'gripzakjes', 'stuks', 'cm)', 'kilo', 'kilogram', 'bolletjes', 'joints', 'pillen', 'pakjes', 'kilogram)', 'drums', 'wikkels', 'xtc-pillen', 'zakjes', 'gram', 'liter', 'pakketten', 'kilo)', 'planten)']\n"
     ]
    }
   ],
   "source": [
    "list_of_quantity_words = ['tabletten', 'kilo', 'gram', 'pakketten']\n",
    "word2vec_quantity_list = create_word2vec_relevant_words(list_of_quantity_words, 2)\n",
    "\n",
    "word2vec_quantity_list = list(set(word2vec_quantity_list + list_of_quantity_words))\n",
    "print(len(word2vec_quantity_list))\n",
    "print(word2vec_quantity_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Country list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97\n",
      "['congo', 'parijs', 'pakistan', 'luxemburg', 'venezuela', 'dubai', 'zweden', 'dominicaanse', 'tsjechië', 'oostenrijk', 'brussel', 'slowakije', 'argentinië', 'peru', 'guayaquil', 'marokko', 'bosnië', 'kroatië', 'denemarken', 'kinshasa', 'sao', 'hongarije', 'litouwen', 'belgië', 'china', 'suriname', 'caracas', 'santa', 'australië', 'syrië', 'buitenland', 'curaçao', 'bulgarije', 'nederland', 'sierra', 'singapore', 'duitsland)', 'sevilla', 'berlijn', 'frankrijk', 'trinidad', 'canada', 'hamburg', 'rabat', 'roemenië', 'ecuador', 'hannover', 'paulo', 'jamaica', 'thailand', 'antwerpen', 'engeland', 'tanger', 'lissabon', 'londen', 'chili', 'nigeria', 'madrid', 'europa', 'spanje', 'dover', 'polen', 'leone', 'brazilië', 'bogota', 'afrika', 'natal', 'portugal', 'mexico', 'noorwegen', 'paramaribo', 'republiek', 'rica', 'italië', 'groot-brittannië', 'costa', '[land]', 'zwitserland', 'irak', 'bremen', 'oekraïne', 'frankfurt', 'turkije', 'lima', 'zuid-amerika', 'rusland', 'panama', 'griekenland', 'amerika', 'kenia', 'servië', 'casablanca', 'barcelona', 'ghana', 'malaga', 'quito', 'ierland']\n"
     ]
    }
   ],
   "source": [
    "list_of_countries = ['duitsland', 'colombia', 'alicante']\n",
    "word2vec_country_list = create_word2vec_relevant_words(list_of_countries, 1)\n",
    "\n",
    "print(len(word2vec_country_list))\n",
    "print(word2vec_country_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Create SpaCy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "# !python -m spacy download nl_core_news_md\n",
    "nlp = spacy.load('nl_core_news_md')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "my_file = open(\"drugs list.txt\", \"r\", encoding='utf-8')\n",
    "my_file = my_file.readlines()\n",
    "drugs_list = []\n",
    "for i in my_file:\n",
    "    drugs_list.append(i.replace('\\n', ''))\n",
    "drugs_list = list(set(drugs_list + word2vec_drug_list))\n",
    "    \n",
    "my_file = open(\"countries list.txt\", \"r\", encoding='utf-8')\n",
    "my_file = my_file.readlines()\n",
    "countries_list = []\n",
    "for i in my_file:\n",
    "    countries_list.append(i.replace('\\n', ''))\n",
    "countries_list = list(set(countries_list + word2vec_country_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def configure_spacy_model():\n",
    "    # Create dict of drug pattern and quantity pattern\n",
    "    pattern_list = []\n",
    "    \n",
    "    for i in drugs_list:\n",
    "        pattern_list.append({\"label\": \"DRUG\", \"pattern\": [{\"lower\": i}]})\n",
    "    \n",
    "#     quantity_rule = {\"label\": \"QUANTITY\", \"pattern\": [{\"IS_DIGIT\": True}, {\"LOWER\": \"gram\"}]}\n",
    "#     pattern_list.append(quantity_rule)\n",
    "    for i in word2vec_quantity_list:\n",
    "        pattern_list.append({\"label\": \"QUANTITY\", \"pattern\": [{\"IS_DIGIT\": True}, {\"LOWER\": i}]})\n",
    "        pattern_list.append({\"label\": \"QUANTITY\", \"pattern\": [{\"ENT_TYPE\": \"CARDINAL\"}, {\"LOWER\": i}]})\n",
    "    \n",
    "    for i in countries_list:\n",
    "        pattern_list.append({\"label\": \"GPE\", \"pattern\": [{\"lower\": i.replace(' ', '').lower()}]})\n",
    "    \n",
    "    # Add drug and quantity rules to the model\n",
    "    config = {\n",
    "   \"phrase_matcher_attr\": None,\n",
    "   \"validate\": True,\n",
    "   \"overwrite_ents\": True,\n",
    "   \"ent_id_sep\": \"||\",\n",
    "    }\n",
    "    ruler = nlp.add_pipe(\"entity_ruler\", config=config)\n",
    "\n",
    "    #List of Entities and Patterns\n",
    "#     patterns = drugs_ent_list\n",
    "    ruler.add_patterns(pattern_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "configure_spacy_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select cases and chunks to keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(len(sentence_list) == len(merged_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every case, split the sentences. If a sentence in a case contains a drug, a smuggle word, and a location: keep chunk and save to trafficking_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relevant_chunk_list = []\n",
    "# ecli_list = []\n",
    "\n",
    "# for index, case in enumerate(sentence_list):\n",
    "#     chunk_list = []\n",
    "#     trafficking_related = False\n",
    "#     for chunk in case:\n",
    "#         if any(drug in chunk for drug in word2vec_drug_list) and any(smuggle_word in chunk for smuggle_word in word2vec_smuggle_list):\n",
    "#             ents = nlp(chunk).ents\n",
    "#             if any(ent.label_ == \"GPE\" or ent.label_ == \"LOC\" for ent in ents):\n",
    "#                 trafficking_related = True\n",
    "#                 chunk_list.append(chunk)\n",
    "#     if trafficking_related:\n",
    "#         relevant_chunk_list.append(chunk_list)\n",
    "#         ecli_list.append(merged_df.iloc[index]['id'].replace('-', ':'))\n",
    "\n",
    "# trafficking_df = pd.DataFrame({'id': pd.Series(ecli_list), 'chunks': pd.Series(relevant_chunk_list)})                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_chunk_list = []\n",
    "ecli_list = []\n",
    "\n",
    "for index, case in enumerate(sentence_list):\n",
    "    chunk_list = []\n",
    "    trafficking_related = False\n",
    "    for chunk in case:\n",
    "        word_list = [x for x in chunk.lower().rstrip().replace('.', '').split(' ') if len(x)>0]\n",
    "        if any(drug in word_list for drug in word2vec_drug_list) and any(smuggle_word in word_list for smuggle_word in word2vec_smuggle_list):\n",
    "            ents = nlp(chunk).ents\n",
    "            if any(ent.label_ == \"GPE\" or ent.label_ == \"LOC\" for ent in ents):\n",
    "                trafficking_related = True\n",
    "                chunk_list.append(chunk)\n",
    "    if trafficking_related:\n",
    "        relevant_chunk_list.append(chunk_list)\n",
    "        ecli_list.append(merged_df.iloc[index]['id'].replace('-', ':'))\n",
    "\n",
    "trafficking_df = pd.DataFrame({'id': pd.Series(ecli_list), 'chunks': pd.Series(relevant_chunk_list)})       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2590 cases kept from original 18124 cases.\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(trafficking_df)} cases kept from original {len(merged_df)} cases.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create rule-based NER & POS tagging model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def extract_chunk_info(txt):\n",
    "    source_country = None\n",
    "    total_info = []\n",
    "    for token in nlp(txt):\n",
    "        info = {}\n",
    "        drug_info = {}\n",
    "        countries = []\n",
    "        \n",
    "        if token.ent_type_ == \"DRUG\":\n",
    "            info = {\"drug\": token.text}\n",
    "            \n",
    "            ## Get source and destination\n",
    "            for ancestor in token.ancestors:\n",
    "                for nephew in ancestor.children:\n",
    "                    if nephew.ent_type_ == \"GPE\" or nephew.ent_type_ == \"LOC\":\n",
    "                        countries.append(nephew)\n",
    "                        for child in nephew.children:\n",
    "                            if child.dep_ == \"conj\" and child.ent_type_ == \"GPE\" or child.ent_type_ == \"LOC\":\n",
    "                                countries.append(child.text)\n",
    "                            elif child.pos_ == \"ADP\" and child.dep_ == \"case\":\n",
    "                                adj = child.text\n",
    "            if len(countries) > 0 :\n",
    "                try:\n",
    "                    info[adj] = countries\n",
    "                except:\n",
    "                    info['land'] = countries\n",
    "                        \n",
    "            ## Get volume\n",
    "            for ancestors in token.ancestors:\n",
    "                for nephew in ancestors.children:\n",
    "                    if nephew.ent_type_ == \"QUANTITY\" or nephew.ent_type_ == \"CARDINAL\":\n",
    "                        for second_nephew in nephew.children:\n",
    "                            if second_nephew.is_digit != nephew.is_digit:\n",
    "                                if second_nephew.is_digit:\n",
    "                                    info['volume'] = second_nephew.text\n",
    "                                    info['volume_type'] = nephew.text\n",
    "                                else:\n",
    "                                    info['volume'] = nephew.text\n",
    "                                    info['volume_type'] = second_nephew.text\n",
    "            if 'volume' not in info:\n",
    "                for child in token.children:\n",
    "                    if (child.dep_ == \"det\" and child.like_num) or (child.dep_ == \"nummod\"):\n",
    "                        info['volume'] = child.text\n",
    "                                \n",
    "        if len(info) > 1:\n",
    "#             print(info)\n",
    "            total_info.append(info)\n",
    "    return total_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get linguistic distance between token a and token b. After iter 10 it is deemed a too far distance.\n",
    "def get_linguistic_distance(a, b):\n",
    "    tokens_to_consider = [b]\n",
    "    found = False\n",
    "    iters = 0\n",
    "    while not found:\n",
    "        for token in tokens_to_consider:\n",
    "            tokens_to_add = []\n",
    "            for ancestor in token.ancestors:\n",
    "                if ancestor not in tokens_to_add and ancestor not in tokens_to_consider:\n",
    "                    tokens_to_add.append(ancestor)\n",
    "            for child in token.children:\n",
    "                if child not in tokens_to_add and child not in tokens_to_consider:\n",
    "                    tokens_to_add.append(child)\n",
    "            tokens_to_consider = tokens_to_consider + tokens_to_add\n",
    "        for x in tokens_to_consider:\n",
    "            if a.orth == x.orth:\n",
    "                found = True\n",
    "        iters += 1\n",
    "        if iters == 10:\n",
    "            found = True\n",
    "    return iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adposition_from_loc(token):\n",
    "    for child in token.children:\n",
    "        if child.pos_ == \"ADP\" and child.dep_ == \"case\":\n",
    "            return child.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_chunk_info(txt):\n",
    "    result = {}\n",
    "    print('START CHUNK')\n",
    "    for token in nlp(txt):\n",
    "        if token.ent_type_ == \"DRUG\":\n",
    "            print(f\" \\n Extracting info for {token.text}.\")\n",
    "            drug_info = extract_info_from_drug(token, txt)\n",
    "            result[token.text] = drug_info\n",
    "    return result\n",
    "            \n",
    "            \n",
    "def extract_info_from_drug(drug, txt):\n",
    "    volumes = []\n",
    "    locations = {}\n",
    "    irrelevant_locations = []\n",
    "    for token in nlp(txt):\n",
    "        \n",
    "        # Extract countries\n",
    "#         if token.ent_type_ == \"GPE\" or token.ent_type_ == \"LOC\":\n",
    "        if token.ent_type_ == \"GPE\":\n",
    "            dist = get_linguistic_distance(drug, token)\n",
    "#             if dist < 15:\n",
    "            adj = get_adposition_from_loc(token)\n",
    "            print(f\"    {adj}: {token.text}, dist: {dist}, conj: {token.conjuncts}\")\n",
    "            locs = [token.text]\n",
    "            for loc in token.conjuncts:\n",
    "                locs.append(loc.text)\n",
    "            if adj not in locations:\n",
    "                locations[adj] = locs\n",
    "            else:\n",
    "                for loc in locs:\n",
    "                    if loc not in locations[adj]:\n",
    "                        locations[adj].append(loc)\n",
    "#             else:\n",
    "#                 irrelevant_locations.append(token.text)\n",
    "#                 print(f\"{token.text} is irrelevant.\")\n",
    "        \n",
    "        # Extract volume\n",
    "        if token.ent_type_ == \"QUANTITY\":\n",
    "            volume = {}\n",
    "            dist = get_linguistic_distance(drug, token)\n",
    "            second_token = \"\"\n",
    "#             if dist < 10:\n",
    "            quantity = {}\n",
    "            for ancestor in token.ancestors:\n",
    "                if ancestor.ent_type_ == \"QUANTITY\":\n",
    "                    second_token = ancestor\n",
    "            for child in token.children:\n",
    "                if child.ent_type_ == \"QUANTITY\":\n",
    "                    second_token = child\n",
    "\n",
    "            ## Decide volume and volume_type\n",
    "            if nlp(token.text)[0].ent_type_ == \"CARDINAL\":\n",
    "                volume['volume'] = token.text\n",
    "                volume['volume_type'] = second_token.text\n",
    "            elif nlp(second_token.text)[0].ent_type_ == \"CARDINAL\":\n",
    "                volume['volume'] = second_token.text\n",
    "                volume['volume_type'] = token.text\n",
    "            volume['dist'] = dist\n",
    "\n",
    "            #Only append when not already in volumes\n",
    "            if volume not in volumes:\n",
    "                volumes.append(volume)\n",
    "#             else:\n",
    "#                 print(f\"{token.text} is irrelevant.\")\n",
    "                \n",
    "        \n",
    "        \n",
    "            \n",
    "    print(volumes)\n",
    "\n",
    "    result = {}\n",
    "    if bool(locations):\n",
    "        result['locations'] = locations\n",
    "#     if len(volumes) > 0:\n",
    "    result[\"volume\"] = volumes\n",
    "    if len(irrelevant_locations) > 0:\n",
    "        result[\"irrelevant_locations\"] = irrelevant_locations\n",
    "    \n",
    "    return result\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECLI:NL:RBZUT:2003:AH9598\n",
      "START CHUNK\n",
      " \n",
      " Extracting info for aceton.\n",
      "    None: Haarlem, dist: 3, conj: (Amstelveen,)\n",
      "    None: Amstelveen, dist: 3, conj: (Haarlem,)\n",
      "[]\n",
      " \n",
      " Extracting info for drugs.\n",
      "    None: Haarlem, dist: 4, conj: (Amstelveen,)\n",
      "    None: Amstelveen, dist: 4, conj: (Haarlem,)\n",
      "[]\n",
      "Info: {'aceton': {'locations': {None: ['Haarlem', 'Amstelveen']}}, 'drugs': {'locations': {None: ['Haarlem', 'Amstelveen']}}} \n",
      "\n",
      "ECLI:NL:RBZWB:2020:2646\n",
      "START CHUNK\n",
      " \n",
      " Extracting info for BMK.\n",
      "    None: IBC-, dist: 10, conj: ()\n",
      "[{'volume': '241', 'volume_type': 'liter', 'dist': 2}, {'dist': 1}, {'volume': '8', 'volume_type': 'liter', 'dist': 2}, {'volume': '15', 'volume_type': 'liter', 'dist': 2}, {'volume': '5', 'volume_type': 'liter', 'dist': 2}, {'volume': '14', 'volume_type': 'liter', 'dist': 2}, {'dist': 10}]\n",
      " \n",
      " Extracting info for Benzylmethylketon.\n",
      "    None: IBC-, dist: 10, conj: ()\n",
      "[{'volume': '241', 'volume_type': 'liter', 'dist': 10}, {'dist': 10}, {'volume': '8', 'volume_type': 'liter', 'dist': 10}, {'volume': '15', 'volume_type': 'liter', 'dist': 10}, {'volume': '5', 'volume_type': 'liter', 'dist': 10}, {'volume': '14', 'volume_type': 'liter', 'dist': 10}]\n",
      " \n",
      " Extracting info for MAPA.\n",
      "    None: IBC-, dist: 10, conj: ()\n",
      "[{'volume': '241', 'volume_type': 'liter', 'dist': 3}, {'dist': 2}, {'volume': '8', 'volume_type': 'liter', 'dist': 3}, {'volume': '15', 'volume_type': 'liter', 'dist': 3}, {'volume': '5', 'volume_type': 'liter', 'dist': 3}, {'volume': '14', 'volume_type': 'liter', 'dist': 3}, {'dist': 10}]\n",
      " \n",
      " Extracting info for BMK.\n",
      "    None: IBC-, dist: 10, conj: ()\n",
      "[{'volume': '241', 'volume_type': 'liter', 'dist': 2}, {'dist': 1}, {'volume': '8', 'volume_type': 'liter', 'dist': 2}, {'volume': '15', 'volume_type': 'liter', 'dist': 2}, {'volume': '5', 'volume_type': 'liter', 'dist': 2}, {'volume': '14', 'volume_type': 'liter', 'dist': 2}, {'dist': 10}]\n",
      " \n",
      " Extracting info for zwavelzuur.\n",
      "    None: IBC-, dist: 10, conj: ()\n",
      "[{'volume': '241', 'volume_type': 'liter', 'dist': 3}, {'dist': 2}, {'volume': '8', 'volume_type': 'liter', 'dist': 2}, {'volume': '8', 'volume_type': 'liter', 'dist': 1}, {'volume': '15', 'volume_type': 'liter', 'dist': 3}, {'volume': '5', 'volume_type': 'liter', 'dist': 3}, {'volume': '14', 'volume_type': 'liter', 'dist': 3}, {'dist': 10}]\n",
      " \n",
      " Extracting info for MAPA.\n",
      "    None: IBC-, dist: 10, conj: ()\n",
      "[{'volume': '241', 'volume_type': 'liter', 'dist': 3}, {'dist': 2}, {'volume': '8', 'volume_type': 'liter', 'dist': 3}, {'volume': '15', 'volume_type': 'liter', 'dist': 3}, {'volume': '5', 'volume_type': 'liter', 'dist': 3}, {'volume': '14', 'volume_type': 'liter', 'dist': 3}, {'dist': 10}]\n",
      " \n",
      " Extracting info for mierenzuur.\n",
      "    None: IBC-, dist: 10, conj: ()\n",
      "[{'volume': '241', 'volume_type': 'liter', 'dist': 3}, {'dist': 2}, {'volume': '8', 'volume_type': 'liter', 'dist': 3}, {'volume': '15', 'volume_type': 'liter', 'dist': 2}, {'volume': '15', 'volume_type': 'liter', 'dist': 1}, {'volume': '5', 'volume_type': 'liter', 'dist': 3}, {'volume': '14', 'volume_type': 'liter', 'dist': 3}, {'dist': 10}]\n",
      " \n",
      " Extracting info for formamide.\n",
      "    None: IBC-, dist: 10, conj: ()\n",
      "[{'volume': '241', 'volume_type': 'liter', 'dist': 3}, {'dist': 2}, {'volume': '8', 'volume_type': 'liter', 'dist': 3}, {'volume': '15', 'volume_type': 'liter', 'dist': 3}, {'volume': '5', 'volume_type': 'liter', 'dist': 2}, {'volume': '5', 'volume_type': 'liter', 'dist': 1}, {'volume': '14', 'volume_type': 'liter', 'dist': 2}, {'dist': 10}]\n",
      " \n",
      " Extracting info for methanol.\n",
      "    None: IBC-, dist: 10, conj: ()\n",
      "[{'volume': '241', 'volume_type': 'liter', 'dist': 4}, {'dist': 3}, {'volume': '8', 'volume_type': 'liter', 'dist': 4}, {'volume': '15', 'volume_type': 'liter', 'dist': 4}, {'volume': '5', 'volume_type': 'liter', 'dist': 3}, {'volume': '5', 'volume_type': 'liter', 'dist': 2}, {'volume': '14', 'volume_type': 'liter', 'dist': 2}, {'dist': 10}]\n",
      "Info: {'BMK': {'locations': {None: ['IBC-']}, 'volume': [{'volume': '241', 'volume_type': 'liter', 'dist': 2}, {'dist': 1}, {'volume': '8', 'volume_type': 'liter', 'dist': 2}, {'volume': '15', 'volume_type': 'liter', 'dist': 2}, {'volume': '5', 'volume_type': 'liter', 'dist': 2}, {'volume': '14', 'volume_type': 'liter', 'dist': 2}, {'dist': 10}]}, 'Benzylmethylketon': {'locations': {None: ['IBC-']}, 'volume': [{'volume': '241', 'volume_type': 'liter', 'dist': 10}, {'dist': 10}, {'volume': '8', 'volume_type': 'liter', 'dist': 10}, {'volume': '15', 'volume_type': 'liter', 'dist': 10}, {'volume': '5', 'volume_type': 'liter', 'dist': 10}, {'volume': '14', 'volume_type': 'liter', 'dist': 10}]}, 'MAPA': {'locations': {None: ['IBC-']}, 'volume': [{'volume': '241', 'volume_type': 'liter', 'dist': 3}, {'dist': 2}, {'volume': '8', 'volume_type': 'liter', 'dist': 3}, {'volume': '15', 'volume_type': 'liter', 'dist': 3}, {'volume': '5', 'volume_type': 'liter', 'dist': 3}, {'volume': '14', 'volume_type': 'liter', 'dist': 3}, {'dist': 10}]}, 'zwavelzuur': {'locations': {None: ['IBC-']}, 'volume': [{'volume': '241', 'volume_type': 'liter', 'dist': 3}, {'dist': 2}, {'volume': '8', 'volume_type': 'liter', 'dist': 2}, {'volume': '8', 'volume_type': 'liter', 'dist': 1}, {'volume': '15', 'volume_type': 'liter', 'dist': 3}, {'volume': '5', 'volume_type': 'liter', 'dist': 3}, {'volume': '14', 'volume_type': 'liter', 'dist': 3}, {'dist': 10}]}, 'mierenzuur': {'locations': {None: ['IBC-']}, 'volume': [{'volume': '241', 'volume_type': 'liter', 'dist': 3}, {'dist': 2}, {'volume': '8', 'volume_type': 'liter', 'dist': 3}, {'volume': '15', 'volume_type': 'liter', 'dist': 2}, {'volume': '15', 'volume_type': 'liter', 'dist': 1}, {'volume': '5', 'volume_type': 'liter', 'dist': 3}, {'volume': '14', 'volume_type': 'liter', 'dist': 3}, {'dist': 10}]}, 'formamide': {'locations': {None: ['IBC-']}, 'volume': [{'volume': '241', 'volume_type': 'liter', 'dist': 3}, {'dist': 2}, {'volume': '8', 'volume_type': 'liter', 'dist': 3}, {'volume': '15', 'volume_type': 'liter', 'dist': 3}, {'volume': '5', 'volume_type': 'liter', 'dist': 2}, {'volume': '5', 'volume_type': 'liter', 'dist': 1}, {'volume': '14', 'volume_type': 'liter', 'dist': 2}, {'dist': 10}]}, 'methanol': {'locations': {None: ['IBC-']}, 'volume': [{'volume': '241', 'volume_type': 'liter', 'dist': 4}, {'dist': 3}, {'volume': '8', 'volume_type': 'liter', 'dist': 4}, {'volume': '15', 'volume_type': 'liter', 'dist': 4}, {'volume': '5', 'volume_type': 'liter', 'dist': 3}, {'volume': '5', 'volume_type': 'liter', 'dist': 2}, {'volume': '14', 'volume_type': 'liter', 'dist': 2}, {'dist': 10}]}} \n",
      "\n",
      "START CHUNK\n",
      " \n",
      " Extracting info for BMK.\n",
      "    tussen: Gemeenschap, dist: 10, conj: (landen,)\n",
      "[]\n",
      " \n",
      " Extracting info for zwavelzuur.\n",
      "    tussen: Gemeenschap, dist: 10, conj: (landen,)\n",
      "[]\n",
      "Info: {'BMK': {'locations': {'tussen': ['Gemeenschap', 'landen']}}, 'zwavelzuur': {'locations': {'tussen': ['Gemeenschap', 'landen']}}} \n",
      "\n",
      "ECLI:NL:PHR:2007:BA1113\n",
      "START CHUNK\n",
      " \n",
      " Extracting info for hashish.\n",
      "[]\n",
      "Info: {'hashish': {}} \n",
      "\n",
      "START CHUNK\n",
      " \n",
      " Extracting info for drugs.\n",
      "    in: Nederland, dist: 1, conj: ()\n",
      "    in: Marokko, dist: 1, conj: ()\n",
      "[]\n",
      " \n",
      " Extracting info for drugs.\n",
      "    in: Nederland, dist: 1, conj: ()\n",
      "    in: Marokko, dist: 1, conj: ()\n",
      "[]\n",
      " \n",
      " Extracting info for drugs.\n",
      "    in: Nederland, dist: 1, conj: ()\n",
      "    in: Marokko, dist: 1, conj: ()\n",
      "[]\n",
      "Info: {'drugs': {'locations': {'in': ['Nederland', 'Marokko']}}} \n",
      "\n",
      "ECLI:NL:GHAMS:2018:2662\n",
      "START CHUNK\n",
      " \n",
      " Extracting info for cocaïne.\n",
      "    vanuit: Argentinië, dist: 2, conj: ()\n",
      "[{'volume': '900', 'volume_type': 'gram', 'dist': 2}, {'volume': '900', 'volume_type': 'gram', 'dist': 1}]\n",
      "Info: {'cocaïne': {'locations': {'vanuit': ['Argentinië']}, 'volume': [{'volume': '900', 'volume_type': 'gram', 'dist': 2}, {'volume': '900', 'volume_type': 'gram', 'dist': 1}]}} \n",
      "\n",
      "ECLI:NL:RBAMS:2017:9087\n",
      "START CHUNK\n",
      " \n",
      " Extracting info for cocaïne.\n",
      "    te: Rotterdam, dist: 3, conj: ()\n",
      "[]\n",
      "Info: {'cocaïne': {'locations': {'te': ['Rotterdam']}}} \n",
      "\n",
      "START CHUNK\n",
      " \n",
      " Extracting info for cocaïne.\n",
      "    in: Rotterdam, dist: 6, conj: ()\n",
      "[]\n",
      "Info: {'cocaïne': {'locations': {'in': ['Rotterdam']}}} \n",
      "\n",
      "START CHUNK\n",
      " \n",
      " Extracting info for cocaïne.\n",
      "    in: Rotterdam, dist: 3, conj: ()\n",
      "[]\n",
      "Info: {'cocaïne': {'locations': {'in': ['Rotterdam']}}} \n",
      "\n",
      "START CHUNK\n",
      " \n",
      " Extracting info for cocaïne.\n",
      "    None: I.6, dist: 10, conj: ()\n",
      "[]\n",
      "Info: {'cocaïne': {'locations': {None: ['I.6']}}} \n",
      "\n",
      "START CHUNK\n",
      " \n",
      " Extracting info for cocaïne.\n",
      "    in: Nederland, dist: 1, conj: ()\n",
      "[]\n",
      "Info: {'cocaïne': {'locations': {'in': ['Nederland']}}} \n",
      "\n",
      "ECLI:NL:RBAMS:2017:9085\n",
      "START CHUNK\n",
      " \n",
      " Extracting info for cocaïne.\n",
      "    in: Rotterdam, dist: 6, conj: ()\n",
      "[]\n",
      "Info: {'cocaïne': {'locations': {'in': ['Rotterdam']}}} \n",
      "\n",
      "START CHUNK\n",
      " \n",
      " Extracting info for cocaïne.\n",
      "    in: Rotterdam, dist: 3, conj: ()\n",
      "[]\n",
      "Info: {'cocaïne': {'locations': {'in': ['Rotterdam']}}} \n",
      "\n",
      "START CHUNK\n",
      " \n",
      " Extracting info for cocaïne.\n",
      "    None: I.6, dist: 10, conj: ()\n",
      "[]\n",
      "Info: {'cocaïne': {'locations': {None: ['I.6']}}} \n",
      "\n",
      "START CHUNK\n",
      " \n",
      " Extracting info for cocaïne.\n",
      "    in: Nederland, dist: 1, conj: ()\n",
      "[]\n",
      "Info: {'cocaïne': {'locations': {'in': ['Nederland']}}} \n",
      "\n",
      "ECLI:NL:RBAMS:2017:9086\n",
      "START CHUNK\n",
      " \n",
      " Extracting info for cocaïne.\n",
      "    None: I.6, dist: 10, conj: ()\n",
      "[]\n",
      "Info: {'cocaïne': {'locations': {None: ['I.6']}}} \n",
      "\n",
      "START CHUNK\n",
      " \n",
      " Extracting info for cocaïne.\n",
      "    in: Nederland, dist: 1, conj: ()\n",
      "[]\n",
      "Info: {'cocaïne': {'locations': {'in': ['Nederland']}}} \n",
      "\n",
      "ECLI:NL:RBAMS:2017:9088\n",
      "START CHUNK\n",
      " \n",
      " Extracting info for cocaïne.\n",
      "    in: Rotterdam, dist: 6, conj: ()\n",
      "[]\n",
      "Info: {'cocaïne': {'locations': {'in': ['Rotterdam']}}} \n",
      "\n",
      "START CHUNK\n",
      " \n",
      " Extracting info for cocaïne.\n",
      "    in: Rotterdam, dist: 2, conj: ()\n",
      "[]\n",
      "Info: {'cocaïne': {'locations': {'in': ['Rotterdam']}}} \n",
      "\n",
      "START CHUNK\n",
      " \n",
      " Extracting info for cocaïne.\n",
      "    None: I.6, dist: 10, conj: ()\n",
      "[]\n",
      "Info: {'cocaïne': {'locations': {None: ['I.6']}}} \n",
      "\n",
      "START CHUNK\n",
      " \n",
      " Extracting info for cocaïne.\n",
      "    in: Nederland, dist: 1, conj: ()\n",
      "[]\n",
      "Info: {'cocaïne': {'locations': {'in': ['Nederland']}}} \n",
      "\n",
      "ECLI:NL:RBAMS:2017:9089\n",
      "START CHUNK\n",
      " \n",
      " Extracting info for cocaïne.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    in: Nederland, dist: 2, conj: ()\n",
      "[{'volume': '234', 'volume_type': 'milliliter', 'dist': 2}, {'volume': '234', 'volume_type': 'milliliter', 'dist': 1}]\n",
      "Info: {'cocaïne': {'locations': {'in': ['Nederland']}, 'volume': [{'volume': '234', 'volume_type': 'milliliter', 'dist': 2}, {'volume': '234', 'volume_type': 'milliliter', 'dist': 1}]}} \n",
      "\n",
      "START CHUNK\n",
      " \n",
      " Extracting info for cocaïne.\n",
      "    in: Nederland, dist: 2, conj: ()\n",
      "    in: Nederland, dist: 4, conj: ()\n",
      "[]\n",
      "Info: {'cocaïne': {'locations': {'in': ['Nederland']}}} \n",
      "\n",
      "START CHUNK\n",
      " \n",
      " Extracting info for cocaïne.\n",
      "    in: Nederland, dist: 1, conj: ()\n",
      "[]\n",
      "Info: {'cocaïne': {'locations': {'in': ['Nederland']}}} \n",
      "\n",
      "START CHUNK\n",
      " \n",
      " Extracting info for cocaïne.\n",
      "    in: Rotterdam, dist: 6, conj: ()\n",
      "[]\n",
      "Info: {'cocaïne': {'locations': {'in': ['Rotterdam']}}} \n",
      "\n",
      "START CHUNK\n",
      " \n",
      " Extracting info for cocaïne.\n",
      "    in: Rotterdam, dist: 2, conj: ()\n",
      "[]\n",
      "Info: {'cocaïne': {'locations': {'in': ['Rotterdam']}}} \n",
      "\n",
      "START CHUNK\n",
      " \n",
      " Extracting info for cocaïne.\n",
      "    None: I.6, dist: 10, conj: ()\n",
      "[]\n",
      "Info: {'cocaïne': {'locations': {None: ['I.6']}}} \n",
      "\n",
      "START CHUNK\n",
      " \n",
      " Extracting info for cocaïne.\n",
      "    in: Nederland, dist: 1, conj: ()\n",
      "[]\n",
      "Info: {'cocaïne': {'locations': {'in': ['Nederland']}}} \n",
      "\n",
      "ECLI:NL:RBAMS:2017:9090\n",
      "START CHUNK\n",
      " \n",
      " Extracting info for cocaïne.\n",
      "    in: Nederland, dist: 2, conj: ()\n",
      "[{'volume': '234', 'volume_type': 'milliliter', 'dist': 2}, {'volume': '234', 'volume_type': 'milliliter', 'dist': 1}]\n",
      "Info: {'cocaïne': {'locations': {'in': ['Nederland']}, 'volume': [{'volume': '234', 'volume_type': 'milliliter', 'dist': 2}, {'volume': '234', 'volume_type': 'milliliter', 'dist': 1}]}} \n",
      "\n",
      "START CHUNK\n",
      " \n",
      " Extracting info for cocaïne.\n",
      "    in: Nederland, dist: 1, conj: ()\n",
      "    in: Nederland, dist: 8, conj: ()\n",
      "[]\n",
      "Info: {'cocaïne': {'locations': {'in': ['Nederland']}}} \n",
      "\n",
      "START CHUNK\n",
      " \n",
      " Extracting info for cocaïne.\n",
      "    in: Nederland, dist: 1, conj: ()\n",
      "[]\n",
      "Info: {'cocaïne': {'locations': {'in': ['Nederland']}}} \n",
      "\n",
      "START CHUNK\n",
      " \n",
      " Extracting info for cocaïne.\n",
      "    None: I.6, dist: 10, conj: ()\n",
      "[]\n",
      "Info: {'cocaïne': {'locations': {None: ['I.6']}}} \n",
      "\n",
      "START CHUNK\n",
      " \n",
      " Extracting info for cocaïne.\n",
      "    in: Nederland, dist: 1, conj: ()\n",
      "[]\n",
      "Info: {'cocaïne': {'locations': {'in': ['Nederland']}}} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(trafficking_df[:10])):\n",
    "    chunks = trafficking_df.iloc[i]['chunks']\n",
    "    id = trafficking_df.iloc[i]['id']\n",
    "    print(id)\n",
    "    for chunk in chunks:\n",
    "        info = extract_chunk_info(chunk)\n",
    "        print(f\"Info: {info} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ECLI:NL:RBZUT:2003:AH9598</td>\n",
       "      <td>[hij op tijdstippen in de periode 6 februari 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ECLI:NL:RBZWB:2020:2646</td>\n",
       "      <td>[- een (compleet) in werking zijnde laboratori...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ECLI:NL:PHR:2007:BA1113</td>\n",
       "      <td>[In de maand december 1998 ontstond onder ande...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ECLI:NL:GHAMS:2018:2662</td>\n",
       "      <td>[Dit feit heeft betrekking op een geslaagde in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ECLI:NL:RBAMS:2017:9087</td>\n",
       "      <td>[Verdachte heeft in de ochtend van 5 april 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2585</th>\n",
       "      <td>ECLI:NL:GHSHE:2020:1730</td>\n",
       "      <td>[Gezien het vorenstaande is het hof van oordee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2586</th>\n",
       "      <td>ECLI:NL:HR:1998:ZD1191</td>\n",
       "      <td>[\"4. hij in de periode van 1 januari 1993 tot ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2587</th>\n",
       "      <td>ECLI:NL:RBNHO:2013:10924</td>\n",
       "      <td>[Met de officier van justitie en de raadsvrouw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2588</th>\n",
       "      <td>ECLI:NL:GHSHE:2021:3205</td>\n",
       "      <td>[hij verdachte in of omstreeks de periode van ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2589</th>\n",
       "      <td>ECLI:NL:RBLIM:2018:3094</td>\n",
       "      <td>[De rechtbank concludeert voorts dat deze coca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2590 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             id  \\\n",
       "0     ECLI:NL:RBZUT:2003:AH9598   \n",
       "1       ECLI:NL:RBZWB:2020:2646   \n",
       "2       ECLI:NL:PHR:2007:BA1113   \n",
       "3       ECLI:NL:GHAMS:2018:2662   \n",
       "4       ECLI:NL:RBAMS:2017:9087   \n",
       "...                         ...   \n",
       "2585    ECLI:NL:GHSHE:2020:1730   \n",
       "2586     ECLI:NL:HR:1998:ZD1191   \n",
       "2587   ECLI:NL:RBNHO:2013:10924   \n",
       "2588    ECLI:NL:GHSHE:2021:3205   \n",
       "2589    ECLI:NL:RBLIM:2018:3094   \n",
       "\n",
       "                                                 chunks  \n",
       "0     [hij op tijdstippen in de periode 6 februari 2...  \n",
       "1     [- een (compleet) in werking zijnde laboratori...  \n",
       "2     [In de maand december 1998 ontstond onder ande...  \n",
       "3     [Dit feit heeft betrekking op een geslaagde in...  \n",
       "4     [Verdachte heeft in de ochtend van 5 april 201...  \n",
       "...                                                 ...  \n",
       "2585  [Gezien het vorenstaande is het hof van oordee...  \n",
       "2586  [\"4. hij in de periode van 1 januari 1993 tot ...  \n",
       "2587  [Met de officier van justitie en de raadsvrouw...  \n",
       "2588  [hij verdachte in of omstreeks de periode van ...  \n",
       "2589  [De rechtbank concludeert voorts dat deze coca...  \n",
       "\n",
       "[2590 rows x 2 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trafficking_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "case = list(trafficking_df[trafficking_df['id'] == 'ECLI:NL:GHAMS:2018:2662']['chunks'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Dit feit heeft betrekking op een geslaagde invoer van \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    900 gram\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">QUANTITY</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    cocaïne\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DRUG</span>\n",
       "</mark>\n",
       " vanuit \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Argentinië\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " door een persoon genaamd [naam \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    6\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       "].</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START CHUNK\n",
      " \n",
      " Extracting info for cocaïne.\n",
      "    vanuit: Argentinië, dist: 2, conj: ()\n",
      "[{'volume': '900', 'volume_type': 'gram'}]\n"
     ]
    }
   ],
   "source": [
    "for chunk in case:\n",
    "    displacy.render(nlp(chunk), style = 'ent')\n",
    "    extract_chunk_info(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entities(txt):\n",
    "    doc = nlp(txt)\n",
    "    for ent in doc.ents:\n",
    "        print(ent, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all loc entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_entities(entity):\n",
    "    for i in range(len(trafficking_df[:1000])):\n",
    "        chunks = list(trafficking_df.iloc[i]['chunks'])\n",
    "        for chunk in chunks:\n",
    "            doc = nlp(chunk)\n",
    "            for ent in doc.ents:\n",
    "                if ent.label_ == entity:\n",
    "#                     print(trafficking_df.iloc[i]['id'])\n",
    "                    print(ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gaswasser\n",
      "Noordzee\n",
      "Noordzee\n",
      "Noordzee\n",
      "Ettenseweg\n",
      "Klein Horendonk\n",
      "Klein Horendonk\n",
      "Klein Horendonk\n",
      "Klein Horendonk\n",
      "Klein Horendonk\n",
      "Klein Horendonk\n",
      "Maasdelta\n",
      "Maasdelta\n",
      "Rotterdamse haven\n",
      "medeveroordeelde\n",
      "medeveroordeelde\n",
      "medeveroordeelde\n",
      "medeveroordeelde\n",
      "medeveroordeelde\n",
      "medeveroordeelde\n",
      "medeveroordeelde\n",
      "medeveroordeelde\n",
      "Prins Clausstraat\n",
      "Westerschelde\n",
      "Noordzee\n",
      "Westerschelde\n",
      "Daartegenover\n",
      "Wvmc\n",
      "Rotterdamse haven\n",
      "medeveroordeelde\n",
      "Westerschelde\n",
      "Noordzee\n",
      "Westerschelde\n",
      "Westerschelde\n",
      "Maasdelta\n",
      "Maasdelta\n",
      "NFI-onderzoek\n",
      "Klein Horendonk\n",
      "Klein Horendonk\n",
      "Klein Horendonk\n",
      "Klein Horendonk\n",
      "Klein Horendonk\n",
      "Klein Horendonk\n",
      "NFI-onderzoek\n",
      "woning.2\n",
      "inrichting/opbouw\n",
      "Maasdelta\n",
      "Verderop\n",
      "NFI-onderzoek\n",
      "ZD04\n",
      "Westelijke Havendijk\n",
      "IJmond\n",
      "ZD04\n",
      "Leuckartmethode\n",
      "Leuckartmethode\n",
      "Eindhovenseweg\n",
      "Eindhovenseweg\n",
      "Eindhovenseweg\n",
      "Leuckartmethode\n",
      "Zuid\n",
      "Leuckartmethode\n",
      "koeriersauto\n",
      "Tonsdijk\n",
      "Leuckartmethode\n",
      "Zuid\n",
      "mengsels/substanties\n",
      "Klein Horendonk\n",
      "Klein Horendonk\n",
      "Tonsdijk\n",
      "Zuid-Limburgse\n",
      "Industrieweg\n",
      "Zuid\n",
      "Oost\n",
      "micro-cellulose\n",
      "micro-cellulose\n",
      "micro-cellulose\n",
      "Opiumwetbesluit\n",
      "Wieringerwaardstraat\n",
      "Luikerweg\n",
      "Luikerweg\n",
      "Rotterdamse haven\n",
      "verwijzingsbevel\n",
      "Pijp\n"
     ]
    }
   ],
   "source": [
    "list_entities(\"LOC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
