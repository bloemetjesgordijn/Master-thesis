{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb61f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0582ddb2",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Load SpaCy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d544508",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('models/configured_spacy_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b56994",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "txt = \"De verdachte smokkelde 123 kg mdma van Nederland naar Ibiza.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb8aa87",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "displacy.render(nlp(txt), style='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b6c04a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cbdd8912",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca72d32",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "merged_df = pd.read_pickle(\"merged_df.pkl\")\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1550e7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9980055",
   "metadata": {},
   "source": [
    "### Load country configs & country classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85851ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_file = open('saves/countries_to_exclude.pkl', \"rb\")\n",
    "countries_to_exclude = pickle.load(open_file)\n",
    "open_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17769144",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_file = open('saves/country_translation_dict.pkl', \"rb\")\n",
    "country_translation_dict = pickle.load(open_file)\n",
    "open_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a739e818",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = 'AIzaSyCcbIhMxSz5OP74pDT0aQLTvXDSMaV8tFk'\n",
    "geocode_url = 'https://maps.googleapis.com/maps/api/geocode/json?address='\n",
    "\n",
    "def get_geocode_country(txt):\n",
    "    res = requests.get(f\"{geocode_url}{txt}&key={api_key}\").json()['results']\n",
    "    country_name = \"None\"\n",
    "    try:\n",
    "        for address_component in res[0]['address_components']:\n",
    "            if 'country' in address_component['types']:\n",
    "                country_name = address_component['long_name']\n",
    "    except:\n",
    "        return \"None\"\n",
    "    return country_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb0e7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim(user_agent = \"geoapiExercises\")\n",
    "\n",
    "def get_geopy_country(txt):\n",
    "    try:\n",
    "        location = geolocator.geocode(txt, language='en')\n",
    "        country_name = location.raw['display_name'].split(',')[-1].strip()\n",
    "        return country_name\n",
    "    except:\n",
    "        return \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6889583d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def country_pipeline(txt):\n",
    "    txt = txt.lower()\n",
    "    # Check if already exists\n",
    "    if txt in countries_to_exclude:\n",
    "        return \"None\"\n",
    "    for key in country_translation_dict:\n",
    "        if txt in country_translation_dict[key]:\n",
    "            return key\n",
    "    \n",
    "    # Get location\n",
    "    geopy_loc = get_geopy_country(txt)\n",
    "    if geopy_loc == \"None\":\n",
    "        countries_to_exclude.append(txt)\n",
    "        return \"None\"\n",
    "    else:\n",
    "        geocode_loc = get_geocode_country(txt)\n",
    "        if geocode_loc == \"None\":\n",
    "            countries_to_exclude.append(txt)\n",
    "            geopy_mistakes[txt] = geopy_loc\n",
    "            return \"None\"\n",
    "        else:\n",
    "            if geocode_loc not in country_translation_dict:\n",
    "                country_translation_dict[geocode_loc] = []\n",
    "            country_translation_dict[geocode_loc].append(txt)\n",
    "            return geocode_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf12d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_pipeline('mek')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4c5251",
   "metadata": {},
   "source": [
    "### Filter cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b37240d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def split_text_in_chunks(doc):\n",
    "    chunks = re.split(r'(?<=[^A-Z].[.?]) +(?=[A-Z])|\\n', doc)\n",
    "    chunks = [x for x in chunks if len(x) > 1]\n",
    "    return chunks\n",
    "\n",
    "def split_cases_in_chunks(df):\n",
    "    return_df = pd.DataFrame(columns=['ecli', 'chunks'])\n",
    "    for index, row in df.iterrows():\n",
    "        chunks = split_text_in_chunks(row['case text'])\n",
    "        return_df = return_df.append({'ecli': row['id'].replace('-', ':'), 'chunks': chunks})\n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe73930",
   "metadata": {},
   "source": [
    "Rules:\n",
    "1. Case needs to concern criminal law\n",
    "2. Case needs to contain a smuggle word\n",
    "3. Case needs to contain a country that is not \"Netherlands\"\n",
    "4. Case needs to contain a chunk that contains a country and a drug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867bb4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enforce_rule_1(df):\n",
    "    return_df = pd.DataFrame()\n",
    "    for index, row in df.iterrows():\n",
    "        if 'Strafrecht' in row['jurisdiction_type']:\n",
    "            return_df = return_df.append(row)\n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5062a8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_file = open('saves/smuggle_words.pkl', \"rb\")\n",
    "smuggle_words = pickle.load(open_file)\n",
    "open_file.close()\n",
    "\n",
    "def enforce_rule_2(df):\n",
    "    return_df = pd.DataFrame()\n",
    "    for index, row in df.iterrows():\n",
    "        if any(word in row['case text'] for word in smuggle_words):\n",
    "            return_df = return_df.append(row)\n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8eee29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enforce_rule_3(df):\n",
    "    return_df = pd.DataFrame(columns=['ecli', 'chunks', 'countries_present'])\n",
    "    for index, row in df.iterrows():\n",
    "        countries_present = []\n",
    "        chunks = row['chunks']\n",
    "        for chunk in chunks:\n",
    "            ents = nlp(chunk).ents\n",
    "            for ent in ents:\n",
    "                if ent.label_ == \"GPE\":\n",
    "                    country = country_pipeline(ent.text)\n",
    "                    if country != \"None\" and not in countries_present:\n",
    "                        countries_present.append(ent.text)\n",
    "                        if country != \"Netherlands\":\n",
    "                            append = True\n",
    "        if len(countries_present) > 0 and append:\n",
    "            return_df = return_df.append({'ecli': row['ecli'], 'chunks': chunks, 'countries_present': countries_present})\n",
    "    return return_df         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a694a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_file = open('saves/drug_list.pkl', \"rb\")\n",
    "drug_list = pickle.load(open_file)\n",
    "open_file.close()\n",
    "\n",
    "def enforce_rule_4(df):\n",
    "    return_df = pd.DataFrame(columns['ecli', 'chunks', 'countries_present'])\n",
    "    for index, row in df.iterrows():\n",
    "        chunks = row['chunks']\n",
    "        relevant_chunks = []\n",
    "        for chunk in chunks:\n",
    "            word_list = [x for x in chunk.lower().rstrip().replace('.', '').split(' ') if len(x)>0]\n",
    "            if any(drug in word_list for drug in drug_list):\n",
    "                ents = nlp(chunk).ents\n",
    "                for ent in ents:\n",
    "                    if ent.type_ == \"GPE\":\n",
    "                        country = country_pipeline(ent.text)\n",
    "                        if country != \"None\":\n",
    "                            relevant_chunks.append(chunk)\n",
    "                        \n",
    "        if len(relevant_chunks) > 0:\n",
    "            return_df = return_df.append({'ecli': row['ecli'], 'chunks': relevant_chunks, 'countries_present': row['countries_present']})\n",
    "    return return_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a9f4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{len(merged_df)} cases in original df.\")\n",
    "trafficking_df = enforce_rule_1(merged_df)\n",
    "print(f\"{len(trafficking_df)} cases after rule 1.\")\n",
    "trafficking_df = enforce_rule_2(trafficking_df)\n",
    "print(f\"{len(trafficking_df)} cases after rule 2.\")\n",
    "trafficking_df = split_cases_in_chunks(trafficking_df)\n",
    "trafficking_df = enforce_rule_3(trafficking_df)\n",
    "print(f\"{len(trafficking_df)} cases after rule 3.\")\n",
    "trafficking_df = enforce_rule_4(trafficking_df)\n",
    "print(f\"{len(trafficking_df)} cases after rule 4.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39186092",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_file = open('saves/trafficking_df.pkl', \"wb\")\n",
    "pickle.dump(trafficking_df, open_file)\n",
    "open_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49f3d54",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d86423",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_file = open('saves/trafficking_df.pkl', \"rb\")\n",
    "trafficking_df = pickle.load(open_file)\n",
    "open_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0593aa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "traffickign_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
