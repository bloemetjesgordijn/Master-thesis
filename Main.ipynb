{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataPath = os.getcwd() + '/court case data/testdata/'\n",
    "caseCount = len(os.listdir(dataPath))\n",
    "data = []\n",
    "try:\n",
    "    os.remove(dataPath + \".DS_Store\")\n",
    "except:\n",
    "    print(\"No file DS_Store\")\n",
    "for filename in os.listdir(dataPath):\n",
    "    f = open(os.path.join(dataPath, filename), encoding='utf-8')\n",
    "    data.append([filename.replace('.txt', ''), f.read()])\n",
    "\n",
    "verdict_df = pd.DataFrame(data, columns=[\"id\", \"case text\"])\n",
    "cases_df = pd.read_csv('./court case data/testdata.csv')\n",
    "merged_df = cases_df.join(verdict_df.set_index('id'), on='id', how='left')\n",
    "\n",
    "merged_df[\"verdict_date\"] = pd.to_datetime(merged_df[\"verdict_date\"])\n",
    "merged_df[\"publication_date\"] = pd.to_datetime(merged_df[\"publication_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Split documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import re\n",
    "alphabets= \"([A-Za-z])\"\n",
    "prefixes = \"(Mr|St|Mrs|Ms|Dr|mr|mevr|mvr)[.]\"\n",
    "suffixes = \"(Inc|Ltd|Jr|Sr|Co)\"\n",
    "starters = \"(Mr|Mrs|Ms|Dr|He\\s|She\\s|It\\s|They\\s|Their\\s|Our\\s|We\\s|But\\s|However\\s|That\\s|This\\s|Wherever)\"\n",
    "acronyms = \"([A-Z][.][A-Z][.](?:[A-Z][.])?)\"\n",
    "websites = \"[.](com|net|org|io|gov|nl)\"\n",
    "articles = \"[artikel ][0-9][.][0-9]\"\n",
    "\n",
    "def split_into_sentences2(text):\n",
    "    text = \" \" + text + \"  \"\n",
    "    text = text.replace(\"\\n\",\" \")\n",
    "    text = re.sub(prefixes,\"\\\\1<prd>\",text)\n",
    "    text = re.sub(websites,\"<prd>\\\\1\",text)\n",
    "    text = re.sub(articles,\"[artikelnummer]\",text)\n",
    "    if \"Ph.D\" in text: text = text.replace(\"Ph.D.\",\"Ph<prd>D<prd>\")\n",
    "    text = re.sub(\"\\s\" + alphabets + \"[.] \",\" \\\\1<prd> \",text)\n",
    "    text = re.sub(acronyms+\" \"+starters,\"\\\\1<stop> \\\\2\",text)\n",
    "    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\\\\3<prd>\",text)\n",
    "    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\",text)\n",
    "    text = re.sub(\" \"+suffixes+\"[.] \"+starters,\" \\\\1<stop> \\\\2\",text)\n",
    "    text = re.sub(\" \"+suffixes+\"[.]\",\" \\\\1<prd>\",text)\n",
    "    text = re.sub(\" \" + alphabets + \"[.]\",\" \\\\1<prd>\",text)\n",
    "    if \"”\" in text: text = text.replace(\".”\",\"”.\")\n",
    "    if \"\\\"\" in text: text = text.replace(\".\\\"\",\"\\\".\")\n",
    "    if \"!\" in text: text = text.replace(\"!\\\"\",\"\\\"!\")\n",
    "    if \"?\" in text: text = text.replace(\"?\\\"\",\"\\\"?\")\n",
    "    text = text.replace(\".\",\".<stop>\")\n",
    "    text = text.replace(\"?\",\"?<stop>\")\n",
    "    text = text.replace(\"!\",\"!<stop>\")\n",
    "    text = text.replace(\"<prd>\",\".\")\n",
    "    sentences = text.split(\"<stop>\")\n",
    "    sentences = sentences[:-1]\n",
    "    sentences = [s.strip() for s in sentences]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def split_into_sentences(text):\n",
    "    sentences = re.split(r'(?<=[^A-Z].[.?]) +(?=[A-Z])|\\n', text)\n",
    "    sentences = [x for x in sentences if len(x) > 1]\n",
    "    return sentences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Two ways of splitting the documents:\n",
    "    For Word2Vec, we need sentences to be an array of words.\n",
    "    For the rest, just the sentence is enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tenlastelegging_words = ['tenlastelegging', 'telastelegging', 'tenlasteleggingen', 'telastlegging']\n",
    "\n",
    "def trim_by_tenlastelegging(doc):\n",
    "    trimmed_doc = doc\n",
    "    stop = False\n",
    "    for keyword in tenlastelegging_words:\n",
    "        if not stop and keyword in doc:\n",
    "            keyword_index = doc.find(keyword)\n",
    "            trimmed_doc = doc[keyword_index:]\n",
    "            stop = True\n",
    "    return trimmed_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sentence_list_by_word = []\n",
    "sentence_list = []\n",
    "\n",
    "for i in range(len(merged_df)):\n",
    "    doc = merged_df.iloc[i]['case text']\n",
    "    trimmed_doc = trim_by_tenlastelegging(doc)\n",
    "    sentences = split_into_sentences(trimmed_doc)\n",
    "    sentence_list.append(sentences)\n",
    "    for j in sentences:\n",
    "        word_list = [x for x in j.lower().rstrip().replace('.', '').split(' ') if len(x)>0]\n",
    "        sentence_list_by_word.append(word_list)\n",
    "        \n",
    "print(len(sentence_list))\n",
    "print(len(sentence_list_by_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(len(sentence_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(len(sentence_list_by_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Create Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import common_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Create and save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# dutch_word2vec_model = Word2Vec(sentences=sentence_list_by_word, vector_size=100, window=5, min_count=1, workers=4)\n",
    "# dutch_word2vec_model.save(\"word2vec_dutch_court_cases.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dutch_word2vec_model = Word2Vec.load(\"word2vec_dutch_court_cases.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sims = dutch_word2vec_model.wv.most_similar('xtc', topn=100)\n",
    "print([i[0] for i in sims])\n",
    "# print(sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Create list of drugs, smuggle, quantity keywords with Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def create_word2vec_relevant_words(words, matches):\n",
    "    word2vec_list = []\n",
    "    for word in words:\n",
    "        results = dutch_word2vec_model.wv.most_similar(word, topn=100)\n",
    "        for i in results:\n",
    "            word2vec_list.append(i[0])\n",
    "            \n",
    "    word2vec_list = list(set([i for i in word2vec_list if word2vec_list.count(i)>matches]))\n",
    "    return word2vec_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Drugs list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "list_of_drugs = ['xtc', 'mdma', 'cocaine', 'wiet', 'speed', 'bmk', 'pmk']\n",
    "word2vec_drug_list = create_word2vec_relevant_words(list_of_drugs, 2)\n",
    "\n",
    "print(len(word2vec_drug_list))\n",
    "print(word2vec_drug_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "drugs_to_exclude = ['pasta', 'kristallen', 'poedervorm']\n",
    "word2vec_drug_list = [drug for drug in word2vec_drug_list if drug not in drugs_to_exclude]\n",
    "print(len(word2vec_drug_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Smuggle keyword list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "list_of_smuggle_words = ['smokkel', 'invoer', 'uitvoer', 'import', 'export', 'transport']\n",
    "word2vec_smuggle_list = create_word2vec_relevant_words(list_of_smuggle_words, 3)\n",
    "\n",
    "word2vec_smuggle_list = list(set(word2vec_smuggle_list + list_of_smuggle_words ))\n",
    "print(len(word2vec_smuggle_list))\n",
    "print(word2vec_smuggle_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# drugs_to_exclude = ['pasta', 'kristallen', 'poedervorm']\n",
    "# word2vec_drug_list = [drug for drug in word2vec_drug_list if drug not in drugs_to_exclude]\n",
    "# print(len(word2vec_drug_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Quantity keyword list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "list_of_quantity_words = ['tabletten', 'kilo', 'gram', 'pakketten']\n",
    "word2vec_quantity_list = create_word2vec_relevant_words(list_of_quantity_words, 2)\n",
    "\n",
    "word2vec_quantity_list = list(set(word2vec_quantity_list + list_of_quantity_words))\n",
    "print(len(word2vec_quantity_list))\n",
    "print(word2vec_quantity_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Country list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "list_of_countries = ['duitsland', 'colombia', 'alicante']\n",
    "word2vec_country_list = create_word2vec_relevant_words(list_of_countries, 1)\n",
    "\n",
    "print(len(word2vec_country_list))\n",
    "print(word2vec_country_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Create SpaCy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "# !python -m spacy download nl_core_news_md\n",
    "nlp = spacy.load('nl_core_news_md')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "my_file = open(\"drugs list.txt\", \"r\", encoding='utf-8')\n",
    "my_file = my_file.readlines()\n",
    "drugs_list = []\n",
    "for i in my_file:\n",
    "    drugs_list.append(i.replace('\\n', ''))\n",
    "drugs_list = list(set(drugs_list + word2vec_drug_list))\n",
    "    \n",
    "my_file = open(\"countries list.txt\", \"r\", encoding='utf-8')\n",
    "my_file = my_file.readlines()\n",
    "countries_list = []\n",
    "for i in my_file:\n",
    "    countries_list.append(i.replace('\\n', ''))\n",
    "countries_list = list(set(countries_list + word2vec_country_list))\n",
    "\n",
    "my_file = open(\"countries_to_exclude.txt\", \"r\", encoding='utf-8')\n",
    "my_file = my_file.readlines()\n",
    "countries_to_exclude = []\n",
    "for i in my_file:\n",
    "    countries_to_exclude.append(i.replace('\\n', ''))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open('countries_that_give_error.txt', 'w') as f:\n",
    "    for item in countries_that_give_error:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def configure_spacy_model():\n",
    "    # Create dict of drug pattern and quantity pattern\n",
    "    pattern_list = []\n",
    "    \n",
    "    for i in countries_to_exclude:\n",
    "        pattern_list.append({\"label\": \"EXCL\", \"pattern\": [{\"lower\": i.lower()}]})\n",
    "    \n",
    "    for i in drugs_list:\n",
    "        pattern_list.append({\"label\": \"DRUG\", \"pattern\": [{\"lower\": i.lower()}]})\n",
    "    \n",
    "#     quantity_rule = {\"label\": \"QUANTITY\", \"pattern\": [{\"IS_DIGIT\": True}, {\"LOWER\": \"gram\"}]}\n",
    "#     pattern_list.append(quantity_rule)\n",
    "    for i in word2vec_quantity_list:\n",
    "        pattern_list.append({\"label\": \"QUANTITY\", \"pattern\": [{\"IS_DIGIT\": True}, {\"LOWER\": i}]})\n",
    "        pattern_list.append({\"label\": \"QUANTITY\", \"pattern\": [{\"ENT_TYPE\": \"CARDINAL\"}, {\"LOWER\": i}]})\n",
    "    \n",
    "    for i in countries_list:\n",
    "        pattern_list.append({\"label\": \"GPE\", \"pattern\": [{\"lower\": i.replace(' ', '').lower()}]})\n",
    "    \n",
    "    # Add drug and quantity rules to the model\n",
    "    config = {\n",
    "   \"phrase_matcher_attr\": None,\n",
    "   \"validate\": True,\n",
    "   \"overwrite_ents\": True,\n",
    "   \"ent_id_sep\": \"||\",\n",
    "    }\n",
    "    ruler = nlp.add_pipe(\"entity_ruler\", config=config)\n",
    "\n",
    "    #List of Entities and Patterns\n",
    "#     patterns = drugs_ent_list\n",
    "    ruler.add_patterns(pattern_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "configure_spacy_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Select cases and chunks to keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(len(sentence_list) == len(merged_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For every case, split the sentences. If a sentence in a case contains a drug, a smuggle word, and a location: keep chunk and save to trafficking_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "country_translation_dict = {}\n",
    "countries_that_give_error = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim(user_agent = \"geoapiExercises\")\n",
    "\n",
    "def get_google_country(loc):\n",
    "    if loc in country_translation_dict:\n",
    "        return country_translation_dict[loc]\n",
    "    if loc in countries_that_give_error:\n",
    "        return \"None\"\n",
    "    else:\n",
    "        try:\n",
    "            location = geolocator.geocode(loc, language='en')\n",
    "            country_name = location.raw['display_name'].split(',')[-1]\n",
    "            country_translation_dict[loc] = country_name\n",
    "            return country_translation_dict[loc]\n",
    "        except:\n",
    "            print(f\"{loc} is not a location.\")\n",
    "            countries_that_give_error.append(loc)\n",
    "            return \"None\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "relevant_chunk_list = []\n",
    "ecli_list = []\n",
    "\n",
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim(user_agent = \"geoapiExercises\")\n",
    "\n",
    "for index, case in enumerate(sentence_list):\n",
    "    chunk_list = []\n",
    "    trafficking_related = False\n",
    "    for chunk in case:\n",
    "        word_list = [x for x in chunk.lower().rstrip().replace('.', '').split(' ') if len(x)>0]\n",
    "        if any(drug in word_list for drug in word2vec_drug_list) and any(smuggle_word in word_list for smuggle_word in word2vec_smuggle_list):\n",
    "            ents = nlp(chunk).ents\n",
    "            if any(ent.label_ == \"GPE\" for ent in ents):\n",
    "                stop = False\n",
    "                for ent in ents:\n",
    "                    if not stop and ent.label_ == \"GPE\":\n",
    "                        country = get_google_country(ent.text)\n",
    "                        if country != \"Netherlands\" and country != \"None\":\n",
    "                            trafficking_related = True\n",
    "                            chunk_list.append(chunk)\n",
    "                            stop = True\n",
    "    if trafficking_related:\n",
    "        relevant_chunk_list.append(chunk_list)\n",
    "        ecli_list.append(merged_df.iloc[index]['id'].replace('-', ':'))\n",
    "\n",
    "trafficking_df = pd.DataFrame({'id': pd.Series(ecli_list), 'chunks': pd.Series(relevant_chunk_list)})  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f\"{len(trafficking_df)} cases kept from original {len(merged_df)} cases.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create rule-based NER & POS tagging model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def extract_chunk_info(txt):\n",
    "    source_country = None\n",
    "    total_info = []\n",
    "    for token in nlp(txt):\n",
    "        info = {}\n",
    "        drug_info = {}\n",
    "        countries = []\n",
    "        \n",
    "        if token.ent_type_ == \"DRUG\":\n",
    "            info = {\"drug\": token.text}\n",
    "            \n",
    "            ## Get source and destination\n",
    "            for ancestor in token.ancestors:\n",
    "                for nephew in ancestor.children:\n",
    "                    if nephew.ent_type_ == \"GPE\" or nephew.ent_type_ == \"LOC\":\n",
    "                        countries.append(nephew)\n",
    "                        for child in nephew.children:\n",
    "                            if child.dep_ == \"conj\" and child.ent_type_ == \"GPE\" or child.ent_type_ == \"LOC\":\n",
    "                                countries.append(child.text)\n",
    "                            elif child.pos_ == \"ADP\" and child.dep_ == \"case\":\n",
    "                                adj = child.text\n",
    "            if len(countries) > 0 :\n",
    "                try:\n",
    "                    info[adj] = countries\n",
    "                except:\n",
    "                    info['land'] = countries\n",
    "                        \n",
    "            ## Get volume\n",
    "            for ancestors in token.ancestors:\n",
    "                for nephew in ancestors.children:\n",
    "                    if nephew.ent_type_ == \"QUANTITY\" or nephew.ent_type_ == \"CARDINAL\":\n",
    "                        for second_nephew in nephew.children:\n",
    "                            if second_nephew.is_digit != nephew.is_digit:\n",
    "                                if second_nephew.is_digit:\n",
    "                                    info['volume'] = second_nephew.text\n",
    "                                    info['volume_type'] = nephew.text\n",
    "                                else:\n",
    "                                    info['volume'] = nephew.text\n",
    "                                    info['volume_type'] = second_nephew.text\n",
    "            if 'volume' not in info:\n",
    "                for child in token.children:\n",
    "                    if (child.dep_ == \"det\" and child.like_num) or (child.dep_ == \"nummod\"):\n",
    "                        info['volume'] = child.text\n",
    "                                \n",
    "        if len(info) > 1:\n",
    "#             print(info)\n",
    "            total_info.append(info)\n",
    "    return total_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Get linguistic distance between token a and token b. After iter 10 it is deemed a too far distance.\n",
    "def get_linguistic_distance(a, b):\n",
    "    tokens_to_consider = [b]\n",
    "    found = False\n",
    "    iters = 0\n",
    "    while not found:\n",
    "        for token in tokens_to_consider:\n",
    "            tokens_to_add = []\n",
    "            for ancestor in token.ancestors:\n",
    "                if ancestor not in tokens_to_add and ancestor not in tokens_to_consider:\n",
    "                    tokens_to_add.append(ancestor)\n",
    "            for child in token.children:\n",
    "                if child not in tokens_to_add and child not in tokens_to_consider:\n",
    "                    tokens_to_add.append(child)\n",
    "            tokens_to_consider = tokens_to_consider + tokens_to_add\n",
    "        for x in tokens_to_consider:\n",
    "            if a.orth == x.orth:\n",
    "                found = True\n",
    "        iters += 1\n",
    "        if iters == 10:\n",
    "            found = True\n",
    "    return iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_adposition_from_loc(token):\n",
    "    for child in token.children:\n",
    "        if child.pos_ == \"ADP\" and child.dep_ == \"case\":\n",
    "            return child.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def extract_chunk_info(txt):\n",
    "    result = {}\n",
    "    print('START CHUNK')\n",
    "    for token in nlp(txt):\n",
    "        if token.ent_type_ == \"DRUG\":\n",
    "            print(f\" \\n Extracting info for {token.text}.\")\n",
    "            drug_info = extract_info_from_drug(token, txt)\n",
    "            result[token.text] = drug_info\n",
    "    return result\n",
    "            \n",
    "adj_list = []          \n",
    "def extract_info_from_drug(drug, txt):\n",
    "    volumes = []\n",
    "    locations = {}\n",
    "    irrelevant_locations = []\n",
    "    for token in nlp(txt):\n",
    "        \n",
    "        # Extract countries\n",
    "        if token.ent_type_ == \"GPE\":\n",
    "            dist = get_linguistic_distance(drug, token)\n",
    "#             if dist < 15:\n",
    "            adj = get_adposition_from_loc(token)\n",
    "            print(f\"    {adj}: {token.text}, dist: {dist}, conj: {token.conjuncts}\")\n",
    "            locs = [token.text]\n",
    "            for loc in token.conjuncts:\n",
    "                locs.append(loc.text)\n",
    "            if adj not in locations:\n",
    "                locations[adj] = locs\n",
    "                if adj not in adj_list:\n",
    "                    adj_list.append(adj)\n",
    "            else:\n",
    "                for loc in locs:\n",
    "                    if loc not in locations[adj]:\n",
    "                        locations[adj].append(loc)\n",
    "#             else:\n",
    "#                 irrelevant_locations.append(token.text)\n",
    "#                 print(f\"{token.text} is irrelevant.\")\n",
    "        \n",
    "        # Extract volume\n",
    "        if token.ent_type_ == \"QUANTITY\":\n",
    "            volume = {}\n",
    "            dist = get_linguistic_distance(drug, token)\n",
    "            second_token = \"\"\n",
    "#             if dist < 10:\n",
    "            quantity = {}\n",
    "            for ancestor in token.ancestors:\n",
    "                if ancestor.ent_type_ == \"QUANTITY\":\n",
    "                    second_token = ancestor\n",
    "            for child in token.children:\n",
    "                if child.ent_type_ == \"QUANTITY\":\n",
    "                    second_token = child\n",
    "\n",
    "            ## Decide volume and volume_type\n",
    "            if not isinstance(second_token, str):\n",
    "                if nlp(token.text)[0].ent_type_ == \"CARDINAL\":\n",
    "                    volume['volume'] = token.text\n",
    "                    volume['volume_type'] = second_token.text\n",
    "                    volume['dist'] = dist\n",
    "                elif nlp(second_token.text)[0].ent_type_ == \"CARDINAL\":\n",
    "                    volume['volume'] = second_token.text\n",
    "                    volume['volume_type'] = token.text\n",
    "                    volume['dist'] = dist\n",
    "\n",
    "                #Only append when not already in volumes\n",
    "                if volume not in volumes:\n",
    "                    volumes.append(volume)\n",
    "    #             else:\n",
    "    #                 print(f\"{token.text} is irrelevant.\")\n",
    "                \n",
    "        \n",
    "        \n",
    "            \n",
    "    print(volumes)\n",
    "\n",
    "    result = {}\n",
    "    if bool(locations):\n",
    "        result['locations'] = locations\n",
    "#     if len(volumes) > 0:\n",
    "    result[\"volume\"] = volumes\n",
    "    if len(irrelevant_locations) > 0:\n",
    "        result[\"irrelevant_locations\"] = irrelevant_locations\n",
    "    \n",
    "    return result\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_chunk_info_without_log(txt):\n",
    "    result = {}\n",
    "    for token in nlp(txt):\n",
    "        if token.ent_type_ == \"DRUG\":\n",
    "            drug_info = extract_info_from_drug_without_log(token, txt)\n",
    "            result[token.text] = drug_info\n",
    "    return result\n",
    "            \n",
    "adj_list = []          \n",
    "def extract_info_from_drug_without_log(drug, txt):\n",
    "    volumes = []\n",
    "    locations = {}\n",
    "    irrelevant_locations = []\n",
    "    for token in nlp(txt):\n",
    "        \n",
    "        # Extract countries\n",
    "        if token.ent_type_ == \"GPE\":\n",
    "            dist = get_linguistic_distance(drug, token)\n",
    "#             if dist < 15:\n",
    "            adj = get_adposition_from_loc(token)\n",
    "            locs = [token.text]\n",
    "            for loc in token.conjuncts:\n",
    "                locs.append(loc.text)\n",
    "            if adj not in locations:\n",
    "                locations[adj] = locs\n",
    "                if adj not in adj_list:\n",
    "                    adj_list.append(adj)\n",
    "            else:\n",
    "                for loc in locs:\n",
    "                    if loc not in locations[adj]:\n",
    "                        locations[adj].append(loc)\n",
    "#             else:\n",
    "#                 irrelevant_locations.append(token.text)\n",
    "#                 print(f\"{token.text} is irrelevant.\")\n",
    "        \n",
    "        # Extract volume\n",
    "        if token.ent_type_ == \"QUANTITY\":\n",
    "            volume = {}\n",
    "            dist = get_linguistic_distance(drug, token)\n",
    "            second_token = \"\"\n",
    "#             if dist < 10:\n",
    "            quantity = {}\n",
    "            for ancestor in token.ancestors:\n",
    "                if ancestor.ent_type_ == \"QUANTITY\":\n",
    "                    second_token = ancestor\n",
    "            for child in token.children:\n",
    "                if child.ent_type_ == \"QUANTITY\":\n",
    "                    second_token = child\n",
    "\n",
    "            ## Decide volume and volume_type\n",
    "            if not isinstance(second_token, str):\n",
    "                if nlp(token.text)[0].ent_type_ == \"CARDINAL\":\n",
    "                    volume['volume'] = token.text\n",
    "                    volume['volume_type'] = second_token.text\n",
    "                    volume['dist'] = dist\n",
    "                elif nlp(second_token.text)[0].ent_type_ == \"CARDINAL\":\n",
    "                    volume['volume'] = second_token.text\n",
    "                    volume['volume_type'] = token.text\n",
    "                    volume['dist'] = dist\n",
    "\n",
    "                #Only append when not already in volumes\n",
    "                if volume not in volumes:\n",
    "                    volumes.append(volume)\n",
    "    #             else:\n",
    "    #                 print(f\"{token.text} is irrelevant.\")\n",
    "                \n",
    "        \n",
    "        \n",
    "            \n",
    "\n",
    "    result = {}\n",
    "    if bool(locations):\n",
    "        result['locations'] = locations\n",
    "#     if len(volumes) > 0:\n",
    "    result[\"volume\"] = volumes\n",
    "    if len(irrelevant_locations) > 0:\n",
    "        result[\"irrelevant_locations\"] = irrelevant_locations\n",
    "    \n",
    "    return result\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuse_chunks(chunks): \n",
    "    # Loop through chunks\n",
    "    drug_dict = {}\n",
    "    for chunk in chunks:\n",
    "        chunk_info = extract_chunk_info_without_log(chunk)\n",
    "\n",
    "        # Loop through drugs\n",
    "        if chunk_info is not None:\n",
    "            for drug in chunk_info:\n",
    "                lowerdrug = drug.lower()\n",
    "                if lowerdrug not in drug_dict:\n",
    "                    drug_dict[lowerdrug] = {'locations': [], 'volumes': []}\n",
    "                if len(chunk_info[drug]['volume']) > 0:\n",
    "                    drug_dict[lowerdrug]['volumes'].append(chunk_info[drug]['volume'])\n",
    "                if 'locations' in chunk_info[drug]:\n",
    "                    drug_dict[lowerdrug]['locations'].append(chunk_info[drug]['locations'])\n",
    "    return drug_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuse_locations(fused_chunks):\n",
    "    for drug in fused_chunks:\n",
    "        adjectives = {}\n",
    "        for location_entry in fused_chunks[drug]['locations']:\n",
    "            for adjective in location_entry:\n",
    "                if adjective not in adjectives:\n",
    "                    adjectives[adjective] = []\n",
    "                for country in location_entry[adjective]:\n",
    "                    if country not in adjectives[adjective]:\n",
    "                        adjectives[adjective].append(country)\n",
    "        fused_chunks[drug]['locations'] = adjectives\n",
    "    return fused_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuse_volumes(fused_locations):\n",
    "    for drug in fused_locations:\n",
    "        final_volume = {}\n",
    "        dist = 100\n",
    "        for volumes in fused_locations[drug]['volumes']:\n",
    "            if len(volumes) > 0:\n",
    "                for volume in volumes:\n",
    "                    if 'dist' in volume:\n",
    "                        if volume['dist'] < dist:\n",
    "                            dist = volume['dist']\n",
    "                            final_volume = volume\n",
    "        fused_locations[drug]['volumes'] = final_volume\n",
    "        return fused_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# country_translation_dict = {}\n",
    "# countries_that_give_error = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_locations(data):\n",
    "    geolocator = Nominatim(user_agent = \"geoapiExercises\")\n",
    "    if data is not None:\n",
    "        for drug in data:\n",
    "            if 'locations' in data[drug]:\n",
    "                data[drug]['original_locations'] = data[drug]['locations'].copy()\n",
    "                for adjective in data[drug]['locations']:\n",
    "                    country_list = []\n",
    "                    locations = data[drug]['locations'][adjective]\n",
    "                    for loc in locations:\n",
    "                        if loc not in country_translation_dict and loc not in countries_that_give_error:    \n",
    "                            try:\n",
    "                                location = geolocator.geocode(loc, language='en')\n",
    "                                country_name = location.raw['display_name'].split(',')[-1]\n",
    "                                country_translation_dict[loc] = country_name\n",
    "                                if country_name not in country_list:\n",
    "                                    country_list.append(country_name)\n",
    "                            except Exception as e:\n",
    "                                print(f\"{loc} is not a location.\")\n",
    "                                countries_that_give_error.append(loc)\n",
    "                        else:\n",
    "                            if loc in country_translation_dict:\n",
    "                                if country_translation_dict[loc] not in country_list:\n",
    "                                    country_list.append(country_translation_dict[loc])\n",
    "                    data[drug]['locations'][adjective] = country_list\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_location_directions(data):\n",
    "    from_adjectives = ['uit', 'vanuit', 'van']\n",
    "    to_adjectives = ['naar']\n",
    "    via_adjectives = ['via']\n",
    "    if data is not None:\n",
    "        for drug in data:\n",
    "            fromlocs = []\n",
    "            tolocs = []\n",
    "            vialocs = []\n",
    "            locations = data[drug]['locations']\n",
    "            for adj in locations:\n",
    "                if adj in from_adjectives:\n",
    "                    for loc in locations[adj]:\n",
    "                        if loc not in fromlocs:\n",
    "                            fromlocs.append(loc)\n",
    "                elif adj in to_adjectives:\n",
    "                    for loc in locations[adj]:\n",
    "                        if loc not in tolocs:\n",
    "                            tolocs.append(loc)\n",
    "                elif adj in via_adjectives:\n",
    "                    for loc in locations[adj]:\n",
    "                        if loc not in vialocs:\n",
    "                            vialocs.append(loc)\n",
    "\n",
    "            data[drug]['locations'] = {'from': fromlocs, 'to': tolocs, 'via': vialocs}\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame(columns=['ecli', 'drug', 'relevant_countries'])    \n",
    "\n",
    "    \n",
    "                            \n",
    "for index, row in trafficking_df.iterrows():\n",
    "    id = row['id']\n",
    "#     print(id)\n",
    "    \n",
    "    fused_chunks = fuse_chunks(row['chunks'])\n",
    "    fused_locations = fuse_locations(fused_chunks)\n",
    "    fused_volumes = fuse_volumes(fused_locations)\n",
    "    translated_locations = translate_locations(fused_volumes)\n",
    "#     location_directions = get_location_directions(translated_locations)\n",
    "    \n",
    "#     print(location_directions)\n",
    "    if translated_locations is not None:\n",
    "        for drug in translated_locations:\n",
    "            relevant_countries = []\n",
    "            curr = translated_locations[drug]\n",
    "            for adjective in curr['locations']:\n",
    "                locs = curr['locations'][adjective]\n",
    "                for loc in locs:\n",
    "                    if loc not in relevant_countries:\n",
    "                        relevant_countries.append(loc)\n",
    "                    \n",
    "            \n",
    "            \n",
    "            row = {'ecli': id, 'drug': drug, 'relevant_countries': relevant_countries}\n",
    "            final_df = final_df.append(row, ignore_index=True)\n",
    "        \n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorcounts = {}\n",
    "\n",
    "for index, row in final_df.iterrows():\n",
    "    locs = row['relevant_countries']\n",
    "    for loc in locs:\n",
    "        if loc != \"Netherlands\":\n",
    "            if loc not in vectorcounts:\n",
    "                vectorcounts[loc] = [0]\n",
    "            vectorcounts[loc][0] = vectorcounts[loc][0] + 1\n",
    "            \n",
    "print(vectorcounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('final_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "geo": "geo",
         "hovertemplate": "<b>%{hovertext}</b><br><br>iso_alpha=%{location}<br>count=%{z}<extra></extra>",
         "hovertext": [
          "Afghanistan",
          "Albania",
          "Algeria",
          "Angola",
          "Argentina",
          "Australia",
          "Austria",
          "Bahrain",
          "Bangladesh",
          "Belgium",
          "Benin",
          "Bolivia",
          "Bosnia and Herzegovina",
          "Botswana",
          "Brazil",
          "Bulgaria",
          "Burkina Faso",
          "Burundi",
          "Cambodia",
          "Cameroon",
          "Canada",
          "Central African Republic",
          "Chad",
          "Chile",
          "China",
          "Colombia",
          "Comoros",
          "Congo, Dem. Rep.",
          "Congo, Rep.",
          "Costa Rica",
          "Cote d'Ivoire",
          "Croatia",
          "Cuba",
          "Czech Republic",
          "Denmark",
          "Djibouti",
          "Dominican Republic",
          "Ecuador",
          "Egypt",
          "El Salvador",
          "Equatorial Guinea",
          "Eritrea",
          "Ethiopia",
          "Finland",
          "France",
          "Gabon",
          "Gambia",
          "Germany",
          "Ghana",
          "Greece",
          "Guatemala",
          "Guinea",
          "Guinea-Bissau",
          "Haiti",
          "Honduras",
          "Hong Kong, China",
          "Hungary",
          "Iceland",
          "India",
          "Indonesia",
          "Iran",
          "Iraq",
          "Ireland",
          "Israel",
          "Italy",
          "Jamaica",
          "Japan",
          "Jordan",
          "Kenya",
          "Korea, Dem. Rep.",
          "Korea, Rep.",
          "Kuwait",
          "Lebanon",
          "Lesotho",
          "Liberia",
          "Libya",
          "Madagascar",
          "Malawi",
          "Malaysia",
          "Mali",
          "Mauritania",
          "Mauritius",
          "Mexico",
          "Mongolia",
          "Montenegro",
          "Morocco",
          "Mozambique",
          "Myanmar",
          "Namibia",
          "Nepal",
          "Netherlands",
          "New Zealand",
          "Nicaragua",
          "Niger",
          "Nigeria",
          "Norway",
          "Oman",
          "Pakistan",
          "Panama",
          "Paraguay",
          "Peru",
          "Philippines",
          "Poland",
          "Portugal",
          "Puerto Rico",
          "Reunion",
          "Romania",
          "Rwanda",
          "Sao Tome and Principe",
          "Saudi Arabia",
          "Senegal",
          "Serbia",
          "Sierra Leone",
          "Singapore",
          "Slovak Republic",
          "Slovenia",
          "Somalia",
          "South Africa",
          "Spain",
          "Sri Lanka",
          "Sudan",
          "Swaziland",
          "Sweden",
          "Switzerland",
          "Syria",
          "Taiwan",
          "Tanzania",
          "Thailand",
          "Togo",
          "Trinidad and Tobago",
          "Tunisia",
          "Turkey",
          "Uganda",
          "United Kingdom",
          "United States",
          "Uruguay",
          "Venezuela",
          "Vietnam",
          "West Bank and Gaza",
          "Yemen, Rep.",
          "Zambia",
          "Zimbabwe"
         ],
         "locations": [
          "AFG",
          "ALB",
          "DZA",
          "AGO",
          "ARG",
          "AUS",
          "AUT",
          "BHR",
          "BGD",
          "BEL",
          "BEN",
          "BOL",
          "BIH",
          "BWA",
          "BRA",
          "BGR",
          "BFA",
          "BDI",
          "KHM",
          "CMR",
          "CAN",
          "CAF",
          "TCD",
          "CHL",
          "CHN",
          "COL",
          "COM",
          "COD",
          "COG",
          "CRI",
          "CIV",
          "HRV",
          "CUB",
          "CZE",
          "DNK",
          "DJI",
          "DOM",
          "ECU",
          "EGY",
          "SLV",
          "GNQ",
          "ERI",
          "ETH",
          "FIN",
          "FRA",
          "GAB",
          "GMB",
          "DEU",
          "GHA",
          "GRC",
          "GTM",
          "GIN",
          "GNB",
          "HTI",
          "HND",
          "HKG",
          "HUN",
          "ISL",
          "IND",
          "IDN",
          "IRN",
          "IRQ",
          "IRL",
          "ISR",
          "ITA",
          "JAM",
          "JPN",
          "JOR",
          "KEN",
          "KOR",
          "KOR",
          "KWT",
          "LBN",
          "LSO",
          "LBR",
          "LBY",
          "MDG",
          "MWI",
          "MYS",
          "MLI",
          "MRT",
          "MUS",
          "MEX",
          "MNG",
          "MNE",
          "MAR",
          "MOZ",
          "MMR",
          "NAM",
          "NPL",
          "NLD",
          "NZL",
          "NIC",
          "NER",
          "NGA",
          "NOR",
          "OMN",
          "PAK",
          "PAN",
          "PRY",
          "PER",
          "PHL",
          "POL",
          "PRT",
          "PRI",
          "REU",
          "ROU",
          "RWA",
          "STP",
          "SAU",
          "SEN",
          "SRB",
          "SLE",
          "SGP",
          "SVK",
          "SVN",
          "SOM",
          "ZAF",
          "ESP",
          "LKA",
          "SDN",
          "SWZ",
          "SWE",
          "CHE",
          "SYR",
          "TWN",
          "TZA",
          "THA",
          "TGO",
          "TTO",
          "TUN",
          "TUR",
          "UGA",
          "GBR",
          "USA",
          "URY",
          "VEN",
          "VNM",
          "PSE",
          "YEM",
          "ZMB",
          "ZWE"
         ],
         "name": "",
         "type": "choropleth",
         "z": [
          1,
          null,
          null,
          null,
          6,
          47,
          11,
          null,
          null,
          271,
          null,
          2,
          4,
          null,
          47,
          null,
          null,
          null,
          null,
          null,
          7,
          null,
          null,
          6,
          33,
          75,
          null,
          null,
          null,
          null,
          null,
          2,
          null,
          null,
          33,
          null,
          61,
          30,
          1,
          null,
          null,
          null,
          null,
          15,
          67,
          null,
          null,
          330,
          4,
          1,
          null,
          null,
          null,
          1,
          null,
          null,
          4,
          3,
          9,
          null,
          2,
          null,
          22,
          null,
          79,
          1,
          2,
          null,
          4,
          null,
          null,
          null,
          null,
          null,
          1,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          16,
          null,
          null,
          54,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          1,
          40,
          null,
          29,
          18,
          null,
          19,
          null,
          81,
          10,
          null,
          null,
          11,
          null,
          null,
          null,
          1,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          121,
          null,
          null,
          null,
          87,
          37,
          null,
          null,
          null,
          11,
          null,
          null,
          1,
          41,
          null,
          52,
          25,
          null,
          19,
          null,
          null,
          null,
          null,
          null
         ]
        }
       ],
       "layout": {
        "coloraxis": {
         "colorbar": {
          "title": {
           "text": "count"
          }
         },
         "colorscale": [
          [
           0,
           "#0d0887"
          ],
          [
           0.1111111111111111,
           "#46039f"
          ],
          [
           0.2222222222222222,
           "#7201a8"
          ],
          [
           0.3333333333333333,
           "#9c179e"
          ],
          [
           0.4444444444444444,
           "#bd3786"
          ],
          [
           0.5555555555555556,
           "#d8576b"
          ],
          [
           0.6666666666666666,
           "#ed7953"
          ],
          [
           0.7777777777777778,
           "#fb9f3a"
          ],
          [
           0.8888888888888888,
           "#fdca26"
          ],
          [
           1,
           "#f0f921"
          ]
         ]
        },
        "geo": {
         "center": {},
         "domain": {
          "x": [
           0,
           1
          ],
          "y": [
           0,
           1
          ]
         }
        },
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"5a0c23fe-3ff9-47c2-8f2d-94b76856de45\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"5a0c23fe-3ff9-47c2-8f2d-94b76856de45\")) {                    Plotly.newPlot(                        \"5a0c23fe-3ff9-47c2-8f2d-94b76856de45\",                        [{\"coloraxis\":\"coloraxis\",\"geo\":\"geo\",\"hovertemplate\":\"<b>%{hovertext}</b><br><br>iso_alpha=%{location}<br>count=%{z}<extra></extra>\",\"hovertext\":[\"Afghanistan\",\"Albania\",\"Algeria\",\"Angola\",\"Argentina\",\"Australia\",\"Austria\",\"Bahrain\",\"Bangladesh\",\"Belgium\",\"Benin\",\"Bolivia\",\"Bosnia and Herzegovina\",\"Botswana\",\"Brazil\",\"Bulgaria\",\"Burkina Faso\",\"Burundi\",\"Cambodia\",\"Cameroon\",\"Canada\",\"Central African Republic\",\"Chad\",\"Chile\",\"China\",\"Colombia\",\"Comoros\",\"Congo, Dem. Rep.\",\"Congo, Rep.\",\"Costa Rica\",\"Cote d'Ivoire\",\"Croatia\",\"Cuba\",\"Czech Republic\",\"Denmark\",\"Djibouti\",\"Dominican Republic\",\"Ecuador\",\"Egypt\",\"El Salvador\",\"Equatorial Guinea\",\"Eritrea\",\"Ethiopia\",\"Finland\",\"France\",\"Gabon\",\"Gambia\",\"Germany\",\"Ghana\",\"Greece\",\"Guatemala\",\"Guinea\",\"Guinea-Bissau\",\"Haiti\",\"Honduras\",\"Hong Kong, China\",\"Hungary\",\"Iceland\",\"India\",\"Indonesia\",\"Iran\",\"Iraq\",\"Ireland\",\"Israel\",\"Italy\",\"Jamaica\",\"Japan\",\"Jordan\",\"Kenya\",\"Korea, Dem. Rep.\",\"Korea, Rep.\",\"Kuwait\",\"Lebanon\",\"Lesotho\",\"Liberia\",\"Libya\",\"Madagascar\",\"Malawi\",\"Malaysia\",\"Mali\",\"Mauritania\",\"Mauritius\",\"Mexico\",\"Mongolia\",\"Montenegro\",\"Morocco\",\"Mozambique\",\"Myanmar\",\"Namibia\",\"Nepal\",\"Netherlands\",\"New Zealand\",\"Nicaragua\",\"Niger\",\"Nigeria\",\"Norway\",\"Oman\",\"Pakistan\",\"Panama\",\"Paraguay\",\"Peru\",\"Philippines\",\"Poland\",\"Portugal\",\"Puerto Rico\",\"Reunion\",\"Romania\",\"Rwanda\",\"Sao Tome and Principe\",\"Saudi Arabia\",\"Senegal\",\"Serbia\",\"Sierra Leone\",\"Singapore\",\"Slovak Republic\",\"Slovenia\",\"Somalia\",\"South Africa\",\"Spain\",\"Sri Lanka\",\"Sudan\",\"Swaziland\",\"Sweden\",\"Switzerland\",\"Syria\",\"Taiwan\",\"Tanzania\",\"Thailand\",\"Togo\",\"Trinidad and Tobago\",\"Tunisia\",\"Turkey\",\"Uganda\",\"United Kingdom\",\"United States\",\"Uruguay\",\"Venezuela\",\"Vietnam\",\"West Bank and Gaza\",\"Yemen, Rep.\",\"Zambia\",\"Zimbabwe\"],\"locations\":[\"AFG\",\"ALB\",\"DZA\",\"AGO\",\"ARG\",\"AUS\",\"AUT\",\"BHR\",\"BGD\",\"BEL\",\"BEN\",\"BOL\",\"BIH\",\"BWA\",\"BRA\",\"BGR\",\"BFA\",\"BDI\",\"KHM\",\"CMR\",\"CAN\",\"CAF\",\"TCD\",\"CHL\",\"CHN\",\"COL\",\"COM\",\"COD\",\"COG\",\"CRI\",\"CIV\",\"HRV\",\"CUB\",\"CZE\",\"DNK\",\"DJI\",\"DOM\",\"ECU\",\"EGY\",\"SLV\",\"GNQ\",\"ERI\",\"ETH\",\"FIN\",\"FRA\",\"GAB\",\"GMB\",\"DEU\",\"GHA\",\"GRC\",\"GTM\",\"GIN\",\"GNB\",\"HTI\",\"HND\",\"HKG\",\"HUN\",\"ISL\",\"IND\",\"IDN\",\"IRN\",\"IRQ\",\"IRL\",\"ISR\",\"ITA\",\"JAM\",\"JPN\",\"JOR\",\"KEN\",\"KOR\",\"KOR\",\"KWT\",\"LBN\",\"LSO\",\"LBR\",\"LBY\",\"MDG\",\"MWI\",\"MYS\",\"MLI\",\"MRT\",\"MUS\",\"MEX\",\"MNG\",\"MNE\",\"MAR\",\"MOZ\",\"MMR\",\"NAM\",\"NPL\",\"NLD\",\"NZL\",\"NIC\",\"NER\",\"NGA\",\"NOR\",\"OMN\",\"PAK\",\"PAN\",\"PRY\",\"PER\",\"PHL\",\"POL\",\"PRT\",\"PRI\",\"REU\",\"ROU\",\"RWA\",\"STP\",\"SAU\",\"SEN\",\"SRB\",\"SLE\",\"SGP\",\"SVK\",\"SVN\",\"SOM\",\"ZAF\",\"ESP\",\"LKA\",\"SDN\",\"SWZ\",\"SWE\",\"CHE\",\"SYR\",\"TWN\",\"TZA\",\"THA\",\"TGO\",\"TTO\",\"TUN\",\"TUR\",\"UGA\",\"GBR\",\"USA\",\"URY\",\"VEN\",\"VNM\",\"PSE\",\"YEM\",\"ZMB\",\"ZWE\"],\"name\":\"\",\"z\":[1.0,null,null,null,6.0,47.0,11.0,null,null,271.0,null,2.0,4.0,null,47.0,null,null,null,null,null,7.0,null,null,6.0,33.0,75.0,null,null,null,null,null,2.0,null,null,33.0,null,61.0,30.0,1.0,null,null,null,null,15.0,67.0,null,null,330.0,4.0,1.0,null,null,null,1.0,null,null,4.0,3.0,9.0,null,2.0,null,22.0,null,79.0,1.0,2.0,null,4.0,null,null,null,null,null,1.0,null,null,null,null,null,null,null,16.0,null,null,54.0,null,null,null,null,null,null,null,null,1.0,40.0,null,29.0,18.0,null,19.0,null,81.0,10.0,null,null,11.0,null,null,null,1.0,null,null,null,null,null,null,null,121.0,null,null,null,87.0,37.0,null,null,null,11.0,null,null,1.0,41.0,null,52.0,25.0,null,19.0,null,null,null,null,null],\"type\":\"choropleth\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"geo\":{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"center\":{}},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"count\"}},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('5a0c23fe-3ff9-47c2-8f2d-94b76856de45');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(12)\n",
    "gapminder = px.data.gapminder().query(\"year==2007\")\n",
    "#gapminder['counts'] = np.nan\n",
    "\n",
    "d = vectorcounts\n",
    "\n",
    "yourdata = pd.DataFrame(d).T.reset_index()\n",
    "yourdata.columns=['country', 'count']\n",
    "\n",
    "df=pd.merge(gapminder, yourdata, how='left', on='country')\n",
    "\n",
    "fig = px.choropleth(df, locations=\"iso_alpha\",\n",
    "                    color=\"count\", \n",
    "                    hover_name=\"country\", # column to add to hover information\n",
    "                    color_continuous_scale=px.colors.sequential.Plasma)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame(columns=['ecli', 'drug', 'from', 'to', 'via'])    \n",
    "\n",
    "    \n",
    "    \n",
    "from geopy.geocoders import Nominatim\n",
    "                        \n",
    "for index, row in trafficking_df.iterrows():\n",
    "    id = row['id']\n",
    "#     print(id)\n",
    "    \n",
    "    fused_chunks = fuse_chunks(row['chunks'])\n",
    "    fused_locations = fuse_locations(fused_chunks)\n",
    "    fused_volumes = fuse_volumes(fused_locations)\n",
    "    translated_locations = translate_locations(fused_volumes)\n",
    "    location_directions = get_location_directions(translated_locations)\n",
    "    \n",
    "#     print(location_directions)\n",
    "    if location_directions is not None:\n",
    "        for drug in location_directions:\n",
    "            curr = location_directions[drug]\n",
    "            fromloc = curr['locations']['from']\n",
    "            toloc = curr['locations']['to']\n",
    "            vialoc = curr['locations']['via']\n",
    "            \n",
    "            row = {'ecli': id, 'drug': drug, 'from': fromloc, 'to': toloc, 'via': vialoc}\n",
    "            final_df = final_df.append(row, ignore_index=True)\n",
    "        \n",
    "final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "geolocator = Nominatim(user_agent = \"geoapiExercises\")\n",
    "location = geolocator.geocode(\"verenigde staten\")\n",
    "country_name = location.raw['display_name'].split(',')[-1]\n",
    "print(country_name)\n",
    "print(len(country_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Get complete adjective list and country list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "complete_adjective_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for index, row in trafficking_df.iterrows():\n",
    "    fused_chunks = fuse_chunks(row['chunks'])\n",
    "    for drug in fused_chunks:\n",
    "        locations = fused_chunks[drug]['locations']\n",
    "        for adjective in locations:\n",
    "            for adj in adjective.keys():\n",
    "                complete_adjective_list.append(adj)\n",
    "            \n",
    "                \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(complete_adjective_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "list(set(complete_adjective_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trafficking_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "case = list(trafficking_df[trafficking_df['id'] == 'ECLI:NL:GHAMS:2018:2662']['chunks'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for chunk in case:\n",
    "    displacy.render(nlp(chunk), style = 'ent')\n",
    "    extract_chunk_info(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_entities(txt):\n",
    "    doc = nlp(txt)\n",
    "    for ent in doc.ents:\n",
    "        print(ent, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Get all loc entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def list_entities(entity):\n",
    "    entity_list = []\n",
    "    for i in range(len(trafficking_df)):\n",
    "        chunks = list(trafficking_df.iloc[i]['chunks'])\n",
    "        for chunk in chunks:\n",
    "            doc = nlp(chunk)\n",
    "            for ent in doc.ents:\n",
    "                if ent.label_ == entity:\n",
    "#                     print(trafficking_df.iloc[i]['id'])\n",
    "                    if ent.text not in entity_list:\n",
    "                        entity_list.append(ent.text)\n",
    "    return entity_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loc_list = list_entities(\"LOC\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(loc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gpe_list = list_entities(\"GPE\")\n",
    "print(gpe_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in gpe_list:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
